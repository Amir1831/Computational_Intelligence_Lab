{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uymp2t7Apac"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2wHoUGH-5zv",
        "outputId": "ddfd0996-a817-459e-9086-a3775d5cbda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri6LkA6AB6_N"
      },
      "outputs": [],
      "source": [
        "cuda = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjFqVVy9-5zw",
        "outputId": "8beba917-4077-4710-f94f-04a05af05f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-21 11:13:51--  https://github.com/matinfazel/Tumor-Classification/raw/main/Tumor.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/matinfazel/Tumor-Classification/main/Tumor.zip [following]\n",
            "--2023-12-21 11:13:51--  https://raw.githubusercontent.com/matinfazel/Tumor-Classification/main/Tumor.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14338568 (14M) [application/zip]\n",
            "Saving to: ‘Tumor.zip.1’\n",
            "\n",
            "Tumor.zip.1         100%[===================>]  13.67M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-21 11:13:51 (196 MB/s) - ‘Tumor.zip.1’ saved [14338568/14338568]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/matinfazel/Tumor-Classification/raw/main/Tumor.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwgEXklA_NVd",
        "outputId": "b8e9dde9-b2ae-4f18-d05d-5910520241a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Tumor.zip\n",
            "replace Brain_Tumor/Image1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# !unzip Tumor.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir ,percent=1, transform = None):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.percent = percent \n",
        "        self.image_paths = self.get_image_paths()\n",
        "        self.Transform = transform\n",
        "        self.Class_names = [\"CNV\",\"DME\",\"DRUSEN\",\"NORMAL\"]\n",
        "\n",
        "    def get_image_paths(self):\n",
        "        image_paths = []\n",
        "        for root, dir , filenames in os.walk(self.data_dir):\n",
        "            counter = 0\n",
        "            for filename in filenames:\n",
        "                if filename.endswith(\".jpeg\"):\n",
        "                    if counter < int(self.percent * len(filenames)):\n",
        "                        counter += 1\n",
        "                        image_paths.append(os.path.join(root, filename))\n",
        "                    else: break\n",
        "        return image_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        # image = Image.open(image_path)\n",
        "        image = read_image(image_path).float()\n",
        "        label = self.get_label(image_path)\n",
        "        if self.Transform:\n",
        "            image = self.Transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_label(self, image_path):\n",
        "        # Extract the label from the image path\n",
        "        class_name = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Map class names to class labels, if required\n",
        "        label_mapping = {\n",
        "            \"CNV\": torch.tensor([1,0,0,0] , dtype=torch.float32),\n",
        "            \"DME\": torch.tensor([0,1,0,0],dtype=torch.float32),\n",
        "            \"DRUSEN\": torch.tensor([0,0,1,0],dtype=torch.float32),\n",
        "            \"NORMAL\": torch.tensor([0,0,0,1],dtype=torch.float32)\n",
        "        }\n",
        "        label = label_mapping[class_name]\n",
        "\n",
        "        return label\n",
        "\n",
        "    def take (self , num ):\n",
        "        # random index\n",
        "        rand = torch.randint(len(image_paths)-1 , (num ,))\n",
        "        # Iterate through samples\n",
        "        for index in rand :\n",
        "            yield self.__getitem__(index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(data_dir = train_dir , transform=pretrained_vit_transforms , percent=0.3)\n",
        "test_dataset = CustomDataset(data_dir = test_dir , transform = pretrained_vit_transforms , percent=1)\n",
        "len(test_dataset) , len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset , batch_size=BATCH_SIZE , shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE , shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9QPnQZ_0Zv9"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pds\n",
        "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
        "\n",
        "############################################################## Loading Data\n",
        "n = 3762\n",
        "image=[]\n",
        "cw = os.getcwd().replace(os.sep, '/')\n",
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "for i in range(n):\n",
        "#    image.append(np.asarray(Image.open(cw + \"/Brain_Tumor/Image\" + str(i+1) + \".jpg\")))\n",
        "    image.append(np.array(Image.open(cw + \"/Brain_Tumor/Image\" + str(i+1) + \".jpg\").resize((48,48))))\n",
        "\n",
        "temp = pds.read_csv(cw + \"/Brain_Tumor.csv\",index_col=None, header=None).to_numpy()\n",
        "temp = temp[1:,1]\n",
        "targets = np.zeros((n,1),dtype=int)\n",
        "targets = []\n",
        "for i in range(n):\n",
        "    targets.append(int(temp[i]))\n",
        "\n",
        "data = np.array(image)\n",
        "data = data/255\n",
        "data = torch.from_numpy(data).permute((0,3,2,1))\n",
        "data = data.float().to(cuda)\n",
        "targets = torch.tensor(targets).to(cuda)\n",
        "dataset = TensorDataset(data,targets)\n",
        "batch_size = 4\n",
        "val_size = int(np.ceil(len(dataset)*0.2))\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_data,test_data = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "#start your code\n",
        "\n",
        "train_loader = DataLoader(train_data , batch_size ,shuffle=True)        #Put the train data into a data loader\n",
        "test_loader = DataLoader(test_data , batch_size ,shuffle=True)         #Put the train data into a data loader\n",
        "# end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMqM0T2o-5zx"
      },
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFjHR3VB-5zy",
        "outputId": "7b93245b-d612-444d-cc81-6431bed624cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    2079\n",
              "1    1683\n",
              "Name: Class, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pds.read_csv(\"./Brain_Tumor.csv\").Class.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWu_1de034Qq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1mUCiDQp-5zz",
        "outputId": "97f9aa88-9b2d-4641-b611-026eb54d806a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count of data: 3009\n",
            "Feature batch shape: torch.Size([4, 3, 48, 48])\n",
            "Labels batch shape: torch.Size([4])\n",
            "Shape after Flatten : torch.Size([4, 6912])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"count of data:\", len(train_data))\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "print(f\"Shape after Flatten : {nn.Flatten()(train_features).shape}\")\n",
        "for i in range(batch_size):\n",
        "    img = train_features[i].squeeze()\n",
        "    label = train_labels[i]\n",
        "    im = transforms.ToPILImage()(img).convert(\"RGB\")\n",
        "\n",
        "    plt.imshow(im)\n",
        "    plt.show()\n",
        "    print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCRXLlUO0nBN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        #start your code\n",
        "        self.flatten = nn.Flatten()              # flatten\n",
        "        # end\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # your code\n",
        "            nn.Linear(6912 , 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512 , 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24,2),\n",
        "            # end\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #start your code\n",
        "        x = self.flatten(x) # flatten\n",
        "        logits =  self.linear_relu_stack(x)# linear_relu_satck\n",
        "        # end\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNoQt0wh-5z0",
        "outputId": "f5b19307-dd78-4c30-e4a7-1e1c8f385815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=6912, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=24, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=24, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPd-IgTgAIIb"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64  # what is this ?\n",
        "epochs = 100\n",
        "\n",
        "# your code\n",
        "loss_fn = nn.CrossEntropyLoss() # CrossEntropy\n",
        "def build_optimizer(model , learning_rate):\n",
        "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate) # SGD\n",
        "    return optimizer\n",
        "# end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sMcbd-3AIiF"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer , config = None):\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        #start your code\n",
        "        #prediction\n",
        "        preds = model(X)\n",
        "        #loss\n",
        "        loss = loss_fn(preds , y)\n",
        "        #loss optimizer\n",
        "        optimizer.zero_grad()\n",
        "        #backward\n",
        "        loss.backward()\n",
        "        #step\n",
        "        optimizer.step()\n",
        "        #end\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DttraSXe-5z0",
        "outputId": "e66a406a-944f-4574-a21a-d0eee4d9d5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.690117  [    0/ 3009]\n",
            "loss: 0.674259  [  400/ 3009]\n",
            "loss: 0.638337  [  800/ 3009]\n",
            "loss: 0.655854  [ 1200/ 3009]\n",
            "loss: 0.562291  [ 1600/ 3009]\n",
            "loss: 0.771485  [ 2000/ 3009]\n",
            "loss: 0.585165  [ 2400/ 3009]\n",
            "loss: 0.549257  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 0.570977 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.653879  [    0/ 3009]\n",
            "loss: 0.792328  [  400/ 3009]\n",
            "loss: 0.555085  [  800/ 3009]\n",
            "loss: 0.858791  [ 1200/ 3009]\n",
            "loss: 0.369696  [ 1600/ 3009]\n",
            "loss: 0.770016  [ 2000/ 3009]\n",
            "loss: 0.437543  [ 2400/ 3009]\n",
            "loss: 0.543532  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 72.8%, Avg loss: 0.524958 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.284106  [    0/ 3009]\n",
            "loss: 0.400078  [  400/ 3009]\n",
            "loss: 0.250819  [  800/ 3009]\n",
            "loss: 0.700529  [ 1200/ 3009]\n",
            "loss: 0.200724  [ 1600/ 3009]\n",
            "loss: 0.515259  [ 2000/ 3009]\n",
            "loss: 1.258090  [ 2400/ 3009]\n",
            "loss: 0.225964  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 0.496466 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.473289  [    0/ 3009]\n",
            "loss: 0.394660  [  400/ 3009]\n",
            "loss: 0.230693  [  800/ 3009]\n",
            "loss: 0.223692  [ 1200/ 3009]\n",
            "loss: 0.509019  [ 1600/ 3009]\n",
            "loss: 0.170953  [ 2000/ 3009]\n",
            "loss: 0.616852  [ 2400/ 3009]\n",
            "loss: 0.496131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 0.501946 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.543751  [    0/ 3009]\n",
            "loss: 0.636611  [  400/ 3009]\n",
            "loss: 0.318141  [  800/ 3009]\n",
            "loss: 0.319363  [ 1200/ 3009]\n",
            "loss: 0.567721  [ 1600/ 3009]\n",
            "loss: 0.107897  [ 2000/ 3009]\n",
            "loss: 0.339843  [ 2400/ 3009]\n",
            "loss: 0.384994  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 76.8%, Avg loss: 0.482618 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.221414  [    0/ 3009]\n",
            "loss: 1.126889  [  400/ 3009]\n",
            "loss: 0.795900  [  800/ 3009]\n",
            "loss: 0.210549  [ 1200/ 3009]\n",
            "loss: 0.484246  [ 1600/ 3009]\n",
            "loss: 0.414225  [ 2000/ 3009]\n",
            "loss: 0.163391  [ 2400/ 3009]\n",
            "loss: 0.643344  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 0.463769 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.015497  [    0/ 3009]\n",
            "loss: 0.152730  [  400/ 3009]\n",
            "loss: 0.340390  [  800/ 3009]\n",
            "loss: 0.777238  [ 1200/ 3009]\n",
            "loss: 0.349717  [ 1600/ 3009]\n",
            "loss: 0.189502  [ 2000/ 3009]\n",
            "loss: 0.443781  [ 2400/ 3009]\n",
            "loss: 0.612401  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg loss: 0.453227 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.225768  [    0/ 3009]\n",
            "loss: 0.704712  [  400/ 3009]\n",
            "loss: 0.491261  [  800/ 3009]\n",
            "loss: 0.241818  [ 1200/ 3009]\n",
            "loss: 0.907888  [ 1600/ 3009]\n",
            "loss: 0.370377  [ 2000/ 3009]\n",
            "loss: 0.464869  [ 2400/ 3009]\n",
            "loss: 0.264681  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.445776 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.423229  [    0/ 3009]\n",
            "loss: 0.895179  [  400/ 3009]\n",
            "loss: 0.348713  [  800/ 3009]\n",
            "loss: 0.204122  [ 1200/ 3009]\n",
            "loss: 0.518795  [ 1600/ 3009]\n",
            "loss: 0.254883  [ 2000/ 3009]\n",
            "loss: 0.043894  [ 2400/ 3009]\n",
            "loss: 0.537607  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.432408 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.524591  [    0/ 3009]\n",
            "loss: 0.629549  [  400/ 3009]\n",
            "loss: 0.339855  [  800/ 3009]\n",
            "loss: 0.430026  [ 1200/ 3009]\n",
            "loss: 0.246084  [ 1600/ 3009]\n",
            "loss: 0.380392  [ 2000/ 3009]\n",
            "loss: 0.806893  [ 2400/ 3009]\n",
            "loss: 0.550372  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 0.439709 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.839614  [    0/ 3009]\n",
            "loss: 1.239141  [  400/ 3009]\n",
            "loss: 0.146911  [  800/ 3009]\n",
            "loss: 0.131792  [ 1200/ 3009]\n",
            "loss: 1.027289  [ 1600/ 3009]\n",
            "loss: 1.134827  [ 2000/ 3009]\n",
            "loss: 0.222815  [ 2400/ 3009]\n",
            "loss: 0.141708  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.417011 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.266403  [    0/ 3009]\n",
            "loss: 0.521354  [  400/ 3009]\n",
            "loss: 0.242981  [  800/ 3009]\n",
            "loss: 0.259612  [ 1200/ 3009]\n",
            "loss: 0.170870  [ 1600/ 3009]\n",
            "loss: 0.106720  [ 2000/ 3009]\n",
            "loss: 0.377236  [ 2400/ 3009]\n",
            "loss: 0.226885  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.430736 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.866069  [    0/ 3009]\n",
            "loss: 0.242347  [  400/ 3009]\n",
            "loss: 0.231270  [  800/ 3009]\n",
            "loss: 0.517065  [ 1200/ 3009]\n",
            "loss: 0.364467  [ 1600/ 3009]\n",
            "loss: 0.415481  [ 2000/ 3009]\n",
            "loss: 0.556690  [ 2400/ 3009]\n",
            "loss: 1.646284  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.398054 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.543441  [    0/ 3009]\n",
            "loss: 0.158372  [  400/ 3009]\n",
            "loss: 0.394841  [  800/ 3009]\n",
            "loss: 0.730350  [ 1200/ 3009]\n",
            "loss: 0.453531  [ 1600/ 3009]\n",
            "loss: 0.267532  [ 2000/ 3009]\n",
            "loss: 0.237919  [ 2400/ 3009]\n",
            "loss: 0.402800  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.405946 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.089720  [    0/ 3009]\n",
            "loss: 0.562683  [  400/ 3009]\n",
            "loss: 0.128592  [  800/ 3009]\n",
            "loss: 0.638896  [ 1200/ 3009]\n",
            "loss: 0.087183  [ 1600/ 3009]\n",
            "loss: 0.358011  [ 2000/ 3009]\n",
            "loss: 0.378228  [ 2400/ 3009]\n",
            "loss: 0.320625  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.393677 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.699411  [    0/ 3009]\n",
            "loss: 0.565702  [  400/ 3009]\n",
            "loss: 0.065328  [  800/ 3009]\n",
            "loss: 0.132295  [ 1200/ 3009]\n",
            "loss: 0.801017  [ 1600/ 3009]\n",
            "loss: 0.363407  [ 2000/ 3009]\n",
            "loss: 0.917258  [ 2400/ 3009]\n",
            "loss: 0.143187  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.372756 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.724008  [    0/ 3009]\n",
            "loss: 0.125706  [  400/ 3009]\n",
            "loss: 0.584278  [  800/ 3009]\n",
            "loss: 0.719694  [ 1200/ 3009]\n",
            "loss: 0.994489  [ 1600/ 3009]\n",
            "loss: 0.154242  [ 2000/ 3009]\n",
            "loss: 0.242397  [ 2400/ 3009]\n",
            "loss: 0.631793  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.362994 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.405988  [    0/ 3009]\n",
            "loss: 0.620837  [  400/ 3009]\n",
            "loss: 0.132754  [  800/ 3009]\n",
            "loss: 0.134428  [ 1200/ 3009]\n",
            "loss: 0.409248  [ 1600/ 3009]\n",
            "loss: 0.156872  [ 2000/ 3009]\n",
            "loss: 0.598482  [ 2400/ 3009]\n",
            "loss: 0.330481  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.361273 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.140908  [    0/ 3009]\n",
            "loss: 0.442528  [  400/ 3009]\n",
            "loss: 0.173489  [  800/ 3009]\n",
            "loss: 0.370297  [ 1200/ 3009]\n",
            "loss: 0.318678  [ 1600/ 3009]\n",
            "loss: 0.086334  [ 2000/ 3009]\n",
            "loss: 0.523235  [ 2400/ 3009]\n",
            "loss: 0.306680  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.383295 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.405309  [    0/ 3009]\n",
            "loss: 0.098774  [  400/ 3009]\n",
            "loss: 0.290414  [  800/ 3009]\n",
            "loss: 0.348254  [ 1200/ 3009]\n",
            "loss: 0.232256  [ 1600/ 3009]\n",
            "loss: 0.344589  [ 2000/ 3009]\n",
            "loss: 0.068878  [ 2400/ 3009]\n",
            "loss: 0.554459  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.334676 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.499067  [    0/ 3009]\n",
            "loss: 0.082849  [  400/ 3009]\n",
            "loss: 0.230363  [  800/ 3009]\n",
            "loss: 0.215462  [ 1200/ 3009]\n",
            "loss: 0.180243  [ 1600/ 3009]\n",
            "loss: 0.088745  [ 2000/ 3009]\n",
            "loss: 0.701563  [ 2400/ 3009]\n",
            "loss: 0.563279  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.323067 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.118056  [    0/ 3009]\n",
            "loss: 0.378934  [  400/ 3009]\n",
            "loss: 0.168854  [  800/ 3009]\n",
            "loss: 0.115085  [ 1200/ 3009]\n",
            "loss: 0.070395  [ 1600/ 3009]\n",
            "loss: 0.518211  [ 2000/ 3009]\n",
            "loss: 0.256346  [ 2400/ 3009]\n",
            "loss: 0.520860  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.314713 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.090174  [    0/ 3009]\n",
            "loss: 0.209950  [  400/ 3009]\n",
            "loss: 0.268790  [  800/ 3009]\n",
            "loss: 0.047564  [ 1200/ 3009]\n",
            "loss: 0.608746  [ 1600/ 3009]\n",
            "loss: 0.088286  [ 2000/ 3009]\n",
            "loss: 0.173142  [ 2400/ 3009]\n",
            "loss: 0.074144  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 0.418987 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.257081  [    0/ 3009]\n",
            "loss: 0.119280  [  400/ 3009]\n",
            "loss: 0.037770  [  800/ 3009]\n",
            "loss: 0.467116  [ 1200/ 3009]\n",
            "loss: 0.276059  [ 1600/ 3009]\n",
            "loss: 0.398282  [ 2000/ 3009]\n",
            "loss: 1.089568  [ 2400/ 3009]\n",
            "loss: 0.349564  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 76.0%, Avg loss: 0.509847 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.524715  [    0/ 3009]\n",
            "loss: 0.075759  [  400/ 3009]\n",
            "loss: 0.331758  [  800/ 3009]\n",
            "loss: 0.056101  [ 1200/ 3009]\n",
            "loss: 0.194464  [ 1600/ 3009]\n",
            "loss: 0.290475  [ 2000/ 3009]\n",
            "loss: 0.290194  [ 2400/ 3009]\n",
            "loss: 0.768223  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.289908 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.121761  [    0/ 3009]\n",
            "loss: 0.224409  [  400/ 3009]\n",
            "loss: 0.288926  [  800/ 3009]\n",
            "loss: 0.137639  [ 1200/ 3009]\n",
            "loss: 0.148988  [ 1600/ 3009]\n",
            "loss: 0.067570  [ 2000/ 3009]\n",
            "loss: 0.055181  [ 2400/ 3009]\n",
            "loss: 0.280812  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.284815 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.120073  [    0/ 3009]\n",
            "loss: 0.079712  [  400/ 3009]\n",
            "loss: 0.015501  [  800/ 3009]\n",
            "loss: 0.712658  [ 1200/ 3009]\n",
            "loss: 0.276991  [ 1600/ 3009]\n",
            "loss: 0.254290  [ 2000/ 3009]\n",
            "loss: 0.035201  [ 2400/ 3009]\n",
            "loss: 0.123863  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.279788 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.407454  [    0/ 3009]\n",
            "loss: 0.217888  [  400/ 3009]\n",
            "loss: 0.063791  [  800/ 3009]\n",
            "loss: 0.255341  [ 1200/ 3009]\n",
            "loss: 0.039360  [ 1600/ 3009]\n",
            "loss: 0.215034  [ 2000/ 3009]\n",
            "loss: 0.348339  [ 2400/ 3009]\n",
            "loss: 0.670549  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.269850 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.491221  [    0/ 3009]\n",
            "loss: 0.225165  [  400/ 3009]\n",
            "loss: 0.584866  [  800/ 3009]\n",
            "loss: 0.182476  [ 1200/ 3009]\n",
            "loss: 0.112565  [ 1600/ 3009]\n",
            "loss: 0.295589  [ 2000/ 3009]\n",
            "loss: 0.594097  [ 2400/ 3009]\n",
            "loss: 0.193213  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.289570 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.069279  [    0/ 3009]\n",
            "loss: 0.443230  [  400/ 3009]\n",
            "loss: 0.050565  [  800/ 3009]\n",
            "loss: 0.086557  [ 1200/ 3009]\n",
            "loss: 0.117590  [ 1600/ 3009]\n",
            "loss: 0.321798  [ 2000/ 3009]\n",
            "loss: 0.208166  [ 2400/ 3009]\n",
            "loss: 0.309264  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 0.520098 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.638137  [    0/ 3009]\n",
            "loss: 0.216675  [  400/ 3009]\n",
            "loss: 0.228801  [  800/ 3009]\n",
            "loss: 0.113523  [ 1200/ 3009]\n",
            "loss: 0.162771  [ 1600/ 3009]\n",
            "loss: 0.074359  [ 2000/ 3009]\n",
            "loss: 0.222423  [ 2400/ 3009]\n",
            "loss: 0.325438  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.473141 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.663867  [    0/ 3009]\n",
            "loss: 0.032330  [  400/ 3009]\n",
            "loss: 0.219655  [  800/ 3009]\n",
            "loss: 0.130312  [ 1200/ 3009]\n",
            "loss: 0.219889  [ 1600/ 3009]\n",
            "loss: 0.339657  [ 2000/ 3009]\n",
            "loss: 0.105108  [ 2400/ 3009]\n",
            "loss: 1.045050  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.271497 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.101686  [    0/ 3009]\n",
            "loss: 0.050152  [  400/ 3009]\n",
            "loss: 0.666305  [  800/ 3009]\n",
            "loss: 0.215409  [ 1200/ 3009]\n",
            "loss: 0.293049  [ 1600/ 3009]\n",
            "loss: 0.169778  [ 2000/ 3009]\n",
            "loss: 0.046546  [ 2400/ 3009]\n",
            "loss: 0.245380  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.3%, Avg loss: 0.374034 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.048557  [    0/ 3009]\n",
            "loss: 0.116424  [  400/ 3009]\n",
            "loss: 0.240319  [  800/ 3009]\n",
            "loss: 0.464901  [ 1200/ 3009]\n",
            "loss: 0.797219  [ 1600/ 3009]\n",
            "loss: 0.300391  [ 2000/ 3009]\n",
            "loss: 0.497966  [ 2400/ 3009]\n",
            "loss: 0.420950  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.461288 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.037304  [    0/ 3009]\n",
            "loss: 0.117816  [  400/ 3009]\n",
            "loss: 0.077024  [  800/ 3009]\n",
            "loss: 0.349523  [ 1200/ 3009]\n",
            "loss: 0.096321  [ 1600/ 3009]\n",
            "loss: 0.266592  [ 2000/ 3009]\n",
            "loss: 0.050158  [ 2400/ 3009]\n",
            "loss: 0.155668  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.227087 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.313054  [    0/ 3009]\n",
            "loss: 0.104511  [  400/ 3009]\n",
            "loss: 0.298353  [  800/ 3009]\n",
            "loss: 0.087299  [ 1200/ 3009]\n",
            "loss: 0.220975  [ 1600/ 3009]\n",
            "loss: 0.064146  [ 2000/ 3009]\n",
            "loss: 0.427122  [ 2400/ 3009]\n",
            "loss: 0.105827  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.9%, Avg loss: 0.232761 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.664306  [    0/ 3009]\n",
            "loss: 0.143835  [  400/ 3009]\n",
            "loss: 0.021091  [  800/ 3009]\n",
            "loss: 0.643976  [ 1200/ 3009]\n",
            "loss: 0.263190  [ 1600/ 3009]\n",
            "loss: 0.005744  [ 2000/ 3009]\n",
            "loss: 0.025846  [ 2400/ 3009]\n",
            "loss: 0.041754  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.213815 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.495429  [    0/ 3009]\n",
            "loss: 0.448507  [  400/ 3009]\n",
            "loss: 0.234292  [  800/ 3009]\n",
            "loss: 0.052017  [ 1200/ 3009]\n",
            "loss: 0.132489  [ 1600/ 3009]\n",
            "loss: 0.061593  [ 2000/ 3009]\n",
            "loss: 0.523745  [ 2400/ 3009]\n",
            "loss: 0.266718  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.213120 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.122040  [    0/ 3009]\n",
            "loss: 0.382808  [  400/ 3009]\n",
            "loss: 0.078797  [  800/ 3009]\n",
            "loss: 0.145554  [ 1200/ 3009]\n",
            "loss: 0.070545  [ 1600/ 3009]\n",
            "loss: 0.377351  [ 2000/ 3009]\n",
            "loss: 0.019063  [ 2400/ 3009]\n",
            "loss: 0.022082  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.225626 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.032961  [    0/ 3009]\n",
            "loss: 0.018653  [  400/ 3009]\n",
            "loss: 0.088912  [  800/ 3009]\n",
            "loss: 0.714388  [ 1200/ 3009]\n",
            "loss: 0.042360  [ 1600/ 3009]\n",
            "loss: 0.018613  [ 2000/ 3009]\n",
            "loss: 0.081148  [ 2400/ 3009]\n",
            "loss: 0.072131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.220733 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.204683  [    0/ 3009]\n",
            "loss: 0.179450  [  400/ 3009]\n",
            "loss: 0.094234  [  800/ 3009]\n",
            "loss: 0.145394  [ 1200/ 3009]\n",
            "loss: 0.049346  [ 1600/ 3009]\n",
            "loss: 0.006174  [ 2000/ 3009]\n",
            "loss: 0.505898  [ 2400/ 3009]\n",
            "loss: 0.735736  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.212931 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.146524  [    0/ 3009]\n",
            "loss: 0.085688  [  400/ 3009]\n",
            "loss: 0.008869  [  800/ 3009]\n",
            "loss: 0.050868  [ 1200/ 3009]\n",
            "loss: 0.049408  [ 1600/ 3009]\n",
            "loss: 0.072889  [ 2000/ 3009]\n",
            "loss: 0.028573  [ 2400/ 3009]\n",
            "loss: 0.023484  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.212304 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.048217  [    0/ 3009]\n",
            "loss: 0.185749  [  400/ 3009]\n",
            "loss: 0.029820  [  800/ 3009]\n",
            "loss: 1.751641  [ 1200/ 3009]\n",
            "loss: 0.007485  [ 1600/ 3009]\n",
            "loss: 0.316623  [ 2000/ 3009]\n",
            "loss: 0.064638  [ 2400/ 3009]\n",
            "loss: 0.870070  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.210881 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.025632  [    0/ 3009]\n",
            "loss: 0.685920  [  400/ 3009]\n",
            "loss: 0.024463  [  800/ 3009]\n",
            "loss: 0.019905  [ 1200/ 3009]\n",
            "loss: 0.279360  [ 1600/ 3009]\n",
            "loss: 0.026658  [ 2000/ 3009]\n",
            "loss: 0.058331  [ 2400/ 3009]\n",
            "loss: 0.013526  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.258847 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.139127  [    0/ 3009]\n",
            "loss: 0.048712  [  400/ 3009]\n",
            "loss: 0.135871  [  800/ 3009]\n",
            "loss: 0.111377  [ 1200/ 3009]\n",
            "loss: 0.257003  [ 1600/ 3009]\n",
            "loss: 0.685024  [ 2000/ 3009]\n",
            "loss: 0.354164  [ 2400/ 3009]\n",
            "loss: 0.022061  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.248532 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.046543  [    0/ 3009]\n",
            "loss: 0.021509  [  400/ 3009]\n",
            "loss: 0.194115  [  800/ 3009]\n",
            "loss: 0.089997  [ 1200/ 3009]\n",
            "loss: 0.079659  [ 1600/ 3009]\n",
            "loss: 0.269670  [ 2000/ 3009]\n",
            "loss: 0.112332  [ 2400/ 3009]\n",
            "loss: 0.429810  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.201331 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.006503  [    0/ 3009]\n",
            "loss: 0.012015  [  400/ 3009]\n",
            "loss: 0.151425  [  800/ 3009]\n",
            "loss: 1.008239  [ 1200/ 3009]\n",
            "loss: 0.105017  [ 1600/ 3009]\n",
            "loss: 0.452238  [ 2000/ 3009]\n",
            "loss: 0.031722  [ 2400/ 3009]\n",
            "loss: 0.391955  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.325208 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.670916  [    0/ 3009]\n",
            "loss: 0.195296  [  400/ 3009]\n",
            "loss: 0.045174  [  800/ 3009]\n",
            "loss: 0.624958  [ 1200/ 3009]\n",
            "loss: 0.009738  [ 1600/ 3009]\n",
            "loss: 0.092973  [ 2000/ 3009]\n",
            "loss: 0.024192  [ 2400/ 3009]\n",
            "loss: 0.033990  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.234787 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.012845  [    0/ 3009]\n",
            "loss: 0.141562  [  400/ 3009]\n",
            "loss: 0.739802  [  800/ 3009]\n",
            "loss: 0.318296  [ 1200/ 3009]\n",
            "loss: 0.041593  [ 1600/ 3009]\n",
            "loss: 0.368332  [ 2000/ 3009]\n",
            "loss: 0.658535  [ 2400/ 3009]\n",
            "loss: 0.183176  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.191717 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.007301  [    0/ 3009]\n",
            "loss: 0.609095  [  400/ 3009]\n",
            "loss: 0.105978  [  800/ 3009]\n",
            "loss: 0.254299  [ 1200/ 3009]\n",
            "loss: 0.018121  [ 1600/ 3009]\n",
            "loss: 0.138547  [ 2000/ 3009]\n",
            "loss: 0.355798  [ 2400/ 3009]\n",
            "loss: 0.221016  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.297987 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.772835  [    0/ 3009]\n",
            "loss: 0.040743  [  400/ 3009]\n",
            "loss: 0.883624  [  800/ 3009]\n",
            "loss: 0.022929  [ 1200/ 3009]\n",
            "loss: 0.001531  [ 1600/ 3009]\n",
            "loss: 0.038064  [ 2000/ 3009]\n",
            "loss: 0.011560  [ 2400/ 3009]\n",
            "loss: 0.258916  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.294230 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.350876  [    0/ 3009]\n",
            "loss: 0.041881  [  400/ 3009]\n",
            "loss: 0.070171  [  800/ 3009]\n",
            "loss: 1.304612  [ 1200/ 3009]\n",
            "loss: 0.146356  [ 1600/ 3009]\n",
            "loss: 0.005140  [ 2000/ 3009]\n",
            "loss: 0.040496  [ 2400/ 3009]\n",
            "loss: 0.126988  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.404277 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.587275  [    0/ 3009]\n",
            "loss: 0.041167  [  400/ 3009]\n",
            "loss: 0.014767  [  800/ 3009]\n",
            "loss: 0.013177  [ 1200/ 3009]\n",
            "loss: 0.066297  [ 1600/ 3009]\n",
            "loss: 0.613788  [ 2000/ 3009]\n",
            "loss: 0.430030  [ 2400/ 3009]\n",
            "loss: 0.218998  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.271173 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.078584  [    0/ 3009]\n",
            "loss: 0.024929  [  400/ 3009]\n",
            "loss: 0.026119  [  800/ 3009]\n",
            "loss: 0.054233  [ 1200/ 3009]\n",
            "loss: 0.086885  [ 1600/ 3009]\n",
            "loss: 0.045433  [ 2000/ 3009]\n",
            "loss: 0.015564  [ 2400/ 3009]\n",
            "loss: 0.174216  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.205301 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.039321  [    0/ 3009]\n",
            "loss: 0.168968  [  400/ 3009]\n",
            "loss: 0.020813  [  800/ 3009]\n",
            "loss: 0.179011  [ 1200/ 3009]\n",
            "loss: 0.046516  [ 1600/ 3009]\n",
            "loss: 0.031929  [ 2000/ 3009]\n",
            "loss: 0.685539  [ 2400/ 3009]\n",
            "loss: 0.015791  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.212998 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.624277  [    0/ 3009]\n",
            "loss: 0.079662  [  400/ 3009]\n",
            "loss: 0.596326  [  800/ 3009]\n",
            "loss: 0.050350  [ 1200/ 3009]\n",
            "loss: 0.233830  [ 1600/ 3009]\n",
            "loss: 0.026898  [ 2000/ 3009]\n",
            "loss: 0.012176  [ 2400/ 3009]\n",
            "loss: 0.001686  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.197868 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.239182  [    0/ 3009]\n",
            "loss: 0.477633  [  400/ 3009]\n",
            "loss: 0.030897  [  800/ 3009]\n",
            "loss: 0.026392  [ 1200/ 3009]\n",
            "loss: 0.000643  [ 1600/ 3009]\n",
            "loss: 0.279751  [ 2000/ 3009]\n",
            "loss: 0.103078  [ 2400/ 3009]\n",
            "loss: 0.072326  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.183563 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.092860  [    0/ 3009]\n",
            "loss: 0.052341  [  400/ 3009]\n",
            "loss: 0.051187  [  800/ 3009]\n",
            "loss: 0.216870  [ 1200/ 3009]\n",
            "loss: 0.040047  [ 1600/ 3009]\n",
            "loss: 0.156741  [ 2000/ 3009]\n",
            "loss: 0.032283  [ 2400/ 3009]\n",
            "loss: 0.043743  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.204014 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.095992  [    0/ 3009]\n",
            "loss: 0.017734  [  400/ 3009]\n",
            "loss: 0.012455  [  800/ 3009]\n",
            "loss: 0.117746  [ 1200/ 3009]\n",
            "loss: 0.123244  [ 1600/ 3009]\n",
            "loss: 0.004946  [ 2000/ 3009]\n",
            "loss: 0.066022  [ 2400/ 3009]\n",
            "loss: 0.072877  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.170680 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.399225  [    0/ 3009]\n",
            "loss: 0.073184  [  400/ 3009]\n",
            "loss: 0.047200  [  800/ 3009]\n",
            "loss: 0.084575  [ 1200/ 3009]\n",
            "loss: 0.062841  [ 1600/ 3009]\n",
            "loss: 0.009179  [ 2000/ 3009]\n",
            "loss: 0.091566  [ 2400/ 3009]\n",
            "loss: 0.260171  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.221004 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.006027  [    0/ 3009]\n",
            "loss: 0.001851  [  400/ 3009]\n",
            "loss: 0.011817  [  800/ 3009]\n",
            "loss: 0.252660  [ 1200/ 3009]\n",
            "loss: 0.632296  [ 1600/ 3009]\n",
            "loss: 0.052633  [ 2000/ 3009]\n",
            "loss: 0.527655  [ 2400/ 3009]\n",
            "loss: 0.082243  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.189862 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.044501  [    0/ 3009]\n",
            "loss: 0.180584  [  400/ 3009]\n",
            "loss: 0.216366  [  800/ 3009]\n",
            "loss: 0.016651  [ 1200/ 3009]\n",
            "loss: 0.036811  [ 1600/ 3009]\n",
            "loss: 0.111178  [ 2000/ 3009]\n",
            "loss: 0.123335  [ 2400/ 3009]\n",
            "loss: 0.004290  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.244437 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.006303  [    0/ 3009]\n",
            "loss: 0.366116  [  400/ 3009]\n",
            "loss: 0.977503  [  800/ 3009]\n",
            "loss: 0.008704  [ 1200/ 3009]\n",
            "loss: 0.227888  [ 1600/ 3009]\n",
            "loss: 0.173530  [ 2000/ 3009]\n",
            "loss: 0.030205  [ 2400/ 3009]\n",
            "loss: 0.012845  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.342894 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.158392  [    0/ 3009]\n",
            "loss: 0.385045  [  400/ 3009]\n",
            "loss: 0.158103  [  800/ 3009]\n",
            "loss: 0.005286  [ 1200/ 3009]\n",
            "loss: 0.002606  [ 1600/ 3009]\n",
            "loss: 0.002603  [ 2000/ 3009]\n",
            "loss: 0.029563  [ 2400/ 3009]\n",
            "loss: 0.040833  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.227715 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.433736  [    0/ 3009]\n",
            "loss: 0.014843  [  400/ 3009]\n",
            "loss: 0.224290  [  800/ 3009]\n",
            "loss: 0.300233  [ 1200/ 3009]\n",
            "loss: 0.087687  [ 1600/ 3009]\n",
            "loss: 0.043814  [ 2000/ 3009]\n",
            "loss: 0.000429  [ 2400/ 3009]\n",
            "loss: 0.062011  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.178038 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.272178  [    0/ 3009]\n",
            "loss: 0.021729  [  400/ 3009]\n",
            "loss: 0.486351  [  800/ 3009]\n",
            "loss: 0.106199  [ 1200/ 3009]\n",
            "loss: 0.027664  [ 1600/ 3009]\n",
            "loss: 0.141823  [ 2000/ 3009]\n",
            "loss: 0.006403  [ 2400/ 3009]\n",
            "loss: 0.220968  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.197633 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.063299  [    0/ 3009]\n",
            "loss: 0.575668  [  400/ 3009]\n",
            "loss: 0.074682  [  800/ 3009]\n",
            "loss: 0.097496  [ 1200/ 3009]\n",
            "loss: 0.031935  [ 1600/ 3009]\n",
            "loss: 0.228278  [ 2000/ 3009]\n",
            "loss: 0.031662  [ 2400/ 3009]\n",
            "loss: 1.299580  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.187229 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.074553  [    0/ 3009]\n",
            "loss: 0.149477  [  400/ 3009]\n",
            "loss: 0.040195  [  800/ 3009]\n",
            "loss: 0.006753  [ 1200/ 3009]\n",
            "loss: 0.419934  [ 1600/ 3009]\n",
            "loss: 0.021552  [ 2000/ 3009]\n",
            "loss: 0.113103  [ 2400/ 3009]\n",
            "loss: 0.086677  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.175492 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.002691  [    0/ 3009]\n",
            "loss: 0.006427  [  400/ 3009]\n",
            "loss: 0.139980  [  800/ 3009]\n",
            "loss: 0.317569  [ 1200/ 3009]\n",
            "loss: 0.007658  [ 1600/ 3009]\n",
            "loss: 0.001754  [ 2000/ 3009]\n",
            "loss: 0.004585  [ 2400/ 3009]\n",
            "loss: 0.019152  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.241178 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.607924  [    0/ 3009]\n",
            "loss: 0.014944  [  400/ 3009]\n",
            "loss: 0.011291  [  800/ 3009]\n",
            "loss: 0.018273  [ 1200/ 3009]\n",
            "loss: 0.184193  [ 1600/ 3009]\n",
            "loss: 0.148476  [ 2000/ 3009]\n",
            "loss: 0.258424  [ 2400/ 3009]\n",
            "loss: 0.015365  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.176103 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.028923  [    0/ 3009]\n",
            "loss: 0.082968  [  400/ 3009]\n",
            "loss: 0.024538  [  800/ 3009]\n",
            "loss: 0.066358  [ 1200/ 3009]\n",
            "loss: 0.034331  [ 1600/ 3009]\n",
            "loss: 0.058183  [ 2000/ 3009]\n",
            "loss: 0.120745  [ 2400/ 3009]\n",
            "loss: 0.165297  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.192108 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.022258  [    0/ 3009]\n",
            "loss: 0.042398  [  400/ 3009]\n",
            "loss: 0.003531  [  800/ 3009]\n",
            "loss: 0.024827  [ 1200/ 3009]\n",
            "loss: 0.002344  [ 1600/ 3009]\n",
            "loss: 0.079547  [ 2000/ 3009]\n",
            "loss: 0.204342  [ 2400/ 3009]\n",
            "loss: 0.024745  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.250853 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.004640  [    0/ 3009]\n",
            "loss: 0.073378  [  400/ 3009]\n",
            "loss: 0.004666  [  800/ 3009]\n",
            "loss: 0.001155  [ 1200/ 3009]\n",
            "loss: 0.002632  [ 1600/ 3009]\n",
            "loss: 0.029169  [ 2000/ 3009]\n",
            "loss: 0.010809  [ 2400/ 3009]\n",
            "loss: 0.007005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.227951 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.043759  [    0/ 3009]\n",
            "loss: 0.008384  [  400/ 3009]\n",
            "loss: 0.581091  [  800/ 3009]\n",
            "loss: 0.402847  [ 1200/ 3009]\n",
            "loss: 0.005071  [ 1600/ 3009]\n",
            "loss: 0.010361  [ 2000/ 3009]\n",
            "loss: 0.022958  [ 2400/ 3009]\n",
            "loss: 0.064585  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.179281 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.038962  [    0/ 3009]\n",
            "loss: 0.010744  [  400/ 3009]\n",
            "loss: 1.424288  [  800/ 3009]\n",
            "loss: 0.113292  [ 1200/ 3009]\n",
            "loss: 0.081298  [ 1600/ 3009]\n",
            "loss: 0.222578  [ 2000/ 3009]\n",
            "loss: 0.072182  [ 2400/ 3009]\n",
            "loss: 0.006191  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.168460 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.077810  [    0/ 3009]\n",
            "loss: 0.231135  [  400/ 3009]\n",
            "loss: 0.042429  [  800/ 3009]\n",
            "loss: 0.306349  [ 1200/ 3009]\n",
            "loss: 0.004676  [ 1600/ 3009]\n",
            "loss: 0.479689  [ 2000/ 3009]\n",
            "loss: 0.662612  [ 2400/ 3009]\n",
            "loss: 0.003254  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.163491 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.010924  [    0/ 3009]\n",
            "loss: 0.001612  [  400/ 3009]\n",
            "loss: 0.018706  [  800/ 3009]\n",
            "loss: 0.024824  [ 1200/ 3009]\n",
            "loss: 0.005431  [ 1600/ 3009]\n",
            "loss: 0.228165  [ 2000/ 3009]\n",
            "loss: 0.025468  [ 2400/ 3009]\n",
            "loss: 0.029915  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.172544 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.007518  [    0/ 3009]\n",
            "loss: 0.012534  [  400/ 3009]\n",
            "loss: 0.381190  [  800/ 3009]\n",
            "loss: 0.021560  [ 1200/ 3009]\n",
            "loss: 0.024187  [ 1600/ 3009]\n",
            "loss: 0.016048  [ 2000/ 3009]\n",
            "loss: 0.010203  [ 2400/ 3009]\n",
            "loss: 0.038745  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.221174 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.261461  [    0/ 3009]\n",
            "loss: 0.006879  [  400/ 3009]\n",
            "loss: 0.000438  [  800/ 3009]\n",
            "loss: 0.020116  [ 1200/ 3009]\n",
            "loss: 0.006626  [ 1600/ 3009]\n",
            "loss: 0.300158  [ 2000/ 3009]\n",
            "loss: 0.114167  [ 2400/ 3009]\n",
            "loss: 0.314375  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.222354 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.009200  [    0/ 3009]\n",
            "loss: 0.027725  [  400/ 3009]\n",
            "loss: 0.013590  [  800/ 3009]\n",
            "loss: 0.003612  [ 1200/ 3009]\n",
            "loss: 0.004493  [ 1600/ 3009]\n",
            "loss: 0.453654  [ 2000/ 3009]\n",
            "loss: 0.066224  [ 2400/ 3009]\n",
            "loss: 0.206569  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.175713 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.004165  [    0/ 3009]\n",
            "loss: 0.020925  [  400/ 3009]\n",
            "loss: 0.002228  [  800/ 3009]\n",
            "loss: 0.058976  [ 1200/ 3009]\n",
            "loss: 0.030622  [ 1600/ 3009]\n",
            "loss: 0.003412  [ 2000/ 3009]\n",
            "loss: 0.491086  [ 2400/ 3009]\n",
            "loss: 0.003855  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.179782 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.004413  [    0/ 3009]\n",
            "loss: 0.041578  [  400/ 3009]\n",
            "loss: 0.000190  [  800/ 3009]\n",
            "loss: 0.028365  [ 1200/ 3009]\n",
            "loss: 0.016139  [ 1600/ 3009]\n",
            "loss: 0.007171  [ 2000/ 3009]\n",
            "loss: 0.080781  [ 2400/ 3009]\n",
            "loss: 0.002110  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.168197 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.006797  [    0/ 3009]\n",
            "loss: 0.003327  [  400/ 3009]\n",
            "loss: 0.094960  [  800/ 3009]\n",
            "loss: 0.013185  [ 1200/ 3009]\n",
            "loss: 0.111558  [ 1600/ 3009]\n",
            "loss: 0.069609  [ 2000/ 3009]\n",
            "loss: 0.001068  [ 2400/ 3009]\n",
            "loss: 0.003774  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.210359 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.098134  [    0/ 3009]\n",
            "loss: 0.335054  [  400/ 3009]\n",
            "loss: 0.162174  [  800/ 3009]\n",
            "loss: 0.065301  [ 1200/ 3009]\n",
            "loss: 0.023053  [ 1600/ 3009]\n",
            "loss: 0.001547  [ 2000/ 3009]\n",
            "loss: 0.004065  [ 2400/ 3009]\n",
            "loss: 0.205133  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.167282 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.055239  [    0/ 3009]\n",
            "loss: 0.001424  [  400/ 3009]\n",
            "loss: 0.010670  [  800/ 3009]\n",
            "loss: 0.002376  [ 1200/ 3009]\n",
            "loss: 0.012897  [ 1600/ 3009]\n",
            "loss: 0.078464  [ 2000/ 3009]\n",
            "loss: 0.085582  [ 2400/ 3009]\n",
            "loss: 0.034002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.188962 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.003274  [    0/ 3009]\n",
            "loss: 0.011569  [  400/ 3009]\n",
            "loss: 0.104427  [  800/ 3009]\n",
            "loss: 0.020953  [ 1200/ 3009]\n",
            "loss: 0.282533  [ 1600/ 3009]\n",
            "loss: 0.055212  [ 2000/ 3009]\n",
            "loss: 0.010750  [ 2400/ 3009]\n",
            "loss: 0.176766  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.166208 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.047503  [    0/ 3009]\n",
            "loss: 0.002842  [  400/ 3009]\n",
            "loss: 0.167348  [  800/ 3009]\n",
            "loss: 0.025205  [ 1200/ 3009]\n",
            "loss: 0.009451  [ 1600/ 3009]\n",
            "loss: 0.002746  [ 2000/ 3009]\n",
            "loss: 0.000437  [ 2400/ 3009]\n",
            "loss: 0.001469  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.180464 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.011403  [    0/ 3009]\n",
            "loss: 0.041395  [  400/ 3009]\n",
            "loss: 0.411806  [  800/ 3009]\n",
            "loss: 0.100662  [ 1200/ 3009]\n",
            "loss: 0.006911  [ 1600/ 3009]\n",
            "loss: 0.151489  [ 2000/ 3009]\n",
            "loss: 0.008831  [ 2400/ 3009]\n",
            "loss: 0.116091  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.234711 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.004594  [    0/ 3009]\n",
            "loss: 0.000804  [  400/ 3009]\n",
            "loss: 0.580224  [  800/ 3009]\n",
            "loss: 0.011570  [ 1200/ 3009]\n",
            "loss: 0.115524  [ 1600/ 3009]\n",
            "loss: 0.038643  [ 2000/ 3009]\n",
            "loss: 0.093626  [ 2400/ 3009]\n",
            "loss: 0.001560  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.157882 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.003343  [    0/ 3009]\n",
            "loss: 0.049742  [  400/ 3009]\n",
            "loss: 0.006381  [  800/ 3009]\n",
            "loss: 0.004911  [ 1200/ 3009]\n",
            "loss: 0.003708  [ 1600/ 3009]\n",
            "loss: 0.003516  [ 2000/ 3009]\n",
            "loss: 0.012233  [ 2400/ 3009]\n",
            "loss: 0.005901  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.185003 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.031581  [    0/ 3009]\n",
            "loss: 0.030699  [  400/ 3009]\n",
            "loss: 0.055390  [  800/ 3009]\n",
            "loss: 1.364727  [ 1200/ 3009]\n",
            "loss: 0.029658  [ 1600/ 3009]\n",
            "loss: 0.088341  [ 2000/ 3009]\n",
            "loss: 0.048505  [ 2400/ 3009]\n",
            "loss: 0.065586  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.165367 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.006096  [    0/ 3009]\n",
            "loss: 0.001405  [  400/ 3009]\n",
            "loss: 0.289930  [  800/ 3009]\n",
            "loss: 0.697730  [ 1200/ 3009]\n",
            "loss: 0.060912  [ 1600/ 3009]\n",
            "loss: 0.000353  [ 2000/ 3009]\n",
            "loss: 0.001948  [ 2400/ 3009]\n",
            "loss: 0.091300  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.181228 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.056157  [    0/ 3009]\n",
            "loss: 0.233473  [  400/ 3009]\n",
            "loss: 0.000102  [  800/ 3009]\n",
            "loss: 0.019548  [ 1200/ 3009]\n",
            "loss: 0.000596  [ 1600/ 3009]\n",
            "loss: 0.042558  [ 2000/ 3009]\n",
            "loss: 0.012790  [ 2400/ 3009]\n",
            "loss: 0.015249  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.242016 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.025989  [    0/ 3009]\n",
            "loss: 0.003271  [  400/ 3009]\n",
            "loss: 0.066728  [  800/ 3009]\n",
            "loss: 0.001017  [ 1200/ 3009]\n",
            "loss: 0.014583  [ 1600/ 3009]\n",
            "loss: 0.033040  [ 2000/ 3009]\n",
            "loss: 0.057760  [ 2400/ 3009]\n",
            "loss: 0.000179  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.390094 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.736873  [    0/ 3009]\n",
            "loss: 0.006613  [  400/ 3009]\n",
            "loss: 0.004427  [  800/ 3009]\n",
            "loss: 0.378426  [ 1200/ 3009]\n",
            "loss: 0.029974  [ 1600/ 3009]\n",
            "loss: 0.029723  [ 2000/ 3009]\n",
            "loss: 0.018387  [ 2400/ 3009]\n",
            "loss: 0.037360  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.171008 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.015563  [    0/ 3009]\n",
            "loss: 0.005498  [  400/ 3009]\n",
            "loss: 0.026309  [  800/ 3009]\n",
            "loss: 0.104323  [ 1200/ 3009]\n",
            "loss: 0.006033  [ 1600/ 3009]\n",
            "loss: 0.000247  [ 2000/ 3009]\n",
            "loss: 0.028813  [ 2400/ 3009]\n",
            "loss: 0.135564  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.185216 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.049633  [    0/ 3009]\n",
            "loss: 0.015570  [  400/ 3009]\n",
            "loss: 0.271499  [  800/ 3009]\n",
            "loss: 0.012303  [ 1200/ 3009]\n",
            "loss: 0.761246  [ 1600/ 3009]\n",
            "loss: 0.098330  [ 2000/ 3009]\n",
            "loss: 0.024700  [ 2400/ 3009]\n",
            "loss: 0.020542  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.168618 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.004613  [    0/ 3009]\n",
            "loss: 0.002760  [  400/ 3009]\n",
            "loss: 0.043108  [  800/ 3009]\n",
            "loss: 0.010843  [ 1200/ 3009]\n",
            "loss: 0.003047  [ 1600/ 3009]\n",
            "loss: 0.064327  [ 2000/ 3009]\n",
            "loss: 0.051352  [ 2400/ 3009]\n",
            "loss: 0.013239  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.205658 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000035  [    0/ 3009]\n",
            "loss: 0.063911  [  400/ 3009]\n",
            "loss: 0.027599  [  800/ 3009]\n",
            "loss: 0.013893  [ 1200/ 3009]\n",
            "loss: 0.040647  [ 1600/ 3009]\n",
            "loss: 0.001055  [ 2000/ 3009]\n",
            "loss: 0.010349  [ 2400/ 3009]\n",
            "loss: 0.004033  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.167299 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.008702  [    0/ 3009]\n",
            "loss: 0.023611  [  400/ 3009]\n",
            "loss: 0.001752  [  800/ 3009]\n",
            "loss: 0.059290  [ 1200/ 3009]\n",
            "loss: 0.002278  [ 1600/ 3009]\n",
            "loss: 0.000135  [ 2000/ 3009]\n",
            "loss: 0.003508  [ 2400/ 3009]\n",
            "loss: 0.011805  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.182239 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, build_optimizer(model , learning_rate))\n",
        "    loss = test_loop(test_loader, model, loss_fn)\n",
        "    losses.append(loss)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "7LTPO1F9-5z0",
        "outputId": "9003fa88-5958-4e5c-885b-447bd0f1124f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7bf1241e7b20>]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB23UlEQVR4nO2deZwcdZ3+n+p77snMZGYyk/tOCEkggRCQOwiKggcuuiiYVVyV7ILZdZV1BVdkw67+WC+EFUXwBFHwQAUhECQQkpALAiEHuY+ZyZw9Z5/1+6PrW1XdU91d3V19P+/Xa16Q6aumM+l66vN5Ps9HkmVZBiGEEEJInrDl+wAIIYQQUt5QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkrzjyfQBmCIfDOHnyJGpqaiBJUr4PhxBCCCEmkGUZg4ODaGtrg80Wv/5RFGLk5MmTmDJlSr4PgxBCCCFpcOzYMUyePDnu7UUhRmpqagBEfpja2to8Hw0hhBBCzOD1ejFlyhT1PB6PohAjojVTW1tLMUIIIYQUGcksFjSwEkIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr5StGJFlGd95bj+++PguDIwE8n04hBBCSNlStmJEkiT87NUjeHzbcRzrG8n34RBCCCFlS9mKEQBon1ABADjeN5rnIyGEEELKl7IWI5PrI2LkRD/FCCGEEJIvylqMiMrICVZGCCGEkLxR1mJkshAj/fSMEEIIIfmirMVIez09I4QQQki+KW8xMoGeEUIIISTflLcYUSoj/SMBDPuCeT4aQgghpDwpazFS43Gi1uMAwOoIIYQQki/KWowAQPuESgCcqCGEEELyBcWIMLGyMkIIIYTkhbIXI5OZNUIIIYTkFYoRNRKeWSOEEEJIPih7MdLOSHhCCCEkr1CMsE1DCCGE5BWKEaUy0jXogy8YyvPREEIIIeVH2YuRhioXPM7I23CqfyzPR0MIIYSUH2UvRiRJom+EEEIIySNlL0YAYDKDzwghhJC8QTECzcTK8V5CCCEk91CMgCmshBBCSD6hGAFTWAkhhJB8QjECBp8RQggh+YRiBJpnpGNgDKGwnOejIYQQQsoLihEAzTUeOGwSgmEZnV5mjRBCCCG5hGIEgN0moY2tGkIIISQvUIwoqBM1HO8lhBBCcgrFiAIX5hFCCCH5gWJEgRM1hBBCSH6gGFHQUlgpRgghhJBcQjGiMJmVEUIIISQvUIwo6D0jssysEUIIISRXUIwoTKqrgCQBvmAY3UP+fB8OIYQQUjZQjCi4HDa01HgAsFVDCCGE5BKKER0c7yWEEEJyD8WIDm28l8FnhBBCSK6gGNHBygghhBCSeyhGdGiR8BQjhBBCSK6gGNExa2I1AODtjsE8HwkhhBBSPlCM6DijvRZAZJqmb5jjvYQQQkguoBjRUetxYnpjJQDgzZPePB8NyTWhsEwRSggheYBiJIYz2usAAG+cGMjzkZBcc9tjO3HO3c/hSM9wvg+FEELKCoqRGBa1RcTI7pMUI+XG26e8CIZl7DzWn+9DIYSQsoJiJIYzlcrIm6yMlB2BUBgAp6kIISTXUIzEcEZbxMR6uGcE3rFAno+G5JJAKLIg8STXARBCSE6hGIlhQpVLzRt58wRNrOWEX6mMcDcRIYTkFooRAxYpI75v0jdSVviDETHCygghhOQWihEDzuRETVkiPCMn+kYhy3Kej4YQQsoHihEDxHjvboqRskKIkWF/CN7RYJ6PhhBCygeKEQPEeO/B7mEM+3hSyhfhsIx/+tUOfOe5/Vl/LVmWVQMrABzn5mZCCMkZFCMGTKxxo7XWA1kG9pyiiTVfHOwewh93ncSDLx3M+msJ86rgZP9Y1l+TEEJIBIqROAgTK30j+WNgNDJaLYyl2URfFQGAE32sjBBCSK6gGInDGSKJleO9eUP4NvyhcNYNpYEYwXNygJURQgjJFRQjcVCTWDnemzf0oXOxlQurCcS0aU4whZUQQnJGWmLkvvvuw/Tp0+HxeLBixQps2bIl7n0ffvhhSJIU9eXxeNI+4FyxSBEj+7uGMBYI5floyhPvmGYejvV0WE3s8zP4jBBCckfKYuSxxx7D2rVrceedd2L79u1YsmQJrrzySnR1dcV9TG1tLU6dOqV+HTlyJKODzgUttW40VbsQCstRJlZZlvHC3i5uds0B3lFdZSTLvpFYXwrFCCGE5I6Uxci9996Lm2++GatXr8bChQvxwAMPoLKyEg899FDcx0iShNbWVvWrpaUlo4POBZIkqdWR3ScjYkSWZXzjT3uw+idb8elHXsvn4ZUF+jZNtisjog3ksEkAgNODPviCrIgRQkguSEmM+P1+bNu2DatWrdKewGbDqlWrsGnTpriPGxoawrRp0zBlyhRce+21ePPNNxO+js/ng9frjfrKByJvZPfxAYTDMu78w5v48cZDACLtm0PdrI5kE33wWLYnaoRnpKnaDY8z8s/iFMd7CSEkJ6QkRrq7uxEKhcZVNlpaWtDR0WH4mHnz5uGhhx7C73//e/z85z9HOBzG+eefj+PHj8d9nXXr1qGurk79mjJlSiqHaRlivPf1EwP4yu9246ebjkCSgOYaNwDghbfjt6ZI5uSyMiKe3+WwoU1ZlMgdNYQQkhuyPk2zcuVK3HjjjVi6dCkuvvhiPPHEE5g4cSL+7//+L+5jbr/9dgwMDKhfx44dy/ZhGiLaNHtOefGrLUchScA3r1uCmy+cCQB4YS/FSDYZHMtdZUQ8v9MuqVubj1OMEEJITkhJjDQ1NcFut6OzszPq+52dnWhtbTX1HE6nE2eddRYOHDgQ9z5utxu1tbVRX/mgvb4C9ZVOAIBNAr59/VJct2wyLp0/EQCw+WAvRvyMi88WUQbWrHtGRGXEjskTImKE472EEJIbUhIjLpcLy5Ytw/r169XvhcNhrF+/HitXrjT1HKFQCG+88QYmTZqU2pHmAUmScOXCVrgdNnz3Y2fh2qXtAIBZE6sxeUIF/KEwXjnQk+ejLF2i2jQ58oy47BLa6timIYSQXJJym2bt2rV48MEH8cgjj2DPnj343Oc+h+HhYaxevRoAcOONN+L2229X7//1r38df/3rX3Hw4EFs374dH//4x3HkyBF8+tOftu6nyCL3fPhM7LjjCrxvcZv6PUmScNn8ZgBs1WSTKANrtj0jwcg0jdNuQ7uojFCMEEJITnCk+oDrr78ep0+fxh133IGOjg4sXboUTz/9tGpqPXr0KGw2TeP09fXh5ptvRkdHByZMmIBly5bhlVdewcKFC637KbKIJEmodI1/my6d14yfbjqCF97ugizLkCQpD0dX2gzmoTLitNPASgghuSZlMQIAa9aswZo1awxv27BhQ9Sf//d//xf/+7//m87LFDTnzWyE22HDyYEx7OscwrzWmnwfUkkxFgjBpxMg2Y6DF2LH5bCpBtaT/WMIh2XYbBSahBCSTbibJk0qXHasnNUIgK2abKCfpAFyWxlprfPAJkVaQ93Dvqy+LiGEEIqRjFB9I8wbsRy9eRXI5TSNBKfdhpbayP4kTtQQQkj2oRjJgEvmRsTIa0f6xp08SWbox3qBHOSMhDQDKwCdb4QprIQQkm0oRjJgamMlZk2sQigsY+P+7nwfTkkxrk2T9WkarU0DQPWNnOgfyerrEkIIoRjJmEvnsVWTDWIrTTnLGXGwMkIIIbmGYiRDLlV8Ixv2nUY4nN2Jj3JCnzEC5NAzIiojStbIcXpGCCEk61CMZMg50xtQ5bLj9KAPb53Kz3bhUiTXlRF/SNtNAwCTmTVCCCE5g2IkQ1wOG941pwkAsH4PWzVWMZjraZqgsYGVKayEEJJ9KEYs4PL5kfTZ55k3YhmxbRpftg2soRAAvRiJjPYOjAYw5OMyREIIySYUIxZwibLFd9exfpweZEiWFYg2jTCUispFthDPL16vxuNErScSUMxWDSGEZBeKEQtorvFgyeQ6AJyqsQqRM9JU5QKgVS6yRayBFQDaJ1QCYKuGEEKyDcWIRVymtGrWv92Z5yMpDbxKzkhTjRtA9isjsQZWAGivZworIYTkAooRi7h8QWTE96X93fAFs3sVXw4IA2ujWhnJUeiZQ1cZ4UQNIYTkBIoRizijrRYttW6M+EPYfLA334dT9AgDa2N1pDKSbTFi1KbhRA0hhOQGihGLkCRJXZz3PH0jGSMMrI3VSmUk6wms0QZWQAs+Y5uGEEKyC8WIheh9I7LMNNZ0CYTCGPFHWl0TlcpItnNGNM+I9k+isSry2v2jXIJICCHZhGLEQi6Y3QiXw4ZjvaM40DWU78MpWoZ0S/IaqnJVGRkvRkSVJNuvTQgh5Q7FiIVUuhw4f1YjAGA9WzVpI1o0lS47Kl12ADmojATHT9O4FTFCQzIhhGQXihGLuVz4RhgNnzbCvFrrcaqVilxv7dX/PysjhBCSXShGLEZs8X3tSC/6R/x5PpriRFRGaiscmiAIZTmBVRhY9W2aHAkhQggpdyhGLGbyhErMb61BWAZe3Hc634dTlIj01ejKSHZbJVqbxqAykuUWESGElDsUI1lAjPhyi296DCoG1hqPI2eCwGiaRt2LE5IRDnM6ihBCsgXFSBa4fIGyxfftLgyMcCw0VbQ2jVNtlWR9UV4CzwjA6gghhGQTipEscNaUesxvrcGQL4gH/vZOvg+n6NC3aXJVGQkExyewutMUI2OBEF492IMgBQwhhJiCYiQL2GwSvnjlPADAT14+hE7vWJ6PqLgQS/JqKxxq2ySQowRWp0Mb7dULk1RMrD944QA++sNX8fi249YdICGElDAUI1nisvnNWD5tAsYCYXx3/f58H05RobZpdJURXxarDLIsG3pGJElKa6LmUM8IAOAUd9oQQogpKEayhCRJ+NJ75gMAHt16DIe6h/N8RMWDyBmp8TjVELJAKJy1iP2AbmxYL0aA9LJGRJsp2+PIhBBSKlCMZJFzpjfgsvnNCIVl3PvsvnwfTtGgzxlx2yMJrLIMBLM00aJPd9X7RABNjPhSECMDihjJdmosIYSUChQjWeaLV86DJAF/3HUSu08M5PtwioKonBGdhyNbJ3f9846rjKTRphFiimKEEELMQTGSZRZMqsW1S9oAAN98Zm+ej6Y4GFQNrM60TaSpIPwiNgmw26So27RpHvOha15WRgghJCUoRnLA2ivmwWGT8OK+03j5QHe+D6fg0QysDthtEiRFH2RrvNcofVWQaptGlmXV8+LPcjYKIYSUChQjOWBqYyVuWDEVAPCvj+9C3zB31sQjHJYx5NMMrOlOtKSC0V4aQaqvPRYIq6KJlRFCCDEHxUiO+OJV8zGjqQqnBsaw9tc7GS8eh0FfEGJopsbjAKAJgkCWplOM0lcFbmdqYkRUdfTPSwghJDEUIzmi2u3AfX9/NtwOG17Yexo/fOlgvg+pIBF+C7fDBo8zMkmTznhtKiRs04jKiElhIY5f/7yEEEISQzGSQxa21eJr15wBIGJm3Xq4N89HVHjozasCNYU1y9M0+skdQapCaEAvRlgZIYQQU1CM5JiPnjMF1y5tQygs459+uQO99I9EoTevCtLJ+kiFRJURd4pihG0aQghJHYqRHCNJEu7+4JmY2VSFDu8Y/uXXO7OWLFqMiDZHjUerjAgxkr3KSAIDa4pCSF8ZyZbHhRBCSg2KkTxQ7XbgvhvOhkvxj2w70pfvQyoYvAnaNNmbpolvYE11mkaM9eqflxBCSGIoRvLEgkm1+MDSSBjaTzcdyfPRFA5a+ur4Nk22Tu5GS/JiX9us/2OABlZCCEkZipE8cuPK6QCAv+w+ha7BsfweTIFgZGB1Kcvysj9NE9/AarZN4x2lZ4QQQlKFYiSPLGqvw9lT6xEIyXh0y7F8H05BoBlYx3tGsjWdEkhUGVEW9aVnYKVnhBBCzEAxkmdEdeSXm48aXkn/YMMBfPHxXQiWyVW2ZmDV2jS58ozEbuwFUg89Y5uGEEJSh2Ikz7znzFY0VrnQ4R3Ds291Rt32+GvH8D9P78Xj245j08GePB1hblErI1FtmuwmsPqV500cemZuUR4NrIQQkjoUI3nG7bDjo+dOAQD8dNNh9ftvnfTiP363W/3z5oPlEZCmekb0lRE168P85txUCJhYlMfQM0IIyR4UIwXADSumwSYBrx7sxb7OQXjHAvj8L7bBFwxjQmWkQrD5UPlWRtxZr4ww9IwQQvIJxUgB0FZfgSsWtgAAHnnlMP7t8ddxuGcE7fUV+MnqcwEAu44NYCyQncpAISHaHHoDqzPF/TCpIiojrgRx8Aw9I4SQ7EExUiCoRtYtR/H0mx1w2iXcd8PZWDK5Di21bvhDYWw/WvrhaIni4LMeepbIM2LitcNhGUM+zTMSCssIcTszIYQkhWKkQDh/ViNmTayCSIb/6vsWYumUekiShBUzGgGUvm9EluWEi/KyVRlJaGBNYax40BdEbLI/WzWEEJIcipECQZIk/OPFswAAH1jahk+cN029bcXMBgDAq3Emag51D+P3O08U/Y6bEX9IrSQY5YwEsh16ZhQHn0KbRowl221au4dihBBCkuNIfheSKz6ybDLOmd6AaQ2VkCTthCYqIzuO9WMsEILHaVdvC4dlrP7JFhzuGcHEajfOn92U8+O2CtGicdoleJyaMFATWPMSema+TSP8IhMqXege8pl+HCGElDusjBQQkiRhRlMVbLZoI+WsiVVoqnbDHwxj17H+qNs2HujG4Z4RAMDrJwZydahZQW9e1YuxXHlGjEPPzCewelUx4lSrIzSxEkJIcihGigBJktRWzeZD0b6Rn7+qLdnb1zGY0+OyGlEZ0aevArnwjCTYTZPCa4vjr6tw6oLaWBkhhJBkUIwUCefNEGJE842cGhjF+re71D/v7SxuMTJokDEC5KIyYsLAmkKbprbCqQobBp8RQkhyKEaKhBUzI76RbUf61BPjo1uOIRSWMbWhEgCwv2uoqEdJjTJGAE0kZKvKIJJdMw09047foZluKUYIISQpFCNFwpzmajRUuTAWCOP14/0IhsJ4dOtRAMDaK+bC47TBHwzjSM9wno80fbT01eg2Ta4qI4Y5IymM9urbNKqAChavOCSEkFxBMVIkSJKEc6drvpH1b3eh0+tDY5UL7zmzFXOaawAA+4q4VSMMoLGVkWwvylNDz4xGe5XX9plIv41u02TX50IIIaUExUgRoc8bEcbVjyyfArfDjrktQowM5e34MkUEnsUaWLNdGfGbWZRnpjIyqq+MiGkaihFCCEkGc0aKiPMU38jmQ73wB8OQJODvz50KAJjXWg2guE2sWhS8sWckL9M0Dq0qEw7L48au9QzoKjvOFPJJCCGk3GFlpIiY11KD+kqneoK7aM5ETG2MmFfVykgRj/eqBtCcT9MkT2AFkoshry7KngZWQggxD8VIEWGzSThH8Y0AwMd1kfHzWiNi5FD3MHzB4tzuKyoj1e7YnJHstjyEydTIwOpOQYxonhEHc0YIISQFKEaKjBVK3sikOg8unTdR/X5rrQc1HgeCYRmHuotzokZsvI31jLhT8G2kgxkDK5C8MhPtGRHHzGkaQghJBsVIkfF350zBh85ux39/eDEcuhOlJEmYp7Rq9hZpq2ZYESPjKyNZXpSXYDeNJEmm99PoPS/OLC/3I4SQUoIG1iKj1uPEvX+31PC2ua01eO1IX9GO9w4pnovqeNM0WQs9i29gFa/vD4UTihFfMISxQOT22gqnutyPbRpCCEkOKyMlhFYZKc7x3sEklZFsG1iNPCOAOTEkzLeSBNS4HVlPjSWEkFKCYqSEmNMSGe/d31V8lRFZlrU2TWxlJMujvWoCq4FnRP/6vkD81xfm1Rq3AzabRM8IIYSkAMVICSEqI0d7RzDiD+b5aFJjNBCCWKsTWxlx67I+skEizwigr4zEn1JSo+ArnVHPxcoIIYQkh2KkhGisdqOp2gVZBg50FVerRvhFbBJQ4bRH3SZO7KGwbPkiQFmWEyawApoY8SVoEw3ERNm7HMrWXhpYCSEkKRQjJcbcIp2o0ftFJCnaSKpvn1hdaQjqxE1cz4gJz4p+rBdgZYQQQlKBYqTE0HbURIuREX8QWw71QpYL08MwpO6lcY67TV+xSFSdSAe9WHA6jKdp3E4TYkSkr4rKCBflEUKIaShGSgyRxLpXtzAvGArjpoe24O/+bxMef+14vg4tIcK8WuW2j7tNP3JrdaVBpK8CJiojCadptPRVALqckcIUf4QQUkikJUbuu+8+TJ8+HR6PBytWrMCWLVtMPe7RRx+FJEn4wAc+kM7LEhMY7aj5wYZ3sPVwHwDg/hffsdx3YQXxxnqB1ILHUkUIDEkC7HGW4JnZjcM2jfX85Y1TuOCe57HjaF++D4UQkmVSFiOPPfYY1q5dizvvvBPbt2/HkiVLcOWVV6Krqyvh4w4fPox//dd/xYUXXpj2wZLkzFXGezu8YxgYCWDH0T58Z/1+AJEKw6HuYTz7Vmc+D9EQLfBsfJsGQNYWz+knaWK9KgK3CTEyzsDK0LOM+etbnTjRP4qX9nfn+1AIIVkmZTFy77334uabb8bq1auxcOFCPPDAA6isrMRDDz0U9zGhUAg33HAD/vM//xMzZ87M6IBJYmo8TrTVeQAAO4714bbHdiIUlnHNkjbcfGHkvX/wpYP5PERD1L00BpURQGvVWF0ZEXHt8Vo0gMnQszijvfSMpI/4nRjxF+fiR0KIeVISI36/H9u2bcOqVau0J7DZsGrVKmzatCnu477+9a+jubkZn/rUp9I/UmKauYpv5N9+8zqO9Iygvb4Cd31gET55/nS47DZsO9KHbUd683yU0Qwl8IwA2YuED6iVEeOqCJBa6JmojGhtmsJriRULwkc0WmSZOYSQ1ElJjHR3dyMUCqGlpSXq+y0tLejo6DB8zMaNG/HjH/8YDz74oOnX8fl88Hq9UV/EPCL8rGvQB0kC7v27JaircKK51oMPntUOAPi/FwurOjKkekaM2zTZioT3J9jYK0glDl71jKitHV7Vp4sqRgJ8DwkpdbI6TTM4OIhPfOITePDBB9HU1GT6cevWrUNdXZ36NWXKlCweZekhTKwA8PlLZmHFzEb1zzdfNAMA8OyeThw8XTjBaPGW5AlcWUphTRZ4pn/tRGPF6sZeZZpG84ywMpIubNMQUj6kJEaamppgt9vR2RltgOzs7ERra+u4+7/zzjs4fPgw3v/+98PhcMDhcOCnP/0p/vCHP8DhcOCdd94xfJ3bb78dAwMD6texY8dSOcyyZ8XMBrgdNpwzfQJuWzU36rbZzTVYtaAZsgw8+NKhPB3heJJ5RrI1TaPupUkkRuz2pK89PoGV0zSZMuyLiJBRihFCSp6UxIjL5cKyZcuwfv169XvhcBjr16/HypUrx91//vz5eOONN7Bz507165prrsGll16KnTt3xq14uN1u1NbWRn0R80yeUImt/7EKv7r5PMMr/s9cNAsA8Nvtx3F60JfrwzNE84wkq4xkyzMS/59CstAzWZbjjvYyDj59WBkhpHww/uRPwNq1a3HTTTdh+fLlOPfcc/Htb38bw8PDWL16NQDgxhtvRHt7O9atWwePx4NFixZFPb6+vh4Axn2fWEttnBFZADhn+gQsnVKPncf68bNNh7H23fNyeGTGJGvTiJO71Qmspjwj6mSM8UlxyBdUl/zVMmfEEmRZxrCfnhFCyoWUPSPXX389vvWtb+GOO+7A0qVLsXPnTjz99NOqqfXo0aM4deqU5QdKrEOSJPzjRZEx359vPloQIWim2zSWJ7CamKZJkjMiouBdDhs8ypI/F6dpMmLEH4LYXMA2DSGlT8qVEQBYs2YN1qxZY3jbhg0bEj724YcfTuclicVcsbAFNW4Heof9ePPkABZPrs/r8SRr02jx6tkLPYtHstCzgZFov4j++VgZSQ8xSQMAIwGO9hJS6nA3TZnisNtw3qzIlM3GA/lPuBxKEAcPZLEyYsForxp4VqEduxrSRjGSFkM6McLKCCk3wmEZT+8+hZP9o/k+lJxBMVLGXDgnMm69sQDitrWtvfEMrNmJVxeL7BKO9iYJPdOW5OkqIyYi5El8xCQNQAMrKT9ePdSDz/58O+74/e58H0rOoBgpYy6YHREjrx3uy+vVZzAUVk2KSSsj2TKwZhAHHzvWq38+tmnSI6oyEghBlum9IeVDlzcy5Vgo0465gGKkjJnZVIW2Og/8oTC2Hs5fPLz+KjiuZyRLbRo19MxEmybeJI8wsNbpKiPZCmkrF/SeEVm2foqKkEJmTLk485fR5wfFSBkjSZJaHXk5j76RIb82jRLPu5FsoiVdUtlNE9fAOhqdvhp5vuwYbsuF4Zh9NGzVkHJCVIrLaZ0ExUiZ8y7FN5LPNe2qXyROVQTI3nRKwESbxu1MnMAaG3gG0MCaKfo2DQCMcFkeKSOEGCmnyirFSJkjKiNvnfKieyi9/uQ3n3kbn37ktbSFwpAvcjKPF3gGJB+vTRdRBjVjYI07TUPPiOUMx4iRMQafkTJiTDHLl5MBnmKkzGmqdmPBpEjc/ivv9KT8eO9YAPdveAfP7enEGycG0jqGQaUyUuUyUxmx9kohpdHeuJ4Ro8pI5DFhGQURKldsDPmixQfbNKSc0DwjFCOkjHjXbCVvZP/plB+75WCvGoV+qn8srdcXBtZElREzm3PTwczW3mRVGe9oREwZjfYCrI6kQ2xlhGKElBNiurGcPGcUIwTvmjMRQCRvJNURyk0HtWrKqYH0AnpEmya/nhETcfApjPbqDbHldHVjFbFihMFnpJwQnhFfGX12UIwQnDu9AS67DScHxnCoezilx27StXZOpJkWOJhkSR6Qi2kaE56RVNo0Nu35yqnvaxWxBlYuyyPlxJhqYA2XTcYOxQhBhcuOZdMmAEhtxLd/xI89HV71z+m2aZLtpQG0yoXVlRG/ksBqxjPiizNmZzTaa7NJcNiyc8zlANs0pJwRYkSWgWCZeM4oRgiA9EZ8Xz3YC71oT7dNM5xkYy+QvcqImUV5+gCzcMwHQyAUVk+U+spI1OOC5fFhYiXCRyQp3a5RjvaSMkJfCSyXixmKEQIAeJcy4rvpYA+CJn/5X1X8ImdPrQcAnMiwMhIvCh5I7ttIl0AKCaxGry/GegGgxhMtRrKVGlsOiN+Jxio3AFZGSHkxptuDVS5tXooRAgBY1F6HugonBseCeN3kiK7wi3x42WQAQPeQL24rIxFmPCPOLO2mMWNgdScSI2OakLLbop8jW6bbckAksDZVuwBQjJDyQm/YLpeLGYoRAgCw2yScPysy4vvHXSeT3r97yIe9nYMAgKvOaIXHGflV6hhIvToybMozkp0Tu6k2jT2+GTXRtuFs+VzKAfE7MbEmUhlh6BkpJ/S/76yMkLLj+nOmAAB+/uqRpFM1okUzv7UGjdVutNVVAABOptGqGTLhGXFmq01jIvRMkqS4EzWDIj3W4NidDlZG0mUoRoywMkLKibEoz0h5eM4oRojKJfOaccm8iQiEZNz9pz0J7ytaNCuVasqkeg8A4GQa471m2jRue3bMoGZCz4D4BtqhBMeutZbK48PEKoKhsNozpxgh5cgoKyOk3PmPqxfAbpPw3J5ObEwwWSPCzlbOjIgRURlJZ6LGzGhv9iojymivWTES8/qJzLc0sKbHsE54TKyOiJHRAKdpSPnAaRpS9sxursEnzpsGAPj6U28aTtZ0esdw8PQwJAlYMUNURiJiJJ2JGlOjvVk2sCatjMR5fbXFlMgzUiZXNlYhfh+cdkmN2GcCKykXZFmOmqaxegVGoUIxQsZx26o5qK90Yl/nEH615ei424Vf5Iy2WtRVRk4W7UqbJtXKiCzLWnXBzDRNlgysiTwj+ttjp4UGx+JXRlz0jKSF3tBc6bIDYJuGlA+x4oNtGlK21Fe6sPaKuQCAe5/dh4GRQNTtql9EadEAwCTVwJqaGPEFw2qrxEzOiPUJrKIyEn+0V//6sR8UWpvGOe4xbNOkh9q2c2lihHHwpFyIrQKWy8UMxQgx5O/PnYq5LdXoGwngnqf3RLm7Vb/ILE2MtCltmlQj4fU7SKpcRdimMWFgLRc3vFWoW5zdDlQ4I+8rKyOkXBiLqb6WS2Uk/qc/KWscdhu++r6F+MSPt+BXW47hdztO4sI5TVgxsxFHekZgt0k4Z3qDev82pU0z6AvCOxaI2mCbCLUk77LDZku+Odf6rb3Jd9MAgNuZxDOSwMBaLlc2ViG2OFe57VplhGKElAmsjBASw4VzJuIr712AtjoPRgMh/PWtTtz11FsAIomt+vjzSpcD9Yp/JJXqiJmxXkBroxjth8mEgNnR3jgtl0TH73Iw9CwdhpTKSJXbgQq2aUiZEfu7Xi5tXlZGSEJuvmgmPn3hDLx50ovn9nTi2bc68dYpLz6iRMDrmVRXgf6RAE72j2Jea42p5zezlwaIrlwEwmG4bfYUfor4pGpgHV8ZSRB6lqXWUqkzrPudqHAKAytHe0l5oJ+kAcrn84NihCRFkiQsaq/DovY63LZqLkJhedweFiAyUbPnlBcnU5ioGUowjaLHGRPJ7nZkLkZkWdbFwSc2sLrjihEToWdlcmVjFUMG0zRjgTDCYTlhK4+QUiB29UG5fH6wTUNSxkiIAOlN1IiFaMnaNIn2w6RLKCxDlsc/v+Hrxws9GzPhGWECa0roKyOVOlMzWzWkHBjnGSmTygjFCLGMdCZqEuV06LHZJDhsmm/ECvTPk2nomZGYcjNnJC30YkS/MZlihJQD5eoZoRghliEmak6kUBlJlNMRSzzfRrro/5Gb3U0TmzOSSEw5ubU3LfQGVptNUn0jnKgh5UBsm6ZcogEoRohlqJWRAfOVEc0zktwDYrUHQy9q0gk98wfD6p9rGHpmGVplJPI7wRRWUk7EihHGwROSIpPqtEh4s+O3ZqLgBVZXRkTFwmW3QZKSiBG7fdxrD+sD2wzEFHNG0kP4iMTixAoXJ2pI+RDbpimXzw+KEWIZLbUe2KRIWbF72GfqMSm1aSw+uQdMTtIAxqFn4tgrnHY4DNo8alAbDawpEbvFWW3T0DNCyoByHe2lGCGW4bTb0FwTqY6cNGliTRSnHku8iZZ0UcVIkowRQB96pp0QkwW20TOSHsMx2TNMYSXlxDgDK8UIIakjTKynTJpYh3ypeEaUk7tVBlalYpFsrBcwbhElioIHtDaNj2IkJYZ1BlZA36ahGCGljxDdonNcLhczFCPEUiYpJlazEzXpTNNYdXL3m1ySBxiHnqnpq3ErI6JNUx4fJlYRK1BF1ggrI6Qc8AW1RZEAKyOEpEV7ihM1ZuPgAetP7gGTUfD6++hbRMkyUqz2uJQDsixryxNpYCVliBDdYtlouUzjUYwQSxETNWZTWM3GwQPxl9Wli7YkL7mB1Sj0LJmQ0jYN08BqFl8wjKAyiTXewFoeH8qkvBGekdoKRYywMkJI6oiskZOpVkZSMLBaVWlIpU1jlDOSzHzLnJHUiRqXdsUaWIu3MmLlpmlS2ohpmlrlc6VcKqsUI8RS2lLYTxMOy9pumlQqI5YZWFNv0/hSMrBymiZVhHm1wmlXdyAVu4H1hb1dWPyff8VTr5/M96GQIkBURuoq2KYhJG3ENM3pQZ9qxIrHSCCkLqqrMVEZ0SoN1u6mMVUZMRBCSUd7uZsmZWIzRgCg0hn5/5EizRl55UA3hnxBvHygJ9+HQoqAsZg2TbnkFFGMEEtpqHKpkyedA4mDz0Sbw26TohaixSObCazJcDvHJ7AmmwRycWtvymiVMm3Uu8IVeR/HirQyIkQrDbjEDKoYUQys5RINQDFCLEWSJJ1vJHGrRh2NdTuSxrED2fSMpGBgDaXuGWFlxDxGlZEKxTtSrG2aQeVn0vthCIlHbJumXKIBKEaI5ZidqBHbWc34RQBdm8biykgqBtao3TR+c56Rcll0ZQWxY70AUKlUpYq1TSMqI8IPQ0giRv2KgbVCyRkpk4sZihFiOWa394rKghm/CKAFj1lWGUnBwGoUepYsZ4SVkdSJjYIHin+aZmgsUgFkm4aYwRfTpuFoLyFp0qZURpKlsIo2TZXpykik0pAPz4hR6FmysWSrxVM5MBQTBQ8AHldxL8oTonWIbRpigtickXL5/KAYIZYjKiNvnfQmvF+yykIs1i/Ky2yaJllgm1YZoYHVLMMGu4rUNk2RekaECCnW4ye5IxDSQv/qGHpGSGZcMq8ZTruEncf6sfVwb9z7DacQeAZY7xkRz+N0mDfPGi7KSzLaWy49XytQPSMufZumuHfTsDJCzDKmq/7RM0JIhrTWeXDdsskAgO8/fyDu/ZKFhsWSrWkalz35xmB9VSYclhEOy0nj4PWhZ7LM6ogZjKdpircyov89GfGH+HtAEiJaNJKkCXJWRgjJgM9dPBt2m4QX953G68f7De8zaHDiSYTVCayBNCojQESQDOvMiPEqO+J4ZRkIMQ7cFIkNrMUnRoZ0vyehsMzJKpKQMWWSpsJpLzvPGcUIyQpTGytxzZI2AMB9LxhXR1JZkgdYv3gupdCzGDEirnZddhvcDuPKit6LQt+IOQwrIyJwLhRGsMg+mEWLRsCsEZIIURnxOO3q511YRtH93qcDxQjJGp+/ZBYkCXjmzU7s6xwcd/twEs9FLOLkbtXVpT8NAysQqcwkCzyLfd5yKbVmiiZG9Ams2v8X20TN0DgxUlzHT3KL8IxU6MQIUB4XMxQjJGvMaanBVWe0AjCujiTzXMTisji3QzWwmhAjkiRFtYkGTRy7Ptm1XExomTJsEITndtig7MwrulbNoJIxIhhm1ghJgFYZsZXdxQzFCMkqt1w6GwDwx10ncbh7OOo2UcI2nTOSrd00JkLP9PeLqowkOHZJkkp+c693LIC7nnorri8oVYwSWCVJUidqis3EOhjTlmHwGUmEvk3jsEkQWzLK4WKGYoRklUXtdbh03kSEZeD+De9E3ZYsNCwWqysjmmckuYEViJ6oMXvsVh9zofHXNzvx442H8L0EU1OpEK9a5nEWZ/BZrGdkiG0akgCfrk0TuZgpn3gAihGSddZcNgcA8MSO4zjaM6J+fzjl0V4lgdViMWKmTQNET/OoUfZJjt1Z4o74gdFIG6Jv2G/J8xlVRgBtoqbYKiOxnpERGlhJAoTYFj4pt7r5uzQ/P/RQjJCss2zaBFw4pwmBkIwvP/E6wsqYq9HkRCJEHohloWcpGFgBrTLi03tGklRGtKC20jSgiZOrN8YbkQ7hsIxhv/HyxGId7431jDD4jCRCLMkTE3rlFJxIMUJywl3XLkKF045X3unBLzYfAZB6HLy6m8YyA2vkxOZM0TPiC4ZMjyWXeptGbNL1jmZ+ktVv5Y19X7Xgs+I6mceKj2Kr7JDcMhZTGbE6W6mQoRghOWF6UxW+dNU8AMC6v7yNd04PqSO6Zkd7jSLZM0GMy5nJGdHfzx8Mq0v+komRUjewWlkZES0amxSZJtBTUTKekeISUyS3qG0a5fffaXFrupChGCE548aV07FiRgNG/CHc+ugO9fvmt/ZmycBqIoEVANxOvRgxVxmxep9OoSHaKiP+UMZ/L/q2nSRF/50Ua5smVqQVW2WH5JYx3TQNwMoIIVnBZpPwzeuWoNJlx+4TkY2+bofNtGfDbXFlJJWcEUD3wRAKay0ms56REr2y0YuD2CpAqhhFwQsqinS0V7Tz6isjG1gZekYSoQ89A6y/ACtkKEZITpnaWInb3zNf/bPZFg2g/4dpjRnUn+o0jSONyojFEfaFhj7EyzuaWasmkaG5ssjbNK21HgCMgyeJGY2pjFh9AVbIUIyQnHPDimlYObMRgPkWDZANz0hqoWdug9CzZGLKXeJXNiOWVkYiz2X0O1HsBtbWOkWMFNnxk9wipmk8rIwQkn1sNgn/c91iLGqvxYfPnmz6cfqWhxWr2APBFA2sRqFnbmfCxwgDWql+mOjFQaYmVq1NM37xYIXqGSmu91GM9mqVkeKq7JDcMhaMNrDq4wRKHfOXpYRYyJSGSjz1Txem9JjYxVFmjafxyCT0LGXPSIl+mOgrI5a1aVyJ2jTFVVkQP1OLIkaKrbJDcsuYP2a0t8TbvHpYGSFFg76CYUWlQfOMpBYH70tjmqZUP0xGdFf61lVGErVpiquy4B2LbtMwDp4kItYzUuoXM3ooRkjRoK+MWPGPM+VpGgMxkswzUuqhZ9EGVmumaQwNrEU4TeMLhtTfsZZaNwBWRkhixo32lvg6CT0UI6RosNskdZW8Ff84xXO4zSawKnH03tEAQkqkvdnQs1K8spFlOWq0N9PKyFBCA2vk72isiKZp9Htpmms4TUOSMxqIfE5UMGeEkMLGKkNXKCxD0RPmc04UU1mPshROkrQwrniUcs6IPxRGMKy1nzL1jCQ0sDqLrzIiqmeVLjvqKpgzQpITN/SsBD8/YqEYIUWFVaNu+seb3k2jvHbvsA9ApCoSmxQaSylv7Y1NQ810tHfIn6hNU3yekUHd+LeaIBsIqVU1QmIR/6bU0DNH6VZWY6EYIUWF26ItlvrKSqoG1p6hSGWkxkRGSil7RoZjhIFVBtZEYmS0iDwX4v2odjuifib6Rkg81NFepS2pbiovwc+PWNISI/fddx+mT58Oj8eDFStWYMuWLXHv+8QTT2D58uWor69HVVUVli5dip/97GdpHzApb9STezCzq8uoyogttdCzXqVNk2ysFyjt0bxYYWCVgdXIhyPK1sVUGdGC8ZxwO2ywK4YntmpIPERlxBNTGQmwMjKexx57DGvXrsWdd96J7du3Y8mSJbjyyivR1dVleP+GhgZ85StfwaZNm/D6669j9erVWL16NZ555pmMD56UH061MpLZB3pAN9Zrs6VWGekbUcSIicpIKRtYY0+q2TSw6tscxYK+TSNJEqqUn4EprMSIcFhWK7ZqHDw9I/G59957cfPNN2P16tVYuHAhHnjgAVRWVuKhhx4yvP8ll1yCD37wg1iwYAFmzZqFW2+9FYsXL8bGjRszPnhSfmju8gwrI8rjzZpX9a8tqhzVnsTpq/rnL802TWxlJHsGVjHaW0xbe2PHv4XI4kQNMULfOuaivCT4/X5s27YNq1at0p7AZsOqVauwadOmpI+XZRnr16/H3r17cdFFF8W9n8/ng9frjfoiBLBuOiXVJXnA+B02ZjwjpfxhIoSBmBTxWrS1N9FummBYLpoqk4iCr1FWBmhipHgEFckd+qpfbM5IOcTBpyRGuru7EQqF0NLSEvX9lpYWdHR0xH3cwMAAqqur4XK5cPXVV+N73/serrjiirj3X7duHerq6tSvKVOmpHKYpIRRPRgZ/uNMNfBM/9oCM22a2GpKKSEMrGLvypAvaHpS5FD3MB5++VBUaydhHLxuhLpYqiODotIjKiNFuuyP5AYhRlx2zV9Uyp6zWHIyTVNTU4OdO3di69atuPvuu7F27Vps2LAh7v1vv/12DAwMqF/Hjh3LxWGSIsCquftUA8/0ry0wY2AtZc+IMLA2K+miQHTQVyLW/XkPvvbHt3Dl//4Nf9t3GoFQWL36MxJ5TrsNDuUDulh8I4Njxm2aIbZpiAFaxoj2OaPFwRfH73wmpLQor6mpCXa7HZ2dnVHf7+zsRGtra9zH2Ww2zJ49GwCwdOlS7NmzB+vWrcMll1xieH+32w232214GylvrIpHDqS4lwYA3M5oL4MpA6tFo8iFiGg31Fe6UOG0YzQQgncsgLrK5F6a00ORrJZTA2O48aEt+MDSNvU2ozYNEGnVDI4Fi6ayIISZ+D0pxkh7kjtGY5bkAayMxMXlcmHZsmVYv369+r1wOIz169dj5cqVpp8nHA7D5/Ol8tKEANDEQ6Y91LQ8IzH3TbaXRv/8JekZUa7kKp121FZE3osBkyZW4Q+5YHYjAOB3O08CiLzHse0wQbEFnwnPSK1HeEaUaRpWRogBsemrQHnFwadUGQGAtWvX4qabbsLy5ctx7rnn4tvf/jaGh4exevVqAMCNN96I9vZ2rFu3DkDE/7F8+XLMmjULPp8Pf/7zn/Gzn/0M999/v7U/CSkLrKqM5Moz4i7hBFZxUq1021HrcaLT6zM93iuqBl+6aj5G/CF88Te7cKx3FBOq4ldVIpUFX9G1aarHTdMUx/GT3DIWs5cG0D5zSrGyGkvKYuT666/H6dOncccdd6CjowNLly7F008/rZpajx49CpsuRGp4eBif//zncfz4cVRUVGD+/Pn4+c9/juuvv966n4KUDVat1BZlT7NR8MB4f4k5z4g1IW2FiKhQVLrsqBUTNSaDz4Z0kzOLJ9fj6VsvwsOvHMa8lpq4jym24LNxo73MGSEJGDWojFj1eVcMpCxGAGDNmjVYs2aN4W2xxtRvfOMb+MY3vpHOyxAyDqs9I+4sV0ZKeVGe8G5UuhyoVU64ZiojsixrJ2q3VjW45dLZCR+nRcIXhxgZ1CWwAswZIYkZNTCwqpWRMhAj3E1DigrRQ+0YyMxzpBpYHeYNrOl5RqSo1yslhnWVEXHCNRN8NhYIqxuT45lVjdBSWIvjZD6o200DaCPLFCPECOEZqYiqjJTu50csFCOkqFjUXgcAeOjlQ/i/F99J+3k6BsYAGGdaxGN8ZST51EgpL8oTFYoql0M1sJrZ3Dvoi5ykJSk6PyQZFUXUptFXf2pjPSNFcPwk96hiRPdvwqrFoMUAxQgpKv7+3Kn4zEUzAQDr/vI27v7TWwinsZL9xX2nAQDnzWw0/ZhxYsRMZaSEy6yxBlbAXJtGGDirXZGdLWapKKI2zYg/pFZ/NAMrQ89IfNQleY7xnhEuyiOkwLDZJPz7exfg3987HwDw4EuH8K+P70qp8jDsC2Lr4V4AwMXzJpp+XCaekVLMCVBHe1M0sA7FTJmYpZg8I6JCZLdJakVHVOGGOE1DDBDTNB6DnBFWRggpUD5z0Sz8v48sgd0m4YkdJ3DzT18zfcX5yjs9CIRkTGmowMymKtOvOW6aJpWtvSX4YaJWRlyOlCojQwl20CSiwqmEhhXBaO+QT/OLiOpPpaiM0DNCDBg18IyUU84IxQgpWj68bDIevHEZPE4bNuw9jY89uBk9Q8mNrRv2dgEALpnbnFKbQG9grXTZ1f0RiSjlnJHo0V5lmsaEgXXIF51MapZiqox4Y6LgARpYSWISxsGX4OdHLBQjpKi5bH4LfvHp81Bf6cSuY/247oFNONY7Evf+siyrfpFLUmjRAIAkSaogMXsiLeWeryZGHNo0jQkD63CaYqSiiBbNDY6N/xlpYCWJMJqmcTMOnpDiYdm0CfjNZ89He30FDnUP40P3v4LdJwYM7/vO6WEc7xuFy27DylnmzasC0cM163coZc+IljNi13JGTFRGBtMVI04x2lv4wk74YkT7CoiOg5fl0vt9IJmRKPQsFJZNb8QuVihGSEkwu7kaT3z+fMxvrcHpQR8++sNXse1I77j7iRbNuTMa1MVlqSDESE2KlRF/KFxSJyB/MKwKrMhobyrTNOl5RrQ2TTFURiLvQ1SbRvl5g2G5LMruJDXUaRqDOHigNFu9eihGSMnQUuvBrz+7EufNbMCQL4gv/ub1cf+A023RCNQ2jcnKiN5nEiyhKxu9b6PCpY32DvmCSUethwz8FGaoKKJFeaovRvczVupOMtxPQ2IxMrDqd2dluhy00KEYISVFrceJH964HA1VLhw8PYxfbj6q3jbqD2HzIWWkd26aYsSRomdEl/BaSo74ESUF1WmX4HLYVGEhy8BQksqFNk1jPvAMgFrJKgYxYmRgddhtqjmRJlYSi08synONT2AFWBkhpOio9TjxhSvmAgC+/dw+DIxESuabDnbDHwyjvb4Cs5ur03puTYwkT18Foq9sSunDRFzZC4HgcdpVs10y34g2TWPuPRSonpEiECNqlkrMz6hO1BRBq4nkFqPdNHrTfCldzBhBMUJKko+dMwVzmqvRNxLA91/YDwDYsDfSorl43sSURnr1iA8Gsy0Gh278t5R8AnrzqkDbT5P4RKtN06RWGVETWIsgZ8TIMwLol+UV/s9AcouRgRUon2V5FCOkJHHYbfjK1QsAAA+/chhHeoZVv0i6LRoAcDtTa9NIkqTbNFw6nhF9xohAzRpJYmI18lOYobIIPSOxYqSyiMaTSW4xGu0FymdZHsUIKVkumdeMi+ZORCAk49ZHd+JIzwicdgkXzG5K+zlTNbDqH1NKWSPiZKqfiKk1ublX9YykOM1UXNM0xmJEq4wU/s9AcstYksoIDayEFDFfee8C2CRg57F+AMDyaQ0p51voSdXACpTmlY2oTuiv4rTx3iQG1jR306hbewOhgh+THozji2GbhsRj1ODfFABdZbV0Pj+MoBghJc281hp87Nyp6p/THekVLJ/WAJfDhiWT600/phQjnUeUk2l0ZSTy/4NJ2jTpJrCK15Llwm/VxPWMKNUdGliJHlmWMRYcP00D6D4/WBkhpLj5whVzUeN2QJKAy+Y3Z/Rct66ag9fvfDfOnFxn+jGlmMIqTqYVLoPKSBIDa7oJrJUubWKnd9if0mNzTfI2TWGLKZJbAiEtYdXjiKmMlODnhxHp16sJKRKaqt14/HMr0TPkx5yWmoyfL7anm4xSdMOLykRV1DRNcgOrLMtpV0YkSUJTtRsn+kfRM+zHlIbKVA87Z6jBbuNGe7VIeEIE+gkxjyu6RqB+foRKW8BSjJCyYH5rbd5euzQ9I2K0NzUD62ggBBHQmqpnBAAaq10RMWJiO3O+CITC6sklbmWEbRqiw6f8vtik6NRmALqckdKujLBNQ0iWKUnPiOFob/L9NGKSxiaNN+qZobHKBQDoGSrcNo2+6hEruDhNQ4zQR8HHZiCV4ueHERQjhGQZZymO9iYwsCbyjIj2RZXbkVbwXEOVGwDQPVy4lRHhF/E4bVEJvIDewFraJXeSGvECzwDdNE0JfX4YQTFCSJYpydAzg4AmM5URYdxMd7y6qTpSGekt4MrIYJwoeACoVH7uEVZGiI4xZS+NkRhhZYQQYgmaG750PkxGDJbdCc/IYIKckUFfRKikK0YaFTHSU8DTNGKst9bAE6PupuE0DdGhZoy4xosRN3NGCCFWIAyspXRlo432GrRpTFRGqtIVI6JNU8AG1kRx90K80cBK9IwZLMkTqJ8fbNMQQjLBWSSVkZ9tOoxHXjls6r6jBqO9Ws5IIG5C6pDPOAzMLA3VhW9gjZcxAtDASoyJt5cGKJ84eI72EpJlnEVgQOsf8eOrv38TADCnpRrnz0q8v2dYnaYZP9obliO3G7VihkRlJMW9NIImpTJSyKFnavqqgWdEbdPQwEp0JDKwFsvFTKawMkJIlnEVgQHteN+o+v/3/OVthMOJzbajBqO9kemRSEk5XtZIuntpBJpnxFew+2kGzbRpWBkhOsxM07BNQwjJCC30rDBPngBwsl8TI68fH8Cf3jiV8P7D/vEGVkmStOCzOL6RdNNXBQ1KzkggJCddyJcvzLRpRvyhpIKPlA/xluQBXJRHCLGIYlh0JcSIwxYRTt98Zm/C41W39sa0W5LtpxnKUIx4nHb1sYWawqpFwcefpgG08WhChB/EUIwUweeHFVCMEJJliuHK5uTAGADgI8sno6najaO9I/jl5iOG9w2EwuoHY1XMKGKyzb1DPi30LF1Eq6ZQfSPaxt7xnhGP0wZF7zFrhKiIyojRNI3W5i3tShrFCCFZphhyRk4olZHZzTW4bdUcAMB3nz9gKCpGdObL2FyEmiRtmkw9I4AWCd9doBM1iUZ7JUlSqyNDBSZGugbHCtaHU+qonhGDnBEnPSOEECtwFsEKcNGmaa/34PpzpmBmUxV6h/344d8OjruvuIpz2KRxS71qKxJHwguvSbU79b00gsbqyERNT4FGwnsTeEaAaN9IofCbbcdx7t3r8bDJ0W5iLQlHe4vgYsYKKEYIyTLFEOcsxEhbfQWcdhv+7ap5AIAfvXQIXd6xqPsOqxt7xy/1Sra5V5g70x3tBQp/WZ5a/YnTiqoswImaHUf7AAB/2d2R5yMpTxKO9rIyQgixAqdDmaYp0A8TfzCMrsFIlaGtvgIAcOUZrTh7aj1GA6FxV8ujBhkjgmT7aYYTtDDMUvCeEV98zwigzxopHDFyWvn733msX71KJ7kjUWXEzcoIIcQKCj1npNM7BlmOGG1F1UGSJHzgrHYAwIGuoaj7C0FRadBqSba5N9NpGqDwI+FF9cdoNw2gzxopnJO+EKP+YBi7jvXn92DKELEoz0iMiIuZQv38sAqKEUKyTKEnKKotmjpPVNulXamSnNBlkADaSGqlgdkuWWXEEjFSwJHwsiwnNelqy/IKrzICAFsO9ebxSMoTUW10G07TRP6dlXocPMUIIVlGyxkpTAPryQHNL6JH/PlkrBjxxW/T1CRYlifLcsahZ4BWGSlEA+tYIIygEmYWt00j9tMUiIFVlmWc1lWZNlOM5JzRBG0aLTSRYoQQkgGFnjNysj9iUI0VI+0TIn/uGwlgROdvUNNXjSojygl40CAddTQQgggdtcIzUoiVkd6RyDE57RIqDU4sQOFFwntHg1HmyG1H+gr2d7VUUT0jBv+mGAdPCLGEQr+yOdFvXBmp9TjVFFF9dcSUgdVgmka0L2yS8RWgWYQY6RvxI1RgkeqdyuRRc40HNptkeJ9sG1j3dQ6m5Kc5PRQ55hqPA/WVTowGQnjjxEBWjo0YM2ZiN02hfn5YBcUIIVmm0HMC9BkjsbSpvhFtvFc/2huLtptm/IlWn74aOxKcCg2VETESliPbhgsJMQbdUuuOe59Kd/Y8Ix0DY3jPd17CJ3+yxfRjurwR4dJS68E50xsAAJsPslWTSwZGxQTWeIHPOHhCiCU4CzzO+WScygigtWpO9BlVRowMrGKaJjAuzdMK8yoAOOw21FdGRE9PgY33dgwIMTJe2AlE4NtIFqZpDnYPIRSWsa9zyHSaqvCLTKx2Y8WMiBjZcqjH8mMjxgRCYfSNRMTIxOrxIlarjBTm54dVUIwQkmVEaFEh5ozIsqwKDSMx0qZUS/RtGjGSWmkgKkRlJBiWVVOewCoxAugj4QvLxNo5qFUZ4lGZxTh44aPxB8Omn19M0kysceO8mY0AgNcO9xVcC6xUEX9ndpuECUrVT4+4mOE0DSEkI4RnpBBzArxjQXWqo63OSIyMn6gZDShtGoP+dqXLDrvilYjNGhGekUyW5AlEJHyhBZ91epNXRoSBNRtx8PpNxmYNviJjpLnGjQWTalHjdmDQF8SeU17Lj4+MR4jBxiqXoc+InhFCiCUUsmdEiIwJlU5DJ7/IGjlusjIiSVLc8V7hNYm3syUVmgp0okbzX8T3jGTTwKpvW5kdfdZXRuw2CcunTwAAvHqQrZpYwlmoFonq3sQa498ZekYIIZaghp4V4IdJIr8IoIkRfWVkJMFoLxB/P82QBXtpBGrWSIG1aTpMVUayZ2DVbzI2u9W4a1CZAFIE1AqlVcO8kWh+tukwzvzaM9h2xNr3RYjBJgO/CMDKCCHEIowMrEO+IH699Rj68txmODlgnDEiEAbWjoEx1UMg2gtGlRRAu8LriFmwN6RUVDLJGBE0CM9IwbZpElRGVDFSGG0atTJSHRFQ5yom1q2He7NSCShWnn+7C8P+EF61eNLodJLKiPj8CIblkv77oBghJMvEXtl4xwK44Ueb8W+/fR3//fTb+Tw03VivsRhprvHAbpMQDMvqFbTwmMSrcExRBMzR3pGo7w8pC+SsMLCKNk1vAbVpRvxBNewtYWVEEXHZaNPoPTRmq0b6Ng0AnNlehwqnHf0jAezrGrT8GIuVDqUFZ/UFROz7H4v4/AAK03dmFRQjhGQZvWdkyBfEJx/aoi4je25PZ16vdrQ2jfHJ026T0FobPVEzmiBnBACmNlQCAI71RsfIi0qAJdM01YUXCd+pnKwqXfaEP6OojGRjtDfaM5L8pOkPamOlzcrJ0Gm3Ydm0iG+Ee2o0RIZMv0GgXyaIyki8No0wwAMUI4SQDBBbN33BMD750BZsP9qPugonKl12dA/58Xoe0y6TeUYAXdaIEnyWyMAKAJMVMXK8L7oyMmjlNE1V4RlY9ZM0iULdREXJHwpbbkrUjzqbGXsW93HaJTW7BYCaN8Lwswj+YFgVd1YH7XUnq4zYdZWRAvSdWQXFCCFZRvR8Q2EZrx3pQ63HgV98egUunjsRQKQXnS/i7aXRo27vVfJIRH5IPAPrlAmiMhItRtQleRZ4RkQkfCHljJjxiwBApVt730YsbNX4gqGonUBmhFqX6hdxRwkozcTaYzo8rZQRLUoAaiXJKrTKyPiMESAyoVbIE3lWQTFCSJZx6q5sajwO/OxTK7CovQ6XzW8GADz/dmdejisYCqsmU6OMEUFs8JkQFfEMrFMaRCVlNCo4Sws9S38vjUBM03jHggVztaiPVU+E025TfQBGCwXTJTZzxUwLK55fYfHkOrjsNnQP+XG8b9TooWWFaMEB2auMNMepjAC6rKIC+V3PBhQjhGSZKpcdrbUe1Lgd+Ok/nIslU+oBAJfMa4YkAbtPeNWr6mS88k43/t9f96q7LDKha9CHUFiGwybFLREDQHt9pNIhxIVIgoxnYJ1UVwGHTUIgJEdN1GhixGn4uFSoq3Cq4Wp9BbKfxsxYr0DEfuuvuDMlthJipjIST4x4nHbD9N1yRf/vs9/CyshYIKTucYrnGQHKY7yXYoSQLOOw2/DMbRdh45cuw1lTJ6jfn1jjxuLJ9QCAF0y0aoZ9QXz2Z9vwvecP4CMPvKJu200XcZJprfOoJ3Yj9CclfVshXmXEbpNUn4m+VaMtysu8MmKzSdp4b4G0arSNvYnbNID+PbVQjCiVESEsek1sNRZiaGLNeAE1SamWnRygGIkSIwZ7l9JF79mpq4gv0sshEp5ihJAcUFfpRF3l+A+by5VWzXoTYuTx146pV1H7Oofwwftexu4MzK8nTJhXAWDyBK3tIjJG7DYJbkf8jw8j34ho79RYUBkBCs/EKto0rXXJKyPiRH/KwhO9GOWdPbEakgTIcvKqUaKxUm0VgHWCqVjRt2lCYRmDFgXWiWC6WM9OLOWwLI9ihJA8InwjLx/oxlgg/qhnKCzjoZcPAwBuuXQW5rZUo2vQh+v/bxM27E3PAHtKCTyLlzEiECfOwbGgeoVY6bQn/PAUvpGoysiYdZURQDOxFsp4b+eg+TbNpGxURpQTW3OtW124lkyodSXwK4jqjZWCSeAPhvH68X78bNNh/Muvd2HVvS9i+TeexevH+y1/LSuIbaP2D1vTqlHTV5NU08ohEp5ihJA8ckZbLVpq3RjxhxLGb//1zQ4c7R3BhEon1lw6B49/9nycP6sRw/4QPvXIa3hi+/GUXztZxoigyu1Qxz73dw4BiJ4IMWKKyBpRzI+yLGPIb900DaCPhM9NZcQXDOFjP3wV9/xlfFCdLMvoUMRdi0HLI5a2LFRGuofFwjW3rmqUWKglqoyobRqLKyMDowFc+D/P45rvv4yv/v5N/Hb7cRzoGkL3kB/PvZUfM3cyYsWIVT4ldS9NAr8IQM8IISTLSJKkTdXsif9B/KONhwAAHz9vGipcdtRVOPHw6nPxobPbEQrL+PJv38CbJ1Nr2ZjJGBGI6smB0xExkmy/TGybZsQfgmizWxF6BugrI7kRI7tPeLHpYA8e2nho3EnBOxpU+/nNSUZ7AWCS0soRAsYKhChrrHZpo89J3pvEbZrsGFjfPDGATq8PLocNF8+diH++fA6uXdoGIHohYyERu9rAquCzZHtpBE5WRggh2eay+S0AgOf3dhka47Yf7cO2I31w2W34xMpp6vddDhv+30eWYNWCFvhDYfzzr3ZgNIW19CdMZIwIxH32d0biweOZVwVaZSQiRoRfxCYBFU6L2jQmr/6tQlQx/KEwDnUPR90mWjT1lU54TPx8qh/DUjGi5VWoCbUJ3htZltWToXGbZvySRCsQXqUVMxrwyD+ci7VXzMWl85qz8lpWIfxAQkRaNd6bbGOvQFRGmMBKCMkaF8xuhMthw7HeURzoGhp3+49eOggAuHZpG5pjWgCSJOF/rluM5ho33jk9jLv+9Jbp11UrIwkyRgSiMrK/y1xlRETCd3p9GAuEVMNflduR0GuSCtoJNzeVEX0VY88pb9RtauCZiRYNoJlcu4d8ll3tipyRxio3mkyYe72jQfXkZnRlLk683rGgOgllBcKrpP+9a9eZpAuNIZ/2889tqQFg3X6aZHtpBMwZIYRknUqXAyuVxMvYqZpjvSN4encHAODTF840fHxDlQv3/t1SAMAvNx9V75+IIV9QzSpJ5hkBNDEilt8lq4xMqHSqCa3H+0Z1kzTWtGgAXWUkR20avXfi7Y7oBXJCqJhp0QCRY3c5bJDl8X6EdOmOatMk390jxnrrKoyrOTUeJ2oUf88pC0WCUXtQ/H6d6h9LOo6ca8TfT7XboYqmXLdpXI7I3w89I4SQrHL5ApHGGi1GHnr5EMIycOGcJsxrrYn7+HfNacI/XhQRK19+4vWkXgRxcqnxOFDjST5qK04coouUbCJGkqSoVs2QhXtpBLleltfh1U7Ib8dURsRUSquJSRog8v6IyoMVrQlZltX3obHKrYvLjy/UzFyVt2ehnSSea5JOBLfUjt8OXSio+TG1bkxQjNxWBZ+ZbtPQM0IIyQWiZ77lUC9W/Ndz+PD9r+DWR3fg11uPAQBujlMV0fMv756HRe216B8J4LbHdmD70T50DBhfaYpyeLKxXkFs9aQySZsGACYrJtbjvSNa+qpFkzRA/JyRA11D2HG0z7LXESSqjHSmkL4qEGLklAUn+hF/CGOByImqsdqlmzRKVBlJPslhpWASnDT43TPaDl0oiL/b1lqPOjJt1TSNVhkx3ksjcCnLNkvZM2LdJwMhJG2mNFRi1YIWPLenE51eHzq9Pmw7EjmhzmupwYVzmpI+h8thw3c/ehau/u5GvHqwFx/6wSsAIh/0LTVuzGutwXkzG7FyVqM6cmvGvApoPX1BZZI2DaD5Ro71jaoVEasmaQBtmmbEH8KoP4QKlx2Huodx7fc3YiwYxrNfuAgzJ1Zb9nr6atOpgTH0j/hRr5yczC7J06ON92YuRoQg8zhtqHTZ1ZNbohaWal5NcMxtavvEGoEgy7L6XJNiwuHaJ1TgRP8ojveNYtk0o0fnh07dziGRkmpFZWTEH8SwYjhnZYRihJCC4cEbl6FvJIDjfSM43jeK430j6B7y44NntZs2fc6cWI0HPrEM339+P070jaJT2T9zcmAMJwfG8MLe0wAA8XRm/CIA0FTlhstuU6/MzFRGRPDZ0Z4RTFHEjJVipNrtgMthU9a7+9Bs8+Cff7VD/YD/7fbj+OKV8y15rWAorLYPqt0ODPmCeLtjEOcpXp8Orzixp1AZsTBUTJ8xIkmS2sISS9iMOG0i48LqqR/vqHYCjhXCk+srsAWZmVhlWcah7mFMbaiEw25N4V/Nj9FVRqyYpuke1ARksn8X6mgvKyOEkGwjSZF9Kw1VLnVnTTpcPHciLp47EUAkufX0oA8n+kex42gfNr3Tgy2HetXplnmttaae02aT0FbvweGeiIHVTGVEzRrpG8Ggrw6AtZ4RSZLQVOXCyYEx9Az58cgrh/HGiQHYJCAsA09uP4F/uWIebAn27pila9CHsByZalgxowHr3+7C26e8qhjp0pXyzWJlqFivUhkRFRFRNRrWVY1i6dJ5IeJhddaI2HPTUOUaZ5pVJ2oy2BL83J4u3PzT1/Dpd83Af7xvYfoHqqNrUKt6TahSKiMWGFhPD2nm1WQXG2roWbCwzL1WQjFCSAljt0lorfOgtc6DZdMm4NMXzkQwFMabJ704NTCmBq6Zoa2+IiUxMrVRCz4bVjf2WvuR01AdESNPbD+ORzYdAQB856Nn4StPvoGTA2N49WAPzp+dvMWVDFG9aKn1YGFbbUSMKL6RcFhW/RfpeUYyP9Gr5lWlylHjdqiVrJ5hHya7Ksc95rQJ8+QkC1tJQOLUXytyTYRXaOex/rSfIxbRpmmt9aCuQvGMWDDBZXasF9BXRsznCBUbNLASUmY47DYsmVKPqxa1qldcZtCX1c0ZWCP3944F1at/q8WIMGoKIXLjyml4/5I2vG9JJNHzN2nE5BshTsaT6jyYr1ST9ihipGc4sh3XJiU3Iuqx8kQvpmbEJuNIqyZx1ogI8ppYHV9AtdVpAsGKTbXqJI1Bto0wtGbSphGj5yJszwq0sW2POk3jHQsimGHLRF8ZSYabi/IIISSCfvrBzLK7SpdDPTmLkDArp2kArR0BAPNba/Dv710AAPjw2ZMBAE/v7lCrMplwql87ic6fFBmx3tvhRSgsq+bVpmp3Sj4FUR3oHfYnXJJoBn0UvCDZIkFxMkzUpmmpc0OSIqvrey2oBhhN0gj0bZp0hY9YPyDC9jJFluWoNo0wsAJQN2inS3c6lZE0DKxbD/emvCoiH1CMEEJM0Z5iZQTQxntFsqyVnhFAu6r0OG343sfOUn0IZ0+tx4ymKoz4Q/iLiRA4AAlPgPrKyPTGKrgdNowFwjjSM5zWWC8QCRsT0fiZVkeE4Giq0k5sompklDXiC4bUiZBEBla3w66+x1Z4W+JN0gDa79ewPwTvaHon+qO6LdHHM/CeCHqH/Wo1ornGA4fdpgbBZTrem0plJN04+N5hP/7+wVdxw482F1yYXCxpiZH77rsP06dPh8fjwYoVK7Bly5a4933wwQdx4YUXYsKECZgwYQJWrVqV8P6EkMIkuk1jbr+MGO8NKh+E1SYqKqlw5RktmNlUhW9etwRzWrRQOEmS8KGz2gHA1EbjY70jOOuuZ/G1P7xpeLvwdUyqi4RziQC6tzsGdaOf5sd6xTFaNVGTsDJiIEaEQHHaJXUjczy0iZrMT+4nE+xD8jjtanbM8f7U2yzesQD6dCO3VrRqxN+tSMwFYNlETS4qI/s6BxEIyegfCVi6ITobpCxGHnvsMaxduxZ33nkntm/fjiVLluDKK69EV1eX4f03bNiAj33sY3jhhRewadMmTJkyBe9+97tx4sSJjA+eEJI79FkjZsWIGO8VVLuTp72mwrJpDXj+Xy/B+xWPiJ4Pnh0RI5sO9iT1Ifxh10n0jwTw1OunDG8XlYtWxeswX4iRU15dQmdqlRFAlzWSYdVB5Ik06q6ymxIsyzutCzxLNsnRZmHwmRA08UbKM5moOdYbLT6O91ohRsZXveotSmE1M1otUKdpUqyMHDytLXSMXe5YaKQsRu69917cfPPNWL16NRYuXIgHHngAlZWVeOihhwzv/4tf/AKf//znsXTpUsyfPx8/+tGPEA6HsX79+owPnhCSO/SldbNtGjHeKzDjNbGKyRMqsXJmI2QZeDJJdeSl/ZH8le4hn+GkxKmYk6jexNqZxlivwKqJGiE4RGVB//9GwWdirNfMVbkafJZhKykUllUzaLywvUxMrLFi5JgFbRqjMLt6NYU1MzGiRcEnNz270lyUd/C0tnjzcCmJEb/fj23btmHVqlXaE9hsWLVqFTZt2mTqOUZGRhAIBNDQ0BD3Pj6fD16vN+qLEJJfPE47lkyuQ63HMS6RNR5iP42gxuLKSDI+vCxiZP3t9hNxPSHDvqCadgtEStt6AqGwtntGEQ/CxPp2hzet9FWBGreewYk+HJa1jb26No2ojHQbVUbUE2FyAWVVJHz3kA/BsAy7TRq3fVrQnsF479EYMXK0x7o2jb4you2nSb9NI8uyrjqV/O9A9YykKEb01ZBD3dZNGGWDlMRId3c3QqEQWlpaor7f0tKCjg5zJrEvfelLaGtrixI0saxbtw51dXXq15QpU1I5TEJIlvj1Z1fipS9dZnpEd2pD/iojAHDVolZUOCMx8TviZE9sPtQTNTK5r2so6vauQR9kJfBMGERFZeRY7yjeUUrh6bRpJlkQt+4dC6ienIYqc56RVDIuMhEIekS1o1VZimdEWwaVESFGFkxS/m4s8Ix0GLVpLIiEH/IF1V1CTWYqI2kaWA9GiZGhBPfMPzmdprnnnnvw6KOP4sknn4THE/8f7u23346BgQH169ixYzk8SkJIPNwOe9R4YzKE4VNg9WhvMqrdDrxnUSsA4DfbjFs1f9vXDUCLyN8fUxnp0AWeiTTXhiqXWgkRJ8EWE1WGWBIty7vvhQO44UevJh2pFWbUGo8Dbocm9poSbDUWlZ5mE2JkkkVtGm08Ov77lIln5Ghv5DEXzIqk4sa2bdKhy9AzkvmyPPF3VuWym2p5pmNg9QfDUdWiwxZUirJJSmKkqakJdrsdnZ2dUd/v7OxEa2trwsd+61vfwj333IO//vWvWLx4ccL7ut1u1NbWRn0RQooPh90WdfKxOvTMDNcprZo/7jyJEf/4kdG/KX6RVQsiFd/YNo06ARIT1DU/Jkq/NcFJNh7xUkfHAiF8d/1+vHygB99dvz/hc/TEGRHVV0ZiW1SpVEaET6bTO5ZR0JeWvhq/xWeFZ+T82REx4h0LYiBDX4eojLTWae/TBAsMrKm8/4C2KC8VA+uxvhE1jA+IiOZUDbC5JCUx4nK5sGzZsijzqTCjrly5Mu7j/ud//gd33XUXnn76aSxfvjz9oyWEFB2iVWOToOZq5JLzZjZiakMlBn1B/PmN6Hby8b4RHDw9DLtNwifPnw4A2N8ZXc7uUCdposWG8I0AkRbOhCQjskYIoeYdC0aFs716sAc+5Sr4F5uPJPQ/qH6Rquhyv2jZBMPyuNyOrhROhk1VbjjtEsIy0Jlg8V4yxCTNpATLGUVqb/dQakFwobCM40pbZl5rrSrMMm3VCM+I3uMiKiP9o5lURsxnjACAM402jZikmd9aiwqnXXmPCne8N+U2zdq1a/Hggw/ikUcewZ49e/C5z30Ow8PDWL16NQDgxhtvxO23367e/7//+7/x1a9+FQ899BCmT5+Ojo4OdHR0YGiosPtXhBBrEBM1VW6H6e3DVmKzSbj+nIjv7LGtR6Nu27g/0qJZOqUeZ02tBxCZPtGPw8Y7iS7QVUaaazxp/Ww1HidqlGqRvg2yQdmuDEQiwP/fs3vjPke3gXkViLTUREBXd0yrpjuFNo1N2W8EZOYbSZS+KqircKpj46m8Vod3DIGQDKddQmutRx0pz6RVE1D2+gDRQlSM9vYN564y4ranvihPTNLMaq7GNGVPVCFP1KQsRq6//np861vfwh133IGlS5di586dePrpp1VT69GjR3HqlDarf//998Pv9+O6667DpEmT1K9vfetb1v0UhJCCRZwYavLQohFct2wy7DYJWw/3qWmwAPCSIkYunNOESpdDPdZ9uuqIqIxMqo1fGUmnRSMwCj57cV9EjPzTZbMBAL/feRK7TxhHeqtjvQZX2VrWiHYVHzXJYfJkqN9Rky6nEuylEUiSlFarRlSOJk+ohN0mRW2MTpfTinHZYZPQUKkJPStCz3JZGZnRVIUZTVWR75WSGAGANWvW4MiRI/D5fNi8eTNWrFih3rZhwwY8/PDD6p8PHz4MWZbHfX3ta1/L9NgJIUWAGO+1Ogo+FVpqPbh0XmRD8a9fixjiQ2EZGw9ExMhFcycCAOY2RwTG/i7NN6Iud4u5op/ZVA2nkv+QzlivoDUm+OxIzzAOdQ/DYZPwmYtm4tqlkUC3/376bcPHq+mrVeOnMtSsEV2l59TAmHpSM3sy1Lwt6ZtYE23s1ZOOiVVUQMTvmhCVseO+qaCG2dW4VeMyoAs9G829ZyQVA6sY6501URMjJVUZIYSQVFg5qxHt9RW4alFik3u2+ajSqvnttuPwB8N448QABkYDqPU4sLi9DgDUSHm9ibVDFwWvx+WwYdbEagCIm5thBjXhVHkd0aJZPn0CajxO/MsV8+C0S3hpfzdeVsSTHtFKMBQjSuumWzeR8+c3IpXrZdMmqLt8kh5jhrH1Y4GQOkESawSOJZ1RYiE6pioiRPiUjvWmX8lR82Ni/t6FZ2TEH4IvmN4yvlTFiDpNk0plRBnlndlUjelCjPRQjBBCypTmGg9e/vJl+Jd3z8vrcVwybyKaa9zoGfbjuT2deElphVwwu0ndtju3JSIuRJtGH3hm1F5YMrkeANSefDpMiqmMbNjbpRxvpJIztbESN6yYBgC45y9vIxyz8Kx7aHwUvKDRIBL+j7tOAoBacUnlGNOtjIhWl8dpM70L53haYkSpjCRo0wyMBPDpR7biyR2JU3nVwLMYoVnjdqgTKulO1KTapkk1Dn5gNKD+XkxvqtTaNKcpRgghJK847DZ8ZHlkzPfRrcfUkd4L50xU7zNXqYzs7xxU1sdrgWdGlYd/efdc3HXtGfi75ekHMwrPyMmBUYwFQnjlnR4AEfEkWHPZbFS57HjjxAD+vDt6f45R+qqgqUob7wUipftdxwdgt0l475mTTB9jpsFn2k6aiqRG38lptGnGiRHlv8f7RseJtyd3HMdze7rwrWf2JXxObaw3WozYbJI2UZOmGMl2m0a0aJpr3KjxOFUxIn7HChGKEUJI2SBEw0v7T2P70X4AEfOqYNbEakhSZO9I95BfTUZtrfNE+QYEzbUefGLl9Iz8MKJt0TEwpo70ttZ6ME+3hbip2o3PXDQLAHDvs/ui1sHHyxkBdJURpZUjqiIXzG4yfVUOGJtsUyFeVosR6RhYYz0jImzPH9QqWwIh9k70jyacttEWII5/n9SJmjRMrLIsq1WLJgMBaUSqlRExSTNzYkSENFa5UON2QJatCYPLBhQjhJCyYVpjFc6fFVmeFwrLmNFUFbU/p8JlV6+u93cOahMgteZ28aSDdqIfU/0il8ybOK6C8KkLZ6CuwomDp4fxzJuRvJRgKKwubEvoGVGCz36/M7It/VqDLceJEK2TvpEARv2pX1mfMmleBTQDa8fAWJToiseQL6guAxR/lw67TX0tfasmFJbx6sEe9c+bD/XGfd4upU1jtABRi4SPFiPdQz5885m31cqHEd7RYMoGYk2MyGqlZywQwr8+vgs/e/XIuPuLdsxMxdMkSRJmTCzsiRqKEUJIWSEyR4DoqohgTrNmYj1lIqgrU4QxdsgXxF+UFozwi+ipdjtwkxLMdt8LByDLMnqVk6EkacZKPY1VmmfkrVNevHN6GG6HDe8+o2XcfRNR63Gq6bkn06iOqFktJiojzTUeOGwSgmEZXYPJPSriSn9CpRO1Hs2PovpGdJWAt0564R3TAuA264RJLEZ7aQQT4rRpvv/8Adz3wjv41jPxc2FOD0Wet9bjMG0gFlNbgGZi/d2OE/jNtuO466m3MDgWfRyaebVK/d70xsKeqKEYIYSUFVee0aqW2S/S+UUEqom1a0itjGSSI5KMSpdD3ffT6fXBYZNwgRJpHsvq86ej0mXHmye9eHHfadUL0lDpMlw+J9oAPcN+/GFnpEVz+YJm1HhST4sVlYZ0fCOiTZMo8Exg14WsmfGNxPpFBEKM6Md7X3knMo0k/v4TVUYSbWPW9tNEiwCxjHHDvq64W6JPDyotGpN+EUCrjABaq+ZXWyMj6v5gGOv3dEXdX6uM6MSIIkwOGYiRn796BBv2dpmqRGULihFCSFnhcdrxgxvOxpeumo/L5o+vQOhNrOpytzQ28qaCfmxYjPQaMaHKhb8/dyoA4AcvvKNljMTxHgjPSP9IAL9XxMg1S9rTPMboqZ9UEALGbIUpFd9IrF9EoKWwas8h/CKrz58BmxQRKkY+mBF/EINKBcWoMqJmjejaNP5gGHtOegFEROWeU4PjHgcApxWPz8QUPDtOm3aq9gfD2HPKi126LdRPva6ZmsNhWR3hndlUrX5/ZhwxMuwL4r/+vAef/MlW7Iyz2ToXUIwQQsqO82c14XOXzDI0pc7RjfdqbZrseUaA6OVxRi0aPTdfNBMuuw1bDvfi6TcjJyHRjomlvsKpjqF2eMdQ43ZETemkdoxKtSLFyogsy6aW5OlRg890rzXiD2Lj/u5xy/riVkYaosd7/cEwth6OVELefUYLFinZMpsPjq+OiFHkSpfdcLmj0bK8vR2DUTkgG/Z1jXscADUB2EjkxMNmk9RWTSAk49EtkbUGCyZFVhL8bd9pDCghbJGJmTCcdkmdTAIQN2vkz2+cwog/hBlNVThbWYmQDyhGCCFEx6yJ1bBJkayGvUr4WaK191agf/5kYqGl1oPrlBHlX22JlOrjVUZsNgkNOqFy1aJW0z6FWMQkTKrL1rxjQQwrplcz0zSArjKivNbuEwN43/c24uM/3oyvP/VW1H2TiZHjyu27jvdjxB9CY5UL81pqsGJGAwBg86HxvhFhJJ7TXG04iqy1abTKyK7j/QAi/h39c+iRZRlPKRNNqYpCEXzmHQvgyR0RI/KX3zMfc5qr4Q+F8dxbnQC0ysfUhko1PwcAZiiekU6vL2op42+2RfJWrls2OS+7owQUI4QQosPjtGOa8sE9Fohc6ZoxXmaCqBjEjvTG47MXzYJNgtrjTzSVoR8fvSaFoLNYFk2OVBKe3n1KzTYxg6guTah0osJlTggJMXK8bxQ/3ngIH/rBK6oP4tEtx9TKBZDcM3LKOwZfMIRXDkREx3mzGmGzSVgxI+LLia2MyLKMxxQ/xnXLJhseX71BZeR1RYy8f3HkPd52pA/eGGPpGycGcLB7GB6nDe8+I7VEYuEb+f3OE/COBdFeX4ELZzfh6sWRvJg/Kcm6sZM0grpKp7rJWVRHjvaMYPOhXkgS8MGz0mvfWQXFCCGExDCnWfsgjxd4ZiUXzmmCTQI+ft5UU1enUxsrcY1uPLchwfGJqklTtRsrZxobY81wydyJWNRei2F/CA+8+I7px6l+kRQEnWjTvLjvNO566i34Q2FcsbAFS6fUwx8K44d/Owgg4o84rnhCYj0jTdUuVDjtkOWIgVaYV8+fFXkPzpnRAEmKjLp2eTVxs+NYP/Z2DsLjtOGapcYnaHWaZlQTZa8fjywyvHrxJMxsqkIoLOPl/dHx/cK3s2pBi2H7JxGiMvKoUg27/pwpsNkkvE8RIy/tP42BkcC4jBE909XtvREB99vtkarIu2Y3mW6hZQuKEUIIiWFuS/RGXiNviZUsnlyPvd94D265dLbpx3zuEu2+8do0gBZn/r7Fk6LK9qkiSZIa6f/IK4ejTuCJUAPPUjjZ6aduXA4b7rr2DPzwE8vwhSvmAgB+ueUIeoZ86ByMLP1z2KRxrTRJklQT6/7OQexQQu7OnxUZ566rcGJBa8RzoZ+qEX6M9545SZ1yikULPYtUPkb9IexXvCBLJtfjYqUFo2/VhMKyLoo/9SqESGHtGfbDJkFNE57dXIP5rTUIhGQ881aHmiOiH+sVaBM1QwiHZVWMxKsA5RKKEUIIiUGYWIHsBp7pcdptKfXs57XW4ENnR05qS6fUx73fP148CzeunIZ/vnxOpoeIS+ZOxLJpE+ALhvH9Fw6YeozZbb16pjZU4sz2OpzZXoc/rLkAn1g5HZIk4aI5TVg8uQ5jgTB+vPEQjvZErvDbJ1QYCi3RqvndzhPwh8KYVOdRqwMAsGJmtG9kcCyAP+6KtDs+es7UuMenxcFHwuTePDmAUFjGxBo3Wmrdqgn5xX2n1RHfVw/2oGvQh7oKJy6em7qJWD/ee+m85qhK09VKtP+fXj8Vt00D6CdqIu2Z432jqHE78O6F+V1iCVCMEELIOPSVkWwGnmXKN69bgm3/sQpntNXFvc+81hp8/dpFCVs5ZolURyLViV9tOYrjBovoYhFZLalURhx2G/6w5gL88Z/ehflK9UK8vqge/XTTEbxxItIaifWLCETr5lnF3LlyVmOU4Iv1jfxx1ymMBkKYObEK50yfEPf4xDRNICRjxB/CLqVFs2RyHSRJwooZDfA4bejwjqkm6N8pptP3njkpSliYxaUTWx89N1ooCd/Iywe61YC5RJWRwz3DqnH1fUsmmfbyZBOKEUIIiWHmxCo1RCybgWeZYrdJhtt6s8n5s5pwwexGBEIyvrt+f8L7jvpD2KK0QPRjpmaIVyW6YkEL5rXUYMgXxH1KdSbWLyIQ3w+EZPXY9ZyrTNTs7xpCz5APj22NtGg+es6UhFWqCqddFQd9I37VvLpY2eLscdpVf86GvacxFgjh6d2RCP8PpGkiFgKmpdaNS2MmcWZOrMbCSbUIhmXIciTd1Uh8ihTWfZ2DatpvIbRoAIoRQggZh9thxzSlnG92HLWcEN6R324/oRomjfj+C/txon8Uk+o8uDRJfopZbDYJt1wWqY4Iz0bcykiMAFo5K9rA26CM+QIRH8yu4wNw2iV8+OzEJ2hJkqImaoR5dfFkrUIlWjUb9nbhhbe7MOgLYlKdB+dMbzD1c8biVsTIR5ZNMWxJvW+JtoV55kTjkWSxvXdwLKjLFolfAcolFCOEEGLAFQtb4HLYsDxBub5cOXvqBFw+vxmhsIxvP2dcHdnfOahOvXztmjMy2mwcy9VnTlJPrEDyNg0QmSQxiqMXvpH7lQmhdy9sNVVtEhM1R3tH1GwPURkBtByR1w734RebIxWXa5a0pW2G/uQF03HFwhasvmC64e3CNwIYT9IAQJXbgWZdDH2+s0X0UIwQQogBt79nAV6/890J/RjlzFrFO/LH10/iyR3Ho26TZRlf+d1uBEIyVi1oxrsXpraYLxl2m4TPXTJL/bMZMbJy1viliIDmGxGtHP0ixUTUKZWRl/afVl6rIqo1Mq2xCjOaqhAMy9h4IDLim84UjeB9i9vw4I3L4wqlaY1VOFNJlZ1lYF4VCN9IIWSL6KEYIYSQOKSbVloOnNFWh4+fNxWyDHzhsV24f8M76uTIb7Ydx5ZDvahw2vG1a87IytX3B89qx6L2WrTXV2B2s/HJt9qteSfOn2WcsXLODK3y1V5fgXfNNhYtsQgT69/2RYTG4vb6cffRT83Maa7GgknJA+0y4Y73L8SVZ7SoY79GCGNrIWSL6LGubkYIIaSs+Po1i1DpcuCHfzuI/376bXQMjOKfLp+D//rzHgDAbavmYPIE46pFpjjtNjzxuQtgt0mGG4sFt1w6G5sP9mDVAuPqTHONB7MmVuGd08NqkJgZRJtG7M/R+0UEl8ybiIdfOQwAuHZpW9ZbIudMb0jqSblhxTQc7B7GF6+cl9VjSRWKEUIIIWlhs0n49/cuQGutB3f96S08sukInnr9FPpGApjfWoN/eNeMrL6+mRHZT71rBj6V5Di++r6F+MsbHfhkHD+GEaJNI9D7RQTnzWxErceBEX8ooxaNlZw5uQ6//seV+T6McVCMEEIIyYh/eNcMtNZ5cNtjO9Gj7K25+4OL1AjzQueSec1JtyXHIiojQMR/caZBZcTjtOOxf1yJ0UAo7vgxiUAxQgghJGPee+YkNFW78dXf7cb7Fk/CsmnpjbAWCxN0lZFZE6vj7ppZMKnW8PskGooRQgghlnDujAY884WL8n0YOaGuQquMGPlFSGoURw2NEEIIKSD0lZHF7RQjmUIxQgghhKTIBF2myOIEiwqJOdimIYQQQlJkYrUbNiky0bOQvpCMoRghhBBCUmRClQs/uGEZaj0OhuNZAMUIIYQQkgZXLWrN9yGUDPSMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr1CMEEIIISSvFMXWXlmWAQBerzfPR0IIIYQQs4jztjiPx6MoxMjg4CAAYMqUKXk+EkIIIYSkyuDgIOrq6uLeLsnJ5EoBEA6HcfLkSdTU1ECSJMue1+v1YsqUKTh27Bhqa2ste14yHr7XuYPvde7ge51b+H7nDqvea1mWMTg4iLa2Nths8Z0hRVEZsdlsmDx5ctaev7a2lr/YOYLvde7ge507+F7nFr7fucOK9zpRRURAAyshhBBC8grFCCGEEELySlmLEbfbjTvvvBNutzvfh1Ly8L3OHXyvcwff69zC9zt35Pq9LgoDKyGEEEJKl7KujBBCCCEk/1CMEEIIISSvUIwQQgghJK9QjBBCCCEkr5S1GLnvvvswffp0eDwerFixAlu2bMn3IRU169atwznnnIOamho0NzfjAx/4APbu3Rt1n7GxMdxyyy1obGxEdXU1PvzhD6OzszNPR1w63HPPPZAkCbfddpv6Pb7X1nLixAl8/OMfR2NjIyoqKnDmmWfitddeU2+XZRl33HEHJk2ahIqKCqxatQr79+/P4xEXJ6FQCF/96lcxY8YMVFRUYNasWbjrrruidpvwvU6Pv/3tb3j/+9+PtrY2SJKE3/3ud1G3m3lfe3t7ccMNN6C2thb19fX41Kc+haGhocwPTi5THn30UdnlcskPPfSQ/Oabb8o333yzXF9fL3d2dub70IqWK6+8Uv7JT34i7969W965c6f83ve+V546dao8NDSk3uezn/2sPGXKFHn9+vXya6+9Jp933nny+eefn8ejLn62bNkiT58+XV68eLF86623qt/ne20dvb298rRp0+RPfvKT8ubNm+WDBw/KzzzzjHzgwAH1Pvfcc49cV1cn/+53v5N37dolX3PNNfKMGTPk0dHRPB558XH33XfLjY2N8lNPPSUfOnRIfvzxx+Xq6mr5O9/5jnofvtfp8ec//1n+yle+Ij/xxBMyAPnJJ5+Mut3M+3rVVVfJS5YskV999VX5pZdekmfPni1/7GMfy/jYylaMnHvuufItt9yi/jkUCsltbW3yunXr8nhUpUVXV5cMQH7xxRdlWZbl/v5+2el0yo8//rh6nz179sgA5E2bNuXrMIuawcFBec6cOfKzzz4rX3zxxaoY4XttLV/60pfkd73rXXFvD4fDcmtrq/zNb35T/V5/f7/sdrvlX/3qV7k4xJLh6quvlv/hH/4h6nsf+tCH5BtuuEGWZb7XVhErRsy8r2+99ZYMQN66dat6n7/85S+yJEnyiRMnMjqesmzT+P1+bNu2DatWrVK/Z7PZsGrVKmzatCmPR1ZaDAwMAAAaGhoAANu2bUMgEIh63+fPn4+pU6fyfU+TW265BVdffXXUewrwvbaaP/zhD1i+fDk+8pGPoLm5GWeddRYefPBB9fZDhw6ho6Mj6v2uq6vDihUr+H6nyPnnn4/169dj3759AIBdu3Zh48aNeM973gOA73W2MPO+btq0CfX19Vi+fLl6n1WrVsFms2Hz5s0ZvX5RLMqzmu7uboRCIbS0tER9v6WlBW+//Xaejqq0CIfDuO2223DBBRdg0aJFAICOjg64XC7U19dH3belpQUdHR15OMri5tFHH8X27duxdevWcbfxvbaWgwcP4v7778fatWvx7//+79i6dSv++Z//GS6XCzfddJP6nhp9pvD9To0vf/nL8Hq9mD9/Pux2O0KhEO6++27ccMMNAMD3OkuYeV87OjrQ3NwcdbvD4UBDQ0PG731ZihGSfW655Rbs3r0bGzduzPehlCTHjh3DrbfeimeffRYejyffh1PyhMNhLF++HP/1X/8FADjrrLOwe/duPPDAA7jpppvyfHSlxa9//Wv84he/wC9/+UucccYZ2LlzJ2677Ta0tbXxvS5hyrJN09TUBLvdPm6yoLOzE62trXk6qtJhzZo1eOqpp/DCCy9g8uTJ6vdbW1vh9/vR398fdX++76mzbds2dHV14eyzz4bD4YDD4cCLL76I7373u3A4HGhpaeF7bSGTJk3CwoULo763YMECHD16FADU95SfKZnzxS9+EV/+8pfx0Y9+FGeeeSY+8YlP4Atf+ALWrVsHgO91tjDzvra2tqKrqyvq9mAwiN7e3ozf+7IUIy6XC8uWLcP69evV74XDYaxfvx4rV67M45EVN7IsY82aNXjyySfx/PPPY8aMGVG3L1u2DE6nM+p937t3L44ePcr3PUUuv/xyvPHGG9i5c6f6tXz5ctxwww3q//O9to4LLrhg3Jj6vn37MG3aNADAjBkz0NraGvV+e71ebN68me93ioyMjMBmiz412e12hMNhAHyvs4WZ93XlypXo7+/Htm3b1Ps8//zzCIfDWLFiRWYHkJH9tYh59NFHZbfbLT/88MPyW2+9JX/mM5+R6+vr5Y6OjnwfWtHyuc99Tq6rq5M3bNggnzp1Sv0aGRlR7/PZz35Wnjp1qvz888/Lr732mrxy5Up55cqVeTzq0kE/TSPLfK+tZMuWLbLD4ZDvvvtuef/+/fIvfvELubKyUv75z3+u3ueee+6R6+vr5d///vfy66+/Ll977bUcN02Dm266SW5vb1dHe5944gm5qalJ/rd/+zf1Pnyv02NwcFDesWOHvGPHDhmAfO+998o7duyQjxw5Isuyuff1qquuks866yx58+bN8saNG+U5c+ZwtDdTvve978lTp06VXS6XfO6558qvvvpqvg+pqAFg+PWTn/xEvc/o6Kj8+c9/Xp4wYYJcWVkpf/CDH5RPnTqVv4MuIWLFCN9ra/njH/8oL1q0SHa73fL8+fPlH/7wh1G3h8Nh+atf/arc0tIiu91u+fLLL5f37t2bp6MtXrxer3zrrbfKU6dOlT0ejzxz5kz5K1/5iuzz+dT78L1OjxdeeMHwM/qmm26SZdnc+9rT0yN/7GMfk6urq+Xa2lp59erV8uDgYMbHJsmyLtaOEEIIISTHlKVnhBBCCCGFA8UIIYQQQvIKxQghhBBC8grFCCGEEELyCsUIIYQQQvIKxQghhBBC8grFCCGEEELyCsUIIYQQQvIKxQghhBBC8grFCCGEEELyCsUIIYQQQvIKxQghhBBC8sr/B/LgpZMmd+5zAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(0,100),losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlmrIf1bEZLp"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork2, self).__init__()\n",
        "        self.stack = nn.Sequential(\n",
        "            #start your code\n",
        "            nn.Conv2d(3,32,3,1,1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,64,3,1,1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(36_864 , 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512 , 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24 ,2 )\n",
        "            # end\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJtcX-ow-5z1",
        "outputId": "3b9e4de4-16b1-4e47-8d5e-37882f9c3e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork2(\n",
            "  (stack): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Flatten(start_dim=1, end_dim=-1)\n",
            "    (6): Linear(in_features=36864, out_features=512, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=512, out_features=24, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=24, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model2 = NeuralNetwork2().to(cuda)\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgUORhmv-5z1",
        "outputId": "759f2420-a1db-48d1-e0a1-6b99246a0d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.694249  [    0/ 3009]\n",
            "loss: 0.695396  [  400/ 3009]\n",
            "loss: 0.658555  [  800/ 3009]\n",
            "loss: 0.684262  [ 1200/ 3009]\n",
            "loss: 0.652700  [ 1600/ 3009]\n",
            "loss: 0.727973  [ 2000/ 3009]\n",
            "loss: 0.589608  [ 2400/ 3009]\n",
            "loss: 0.593111  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 0.673495 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.593506  [    0/ 3009]\n",
            "loss: 0.638055  [  400/ 3009]\n",
            "loss: 0.682097  [  800/ 3009]\n",
            "loss: 0.634624  [ 1200/ 3009]\n",
            "loss: 0.711995  [ 1600/ 3009]\n",
            "loss: 0.697354  [ 2000/ 3009]\n",
            "loss: 0.563267  [ 2400/ 3009]\n",
            "loss: 0.740802  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 0.637627 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.627057  [    0/ 3009]\n",
            "loss: 0.582832  [  400/ 3009]\n",
            "loss: 0.586425  [  800/ 3009]\n",
            "loss: 0.622320  [ 1200/ 3009]\n",
            "loss: 0.622441  [ 1600/ 3009]\n",
            "loss: 0.666410  [ 2000/ 3009]\n",
            "loss: 0.565490  [ 2400/ 3009]\n",
            "loss: 0.467114  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 76.0%, Avg loss: 0.539224 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.368287  [    0/ 3009]\n",
            "loss: 0.843852  [  400/ 3009]\n",
            "loss: 0.504653  [  800/ 3009]\n",
            "loss: 0.626153  [ 1200/ 3009]\n",
            "loss: 0.310698  [ 1600/ 3009]\n",
            "loss: 0.274011  [ 2000/ 3009]\n",
            "loss: 0.522293  [ 2400/ 3009]\n",
            "loss: 0.398830  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 75.3%, Avg loss: 0.501105 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.534751  [    0/ 3009]\n",
            "loss: 0.934636  [  400/ 3009]\n",
            "loss: 0.314031  [  800/ 3009]\n",
            "loss: 0.420808  [ 1200/ 3009]\n",
            "loss: 0.532421  [ 1600/ 3009]\n",
            "loss: 0.646403  [ 2000/ 3009]\n",
            "loss: 0.319501  [ 2400/ 3009]\n",
            "loss: 0.262016  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 0.481203 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.495014  [    0/ 3009]\n",
            "loss: 0.259319  [  400/ 3009]\n",
            "loss: 0.192231  [  800/ 3009]\n",
            "loss: 1.328971  [ 1200/ 3009]\n",
            "loss: 0.392813  [ 1600/ 3009]\n",
            "loss: 0.672435  [ 2000/ 3009]\n",
            "loss: 0.505624  [ 2400/ 3009]\n",
            "loss: 0.546431  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 0.466279 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.330353  [    0/ 3009]\n",
            "loss: 0.291563  [  400/ 3009]\n",
            "loss: 0.880172  [  800/ 3009]\n",
            "loss: 1.320387  [ 1200/ 3009]\n",
            "loss: 0.390031  [ 1600/ 3009]\n",
            "loss: 0.142088  [ 2000/ 3009]\n",
            "loss: 0.671458  [ 2400/ 3009]\n",
            "loss: 0.223675  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 0.462179 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.551642  [    0/ 3009]\n",
            "loss: 0.679758  [  400/ 3009]\n",
            "loss: 0.120072  [  800/ 3009]\n",
            "loss: 0.479118  [ 1200/ 3009]\n",
            "loss: 0.561728  [ 1600/ 3009]\n",
            "loss: 0.800065  [ 2000/ 3009]\n",
            "loss: 0.134920  [ 2400/ 3009]\n",
            "loss: 0.638808  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.420025 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.181058  [    0/ 3009]\n",
            "loss: 0.476328  [  400/ 3009]\n",
            "loss: 0.793069  [  800/ 3009]\n",
            "loss: 0.774077  [ 1200/ 3009]\n",
            "loss: 0.651152  [ 1600/ 3009]\n",
            "loss: 0.529852  [ 2000/ 3009]\n",
            "loss: 0.594834  [ 2400/ 3009]\n",
            "loss: 0.137719  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.7%, Avg loss: 0.419937 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.834789  [    0/ 3009]\n",
            "loss: 0.231440  [  400/ 3009]\n",
            "loss: 0.479048  [  800/ 3009]\n",
            "loss: 0.117851  [ 1200/ 3009]\n",
            "loss: 0.244712  [ 1600/ 3009]\n",
            "loss: 0.178930  [ 2000/ 3009]\n",
            "loss: 0.379081  [ 2400/ 3009]\n",
            "loss: 0.599987  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 79.3%, Avg loss: 0.450652 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.151992  [    0/ 3009]\n",
            "loss: 0.176912  [  400/ 3009]\n",
            "loss: 0.351415  [  800/ 3009]\n",
            "loss: 0.247838  [ 1200/ 3009]\n",
            "loss: 0.158393  [ 1600/ 3009]\n",
            "loss: 0.484625  [ 2000/ 3009]\n",
            "loss: 0.352358  [ 2400/ 3009]\n",
            "loss: 0.052665  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.379676 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.039899  [    0/ 3009]\n",
            "loss: 0.080865  [  400/ 3009]\n",
            "loss: 0.450896  [  800/ 3009]\n",
            "loss: 0.167304  [ 1200/ 3009]\n",
            "loss: 0.122087  [ 1600/ 3009]\n",
            "loss: 0.051019  [ 2000/ 3009]\n",
            "loss: 0.163362  [ 2400/ 3009]\n",
            "loss: 0.154690  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.423526 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.617306  [    0/ 3009]\n",
            "loss: 0.141544  [  400/ 3009]\n",
            "loss: 0.607791  [  800/ 3009]\n",
            "loss: 0.343291  [ 1200/ 3009]\n",
            "loss: 0.476560  [ 1600/ 3009]\n",
            "loss: 0.080692  [ 2000/ 3009]\n",
            "loss: 0.521105  [ 2400/ 3009]\n",
            "loss: 0.452686  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.389307 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.494254  [    0/ 3009]\n",
            "loss: 0.353025  [  400/ 3009]\n",
            "loss: 0.130950  [  800/ 3009]\n",
            "loss: 0.471629  [ 1200/ 3009]\n",
            "loss: 0.988184  [ 1600/ 3009]\n",
            "loss: 0.112982  [ 2000/ 3009]\n",
            "loss: 1.066662  [ 2400/ 3009]\n",
            "loss: 0.335832  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.372542 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.129016  [    0/ 3009]\n",
            "loss: 0.244029  [  400/ 3009]\n",
            "loss: 0.641012  [  800/ 3009]\n",
            "loss: 0.501355  [ 1200/ 3009]\n",
            "loss: 0.090507  [ 1600/ 3009]\n",
            "loss: 0.233492  [ 2000/ 3009]\n",
            "loss: 1.223993  [ 2400/ 3009]\n",
            "loss: 0.360899  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.349754 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.151481  [    0/ 3009]\n",
            "loss: 0.015479  [  400/ 3009]\n",
            "loss: 0.045785  [  800/ 3009]\n",
            "loss: 0.334352  [ 1200/ 3009]\n",
            "loss: 0.368729  [ 1600/ 3009]\n",
            "loss: 0.048659  [ 2000/ 3009]\n",
            "loss: 0.241868  [ 2400/ 3009]\n",
            "loss: 0.359376  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.339925 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.031162  [    0/ 3009]\n",
            "loss: 1.046239  [  400/ 3009]\n",
            "loss: 0.239876  [  800/ 3009]\n",
            "loss: 0.016417  [ 1200/ 3009]\n",
            "loss: 0.439614  [ 1600/ 3009]\n",
            "loss: 0.128648  [ 2000/ 3009]\n",
            "loss: 0.139937  [ 2400/ 3009]\n",
            "loss: 0.247661  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.383460 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.227411  [    0/ 3009]\n",
            "loss: 0.099553  [  400/ 3009]\n",
            "loss: 0.019541  [  800/ 3009]\n",
            "loss: 0.271050  [ 1200/ 3009]\n",
            "loss: 0.230396  [ 1600/ 3009]\n",
            "loss: 0.091817  [ 2000/ 3009]\n",
            "loss: 0.169901  [ 2400/ 3009]\n",
            "loss: 0.211772  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.327496 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.088484  [    0/ 3009]\n",
            "loss: 0.341332  [  400/ 3009]\n",
            "loss: 0.105197  [  800/ 3009]\n",
            "loss: 0.021826  [ 1200/ 3009]\n",
            "loss: 0.079652  [ 1600/ 3009]\n",
            "loss: 0.057163  [ 2000/ 3009]\n",
            "loss: 0.551414  [ 2400/ 3009]\n",
            "loss: 0.117953  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 0.347758 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.055479  [    0/ 3009]\n",
            "loss: 0.396636  [  400/ 3009]\n",
            "loss: 0.443934  [  800/ 3009]\n",
            "loss: 0.059361  [ 1200/ 3009]\n",
            "loss: 0.016744  [ 1600/ 3009]\n",
            "loss: 0.165302  [ 2000/ 3009]\n",
            "loss: 0.162205  [ 2400/ 3009]\n",
            "loss: 0.637001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.315639 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.093569  [    0/ 3009]\n",
            "loss: 0.152160  [  400/ 3009]\n",
            "loss: 0.140032  [  800/ 3009]\n",
            "loss: 0.284425  [ 1200/ 3009]\n",
            "loss: 0.409896  [ 1600/ 3009]\n",
            "loss: 0.100490  [ 2000/ 3009]\n",
            "loss: 0.221909  [ 2400/ 3009]\n",
            "loss: 0.481037  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.345701 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.142331  [    0/ 3009]\n",
            "loss: 0.048264  [  400/ 3009]\n",
            "loss: 0.326696  [  800/ 3009]\n",
            "loss: 0.308416  [ 1200/ 3009]\n",
            "loss: 0.068804  [ 1600/ 3009]\n",
            "loss: 0.835637  [ 2000/ 3009]\n",
            "loss: 0.045357  [ 2400/ 3009]\n",
            "loss: 0.382485  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.309727 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.818411  [    0/ 3009]\n",
            "loss: 1.006248  [  400/ 3009]\n",
            "loss: 0.493635  [  800/ 3009]\n",
            "loss: 0.531699  [ 1200/ 3009]\n",
            "loss: 0.588905  [ 1600/ 3009]\n",
            "loss: 0.343753  [ 2000/ 3009]\n",
            "loss: 0.560801  [ 2400/ 3009]\n",
            "loss: 0.430155  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.305855 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.199348  [    0/ 3009]\n",
            "loss: 0.212436  [  400/ 3009]\n",
            "loss: 1.500347  [  800/ 3009]\n",
            "loss: 0.076968  [ 1200/ 3009]\n",
            "loss: 0.436591  [ 1600/ 3009]\n",
            "loss: 0.463717  [ 2000/ 3009]\n",
            "loss: 0.180706  [ 2400/ 3009]\n",
            "loss: 0.182286  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.300187 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.298529  [    0/ 3009]\n",
            "loss: 0.258365  [  400/ 3009]\n",
            "loss: 0.148364  [  800/ 3009]\n",
            "loss: 0.350080  [ 1200/ 3009]\n",
            "loss: 0.310463  [ 1600/ 3009]\n",
            "loss: 0.158949  [ 2000/ 3009]\n",
            "loss: 0.125535  [ 2400/ 3009]\n",
            "loss: 1.832179  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.303860 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.407869  [    0/ 3009]\n",
            "loss: 0.061332  [  400/ 3009]\n",
            "loss: 0.449757  [  800/ 3009]\n",
            "loss: 0.081688  [ 1200/ 3009]\n",
            "loss: 0.070381  [ 1600/ 3009]\n",
            "loss: 0.361880  [ 2000/ 3009]\n",
            "loss: 0.064973  [ 2400/ 3009]\n",
            "loss: 0.013275  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.340293 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.076348  [    0/ 3009]\n",
            "loss: 0.272726  [  400/ 3009]\n",
            "loss: 0.221961  [  800/ 3009]\n",
            "loss: 0.206759  [ 1200/ 3009]\n",
            "loss: 0.198550  [ 1600/ 3009]\n",
            "loss: 0.130190  [ 2000/ 3009]\n",
            "loss: 0.842165  [ 2400/ 3009]\n",
            "loss: 0.061860  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.502338 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.317218  [    0/ 3009]\n",
            "loss: 0.171520  [  400/ 3009]\n",
            "loss: 0.171238  [  800/ 3009]\n",
            "loss: 0.067221  [ 1200/ 3009]\n",
            "loss: 0.306281  [ 1600/ 3009]\n",
            "loss: 0.043245  [ 2000/ 3009]\n",
            "loss: 0.901495  [ 2400/ 3009]\n",
            "loss: 0.015387  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.5%, Avg loss: 0.444039 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.052337  [    0/ 3009]\n",
            "loss: 0.738661  [  400/ 3009]\n",
            "loss: 0.066226  [  800/ 3009]\n",
            "loss: 0.585296  [ 1200/ 3009]\n",
            "loss: 0.213169  [ 1600/ 3009]\n",
            "loss: 0.102165  [ 2000/ 3009]\n",
            "loss: 0.361674  [ 2400/ 3009]\n",
            "loss: 0.356508  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.281452 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.046775  [    0/ 3009]\n",
            "loss: 0.362532  [  400/ 3009]\n",
            "loss: 0.167725  [  800/ 3009]\n",
            "loss: 0.012526  [ 1200/ 3009]\n",
            "loss: 0.468175  [ 1600/ 3009]\n",
            "loss: 0.145302  [ 2000/ 3009]\n",
            "loss: 0.928994  [ 2400/ 3009]\n",
            "loss: 0.529365  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.300647 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.192537  [    0/ 3009]\n",
            "loss: 0.165189  [  400/ 3009]\n",
            "loss: 0.135345  [  800/ 3009]\n",
            "loss: 0.049765  [ 1200/ 3009]\n",
            "loss: 0.212916  [ 1600/ 3009]\n",
            "loss: 0.210403  [ 2000/ 3009]\n",
            "loss: 0.868336  [ 2400/ 3009]\n",
            "loss: 0.171579  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.277051 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.175712  [    0/ 3009]\n",
            "loss: 0.025190  [  400/ 3009]\n",
            "loss: 0.010591  [  800/ 3009]\n",
            "loss: 0.112396  [ 1200/ 3009]\n",
            "loss: 0.237211  [ 1600/ 3009]\n",
            "loss: 0.059281  [ 2000/ 3009]\n",
            "loss: 0.138429  [ 2400/ 3009]\n",
            "loss: 0.447192  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.266358 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.260177  [    0/ 3009]\n",
            "loss: 0.066046  [  400/ 3009]\n",
            "loss: 0.038752  [  800/ 3009]\n",
            "loss: 0.106545  [ 1200/ 3009]\n",
            "loss: 0.147405  [ 1600/ 3009]\n",
            "loss: 0.183496  [ 2000/ 3009]\n",
            "loss: 0.103333  [ 2400/ 3009]\n",
            "loss: 0.193574  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.274333 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.071605  [    0/ 3009]\n",
            "loss: 0.040307  [  400/ 3009]\n",
            "loss: 0.116886  [  800/ 3009]\n",
            "loss: 0.167776  [ 1200/ 3009]\n",
            "loss: 0.500139  [ 1600/ 3009]\n",
            "loss: 0.097603  [ 2000/ 3009]\n",
            "loss: 0.007459  [ 2400/ 3009]\n",
            "loss: 0.384747  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.273744 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.114900  [    0/ 3009]\n",
            "loss: 0.076622  [  400/ 3009]\n",
            "loss: 0.566664  [  800/ 3009]\n",
            "loss: 0.207847  [ 1200/ 3009]\n",
            "loss: 0.178889  [ 1600/ 3009]\n",
            "loss: 0.037701  [ 2000/ 3009]\n",
            "loss: 0.211370  [ 2400/ 3009]\n",
            "loss: 0.095884  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.240522 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.212539  [    0/ 3009]\n",
            "loss: 0.603614  [  400/ 3009]\n",
            "loss: 1.557918  [  800/ 3009]\n",
            "loss: 0.017020  [ 1200/ 3009]\n",
            "loss: 0.042612  [ 1600/ 3009]\n",
            "loss: 0.089828  [ 2000/ 3009]\n",
            "loss: 0.225720  [ 2400/ 3009]\n",
            "loss: 0.144251  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.269586 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.417886  [    0/ 3009]\n",
            "loss: 0.048213  [  400/ 3009]\n",
            "loss: 0.139644  [  800/ 3009]\n",
            "loss: 0.005656  [ 1200/ 3009]\n",
            "loss: 0.314641  [ 1600/ 3009]\n",
            "loss: 0.130931  [ 2000/ 3009]\n",
            "loss: 0.286010  [ 2400/ 3009]\n",
            "loss: 0.241333  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.292583 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.088525  [    0/ 3009]\n",
            "loss: 0.012760  [  400/ 3009]\n",
            "loss: 0.094768  [  800/ 3009]\n",
            "loss: 0.122517  [ 1200/ 3009]\n",
            "loss: 0.829116  [ 1600/ 3009]\n",
            "loss: 0.050628  [ 2000/ 3009]\n",
            "loss: 0.019400  [ 2400/ 3009]\n",
            "loss: 0.039812  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.318226 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.371910  [    0/ 3009]\n",
            "loss: 0.050482  [  400/ 3009]\n",
            "loss: 0.009153  [  800/ 3009]\n",
            "loss: 0.307712  [ 1200/ 3009]\n",
            "loss: 0.015377  [ 1600/ 3009]\n",
            "loss: 0.027400  [ 2000/ 3009]\n",
            "loss: 0.028718  [ 2400/ 3009]\n",
            "loss: 0.523547  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.232645 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.059128  [    0/ 3009]\n",
            "loss: 0.118562  [  400/ 3009]\n",
            "loss: 0.050685  [  800/ 3009]\n",
            "loss: 0.133805  [ 1200/ 3009]\n",
            "loss: 0.131686  [ 1600/ 3009]\n",
            "loss: 0.011641  [ 2000/ 3009]\n",
            "loss: 0.094199  [ 2400/ 3009]\n",
            "loss: 0.192025  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.239612 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.075740  [    0/ 3009]\n",
            "loss: 0.114392  [  400/ 3009]\n",
            "loss: 0.215859  [  800/ 3009]\n",
            "loss: 0.121504  [ 1200/ 3009]\n",
            "loss: 0.032565  [ 1600/ 3009]\n",
            "loss: 0.554738  [ 2000/ 3009]\n",
            "loss: 0.217820  [ 2400/ 3009]\n",
            "loss: 0.209668  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.225194 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.362973  [    0/ 3009]\n",
            "loss: 0.187502  [  400/ 3009]\n",
            "loss: 0.606180  [  800/ 3009]\n",
            "loss: 0.274102  [ 1200/ 3009]\n",
            "loss: 0.427468  [ 1600/ 3009]\n",
            "loss: 0.057756  [ 2000/ 3009]\n",
            "loss: 0.329763  [ 2400/ 3009]\n",
            "loss: 0.050080  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.228406 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.156743  [    0/ 3009]\n",
            "loss: 0.201994  [  400/ 3009]\n",
            "loss: 0.018482  [  800/ 3009]\n",
            "loss: 0.012680  [ 1200/ 3009]\n",
            "loss: 0.203584  [ 1600/ 3009]\n",
            "loss: 0.055998  [ 2000/ 3009]\n",
            "loss: 0.028255  [ 2400/ 3009]\n",
            "loss: 0.019412  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.223406 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.324564  [    0/ 3009]\n",
            "loss: 0.037259  [  400/ 3009]\n",
            "loss: 0.274101  [  800/ 3009]\n",
            "loss: 0.071404  [ 1200/ 3009]\n",
            "loss: 0.084156  [ 1600/ 3009]\n",
            "loss: 0.002585  [ 2000/ 3009]\n",
            "loss: 0.343056  [ 2400/ 3009]\n",
            "loss: 0.147260  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.262765 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.011260  [    0/ 3009]\n",
            "loss: 0.188284  [  400/ 3009]\n",
            "loss: 0.933168  [  800/ 3009]\n",
            "loss: 0.050745  [ 1200/ 3009]\n",
            "loss: 0.083866  [ 1600/ 3009]\n",
            "loss: 0.007832  [ 2000/ 3009]\n",
            "loss: 0.683374  [ 2400/ 3009]\n",
            "loss: 0.006911  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.195816 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.055377  [    0/ 3009]\n",
            "loss: 0.313075  [  400/ 3009]\n",
            "loss: 0.509950  [  800/ 3009]\n",
            "loss: 0.051505  [ 1200/ 3009]\n",
            "loss: 0.014260  [ 1600/ 3009]\n",
            "loss: 0.788732  [ 2000/ 3009]\n",
            "loss: 0.515419  [ 2400/ 3009]\n",
            "loss: 0.016274  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.229504 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.017742  [    0/ 3009]\n",
            "loss: 0.868334  [  400/ 3009]\n",
            "loss: 0.036837  [  800/ 3009]\n",
            "loss: 0.095142  [ 1200/ 3009]\n",
            "loss: 0.375830  [ 1600/ 3009]\n",
            "loss: 0.002314  [ 2000/ 3009]\n",
            "loss: 0.040049  [ 2400/ 3009]\n",
            "loss: 0.243484  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.217544 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.056241  [    0/ 3009]\n",
            "loss: 0.179396  [  400/ 3009]\n",
            "loss: 0.074837  [  800/ 3009]\n",
            "loss: 0.123404  [ 1200/ 3009]\n",
            "loss: 0.175245  [ 1600/ 3009]\n",
            "loss: 0.049605  [ 2000/ 3009]\n",
            "loss: 0.022940  [ 2400/ 3009]\n",
            "loss: 0.075712  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.224531 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.597266  [    0/ 3009]\n",
            "loss: 0.515588  [  400/ 3009]\n",
            "loss: 0.064392  [  800/ 3009]\n",
            "loss: 0.233398  [ 1200/ 3009]\n",
            "loss: 0.337355  [ 1600/ 3009]\n",
            "loss: 0.241609  [ 2000/ 3009]\n",
            "loss: 0.680627  [ 2400/ 3009]\n",
            "loss: 0.015075  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.221707 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.010084  [    0/ 3009]\n",
            "loss: 0.363358  [  400/ 3009]\n",
            "loss: 0.076182  [  800/ 3009]\n",
            "loss: 0.128578  [ 1200/ 3009]\n",
            "loss: 0.082441  [ 1600/ 3009]\n",
            "loss: 0.287461  [ 2000/ 3009]\n",
            "loss: 0.172910  [ 2400/ 3009]\n",
            "loss: 0.028282  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.546622 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.186085  [    0/ 3009]\n",
            "loss: 0.282016  [  400/ 3009]\n",
            "loss: 0.004890  [  800/ 3009]\n",
            "loss: 0.014922  [ 1200/ 3009]\n",
            "loss: 0.015045  [ 1600/ 3009]\n",
            "loss: 0.046228  [ 2000/ 3009]\n",
            "loss: 0.368101  [ 2400/ 3009]\n",
            "loss: 0.005621  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.186760 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.408092  [    0/ 3009]\n",
            "loss: 0.420568  [  400/ 3009]\n",
            "loss: 0.001859  [  800/ 3009]\n",
            "loss: 0.050061  [ 1200/ 3009]\n",
            "loss: 0.022620  [ 1600/ 3009]\n",
            "loss: 0.015560  [ 2000/ 3009]\n",
            "loss: 0.134192  [ 2400/ 3009]\n",
            "loss: 0.003958  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.205759 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.099594  [    0/ 3009]\n",
            "loss: 0.373307  [  400/ 3009]\n",
            "loss: 0.112399  [  800/ 3009]\n",
            "loss: 0.004408  [ 1200/ 3009]\n",
            "loss: 0.053381  [ 1600/ 3009]\n",
            "loss: 0.600495  [ 2000/ 3009]\n",
            "loss: 0.175001  [ 2400/ 3009]\n",
            "loss: 0.006901  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.219098 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.051893  [    0/ 3009]\n",
            "loss: 0.013435  [  400/ 3009]\n",
            "loss: 0.072455  [  800/ 3009]\n",
            "loss: 0.024469  [ 1200/ 3009]\n",
            "loss: 0.072927  [ 1600/ 3009]\n",
            "loss: 0.070516  [ 2000/ 3009]\n",
            "loss: 0.862037  [ 2400/ 3009]\n",
            "loss: 0.024416  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.197816 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.299199  [    0/ 3009]\n",
            "loss: 0.043813  [  400/ 3009]\n",
            "loss: 0.117068  [  800/ 3009]\n",
            "loss: 0.092665  [ 1200/ 3009]\n",
            "loss: 0.155351  [ 1600/ 3009]\n",
            "loss: 0.093629  [ 2000/ 3009]\n",
            "loss: 0.169683  [ 2400/ 3009]\n",
            "loss: 0.092215  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.207836 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.008227  [    0/ 3009]\n",
            "loss: 0.635602  [  400/ 3009]\n",
            "loss: 0.024647  [  800/ 3009]\n",
            "loss: 0.016073  [ 1200/ 3009]\n",
            "loss: 0.581145  [ 1600/ 3009]\n",
            "loss: 0.005475  [ 2000/ 3009]\n",
            "loss: 0.224703  [ 2400/ 3009]\n",
            "loss: 0.204533  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.198546 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.342650  [    0/ 3009]\n",
            "loss: 0.003050  [  400/ 3009]\n",
            "loss: 1.052212  [  800/ 3009]\n",
            "loss: 0.135896  [ 1200/ 3009]\n",
            "loss: 0.001935  [ 1600/ 3009]\n",
            "loss: 0.059991  [ 2000/ 3009]\n",
            "loss: 0.293170  [ 2400/ 3009]\n",
            "loss: 0.087073  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.189728 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.086618  [    0/ 3009]\n",
            "loss: 0.022993  [  400/ 3009]\n",
            "loss: 0.161681  [  800/ 3009]\n",
            "loss: 0.055392  [ 1200/ 3009]\n",
            "loss: 0.021059  [ 1600/ 3009]\n",
            "loss: 0.034234  [ 2000/ 3009]\n",
            "loss: 0.563715  [ 2400/ 3009]\n",
            "loss: 0.000781  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.184367 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.009738  [    0/ 3009]\n",
            "loss: 0.118599  [  400/ 3009]\n",
            "loss: 0.004865  [  800/ 3009]\n",
            "loss: 0.042353  [ 1200/ 3009]\n",
            "loss: 0.041893  [ 1600/ 3009]\n",
            "loss: 0.382271  [ 2000/ 3009]\n",
            "loss: 0.116803  [ 2400/ 3009]\n",
            "loss: 0.107692  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.239411 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.107692  [    0/ 3009]\n",
            "loss: 0.028414  [  400/ 3009]\n",
            "loss: 0.008266  [  800/ 3009]\n",
            "loss: 0.042304  [ 1200/ 3009]\n",
            "loss: 0.061297  [ 1600/ 3009]\n",
            "loss: 0.075798  [ 2000/ 3009]\n",
            "loss: 0.013838  [ 2400/ 3009]\n",
            "loss: 0.627438  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.177265 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.015602  [    0/ 3009]\n",
            "loss: 0.008547  [  400/ 3009]\n",
            "loss: 0.004169  [  800/ 3009]\n",
            "loss: 0.330711  [ 1200/ 3009]\n",
            "loss: 0.008240  [ 1600/ 3009]\n",
            "loss: 0.027725  [ 2000/ 3009]\n",
            "loss: 0.024826  [ 2400/ 3009]\n",
            "loss: 0.065147  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.174658 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.037079  [    0/ 3009]\n",
            "loss: 0.009417  [  400/ 3009]\n",
            "loss: 0.109987  [  800/ 3009]\n",
            "loss: 0.063714  [ 1200/ 3009]\n",
            "loss: 0.009629  [ 1600/ 3009]\n",
            "loss: 0.338788  [ 2000/ 3009]\n",
            "loss: 0.082173  [ 2400/ 3009]\n",
            "loss: 0.011779  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.165274 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.001519  [    0/ 3009]\n",
            "loss: 0.356842  [  400/ 3009]\n",
            "loss: 0.068561  [  800/ 3009]\n",
            "loss: 0.014414  [ 1200/ 3009]\n",
            "loss: 0.153537  [ 1600/ 3009]\n",
            "loss: 0.042644  [ 2000/ 3009]\n",
            "loss: 0.006452  [ 2400/ 3009]\n",
            "loss: 0.200495  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.169514 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.619472  [    0/ 3009]\n",
            "loss: 0.010936  [  400/ 3009]\n",
            "loss: 0.018953  [  800/ 3009]\n",
            "loss: 0.092587  [ 1200/ 3009]\n",
            "loss: 0.013407  [ 1600/ 3009]\n",
            "loss: 0.329997  [ 2000/ 3009]\n",
            "loss: 0.724593  [ 2400/ 3009]\n",
            "loss: 0.280553  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.172695 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.001812  [    0/ 3009]\n",
            "loss: 0.032620  [  400/ 3009]\n",
            "loss: 0.050132  [  800/ 3009]\n",
            "loss: 0.011451  [ 1200/ 3009]\n",
            "loss: 0.067577  [ 1600/ 3009]\n",
            "loss: 0.049479  [ 2000/ 3009]\n",
            "loss: 0.215252  [ 2400/ 3009]\n",
            "loss: 0.012166  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.179096 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.123603  [    0/ 3009]\n",
            "loss: 0.110502  [  400/ 3009]\n",
            "loss: 0.424632  [  800/ 3009]\n",
            "loss: 0.397333  [ 1200/ 3009]\n",
            "loss: 0.206561  [ 1600/ 3009]\n",
            "loss: 0.032294  [ 2000/ 3009]\n",
            "loss: 0.051678  [ 2400/ 3009]\n",
            "loss: 0.290273  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.183730 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.203547  [    0/ 3009]\n",
            "loss: 0.007383  [  400/ 3009]\n",
            "loss: 0.230873  [  800/ 3009]\n",
            "loss: 0.115330  [ 1200/ 3009]\n",
            "loss: 0.002225  [ 1600/ 3009]\n",
            "loss: 0.011349  [ 2000/ 3009]\n",
            "loss: 0.002257  [ 2400/ 3009]\n",
            "loss: 0.003908  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.198016 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.006876  [    0/ 3009]\n",
            "loss: 0.044549  [  400/ 3009]\n",
            "loss: 0.800005  [  800/ 3009]\n",
            "loss: 0.181998  [ 1200/ 3009]\n",
            "loss: 0.017508  [ 1600/ 3009]\n",
            "loss: 0.002758  [ 2000/ 3009]\n",
            "loss: 0.111515  [ 2400/ 3009]\n",
            "loss: 0.303418  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.177331 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.053775  [    0/ 3009]\n",
            "loss: 0.038075  [  400/ 3009]\n",
            "loss: 0.038541  [  800/ 3009]\n",
            "loss: 0.051161  [ 1200/ 3009]\n",
            "loss: 0.306142  [ 1600/ 3009]\n",
            "loss: 0.057429  [ 2000/ 3009]\n",
            "loss: 0.012254  [ 2400/ 3009]\n",
            "loss: 0.004749  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.177435 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.035802  [    0/ 3009]\n",
            "loss: 0.071464  [  400/ 3009]\n",
            "loss: 0.003752  [  800/ 3009]\n",
            "loss: 0.082117  [ 1200/ 3009]\n",
            "loss: 0.007816  [ 1600/ 3009]\n",
            "loss: 0.011091  [ 2000/ 3009]\n",
            "loss: 0.048285  [ 2400/ 3009]\n",
            "loss: 0.375221  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.175073 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 1.458230  [    0/ 3009]\n",
            "loss: 0.005808  [  400/ 3009]\n",
            "loss: 0.012992  [  800/ 3009]\n",
            "loss: 0.002018  [ 1200/ 3009]\n",
            "loss: 0.001836  [ 1600/ 3009]\n",
            "loss: 0.012905  [ 2000/ 3009]\n",
            "loss: 0.309762  [ 2400/ 3009]\n",
            "loss: 0.195306  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.185811 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.000668  [    0/ 3009]\n",
            "loss: 0.068409  [  400/ 3009]\n",
            "loss: 0.076498  [  800/ 3009]\n",
            "loss: 0.920072  [ 1200/ 3009]\n",
            "loss: 0.245862  [ 1600/ 3009]\n",
            "loss: 0.002730  [ 2000/ 3009]\n",
            "loss: 1.236473  [ 2400/ 3009]\n",
            "loss: 0.024313  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.161870 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.016011  [    0/ 3009]\n",
            "loss: 0.025707  [  400/ 3009]\n",
            "loss: 0.372019  [  800/ 3009]\n",
            "loss: 0.005069  [ 1200/ 3009]\n",
            "loss: 0.006072  [ 1600/ 3009]\n",
            "loss: 0.002271  [ 2000/ 3009]\n",
            "loss: 0.013865  [ 2400/ 3009]\n",
            "loss: 0.000757  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.340292 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 1.573075  [    0/ 3009]\n",
            "loss: 0.472228  [  400/ 3009]\n",
            "loss: 0.029257  [  800/ 3009]\n",
            "loss: 0.744042  [ 1200/ 3009]\n",
            "loss: 0.051494  [ 1600/ 3009]\n",
            "loss: 0.097492  [ 2000/ 3009]\n",
            "loss: 0.003867  [ 2400/ 3009]\n",
            "loss: 0.086073  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.173751 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.159183  [    0/ 3009]\n",
            "loss: 0.000407  [  400/ 3009]\n",
            "loss: 0.043644  [  800/ 3009]\n",
            "loss: 0.082974  [ 1200/ 3009]\n",
            "loss: 0.092027  [ 1600/ 3009]\n",
            "loss: 0.009919  [ 2000/ 3009]\n",
            "loss: 0.000503  [ 2400/ 3009]\n",
            "loss: 0.226073  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.152334 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.904895  [    0/ 3009]\n",
            "loss: 0.035497  [  400/ 3009]\n",
            "loss: 0.001842  [  800/ 3009]\n",
            "loss: 0.239328  [ 1200/ 3009]\n",
            "loss: 0.032713  [ 1600/ 3009]\n",
            "loss: 0.006302  [ 2000/ 3009]\n",
            "loss: 0.029624  [ 2400/ 3009]\n",
            "loss: 0.059465  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.151252 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.017315  [    0/ 3009]\n",
            "loss: 0.053331  [  400/ 3009]\n",
            "loss: 0.017941  [  800/ 3009]\n",
            "loss: 0.043893  [ 1200/ 3009]\n",
            "loss: 0.000282  [ 1600/ 3009]\n",
            "loss: 0.067655  [ 2000/ 3009]\n",
            "loss: 0.103143  [ 2400/ 3009]\n",
            "loss: 0.076797  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.166319 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.017420  [    0/ 3009]\n",
            "loss: 0.003107  [  400/ 3009]\n",
            "loss: 0.074399  [  800/ 3009]\n",
            "loss: 0.003883  [ 1200/ 3009]\n",
            "loss: 0.078335  [ 1600/ 3009]\n",
            "loss: 0.002812  [ 2000/ 3009]\n",
            "loss: 0.077245  [ 2400/ 3009]\n",
            "loss: 0.175506  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.165232 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.309322  [    0/ 3009]\n",
            "loss: 0.006176  [  400/ 3009]\n",
            "loss: 0.008539  [  800/ 3009]\n",
            "loss: 0.607714  [ 1200/ 3009]\n",
            "loss: 0.037015  [ 1600/ 3009]\n",
            "loss: 0.007554  [ 2000/ 3009]\n",
            "loss: 0.211467  [ 2400/ 3009]\n",
            "loss: 0.007366  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.137727 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.036158  [    0/ 3009]\n",
            "loss: 0.130902  [  400/ 3009]\n",
            "loss: 0.280296  [  800/ 3009]\n",
            "loss: 0.429629  [ 1200/ 3009]\n",
            "loss: 0.168743  [ 1600/ 3009]\n",
            "loss: 0.000802  [ 2000/ 3009]\n",
            "loss: 0.064424  [ 2400/ 3009]\n",
            "loss: 0.021169  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.146973 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.021066  [    0/ 3009]\n",
            "loss: 0.039151  [  400/ 3009]\n",
            "loss: 0.063535  [  800/ 3009]\n",
            "loss: 0.009692  [ 1200/ 3009]\n",
            "loss: 0.029678  [ 1600/ 3009]\n",
            "loss: 0.033814  [ 2000/ 3009]\n",
            "loss: 0.013588  [ 2400/ 3009]\n",
            "loss: 0.015628  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.155154 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.152342  [    0/ 3009]\n",
            "loss: 0.086077  [  400/ 3009]\n",
            "loss: 0.001294  [  800/ 3009]\n",
            "loss: 0.003122  [ 1200/ 3009]\n",
            "loss: 0.458417  [ 1600/ 3009]\n",
            "loss: 0.009198  [ 2000/ 3009]\n",
            "loss: 0.050879  [ 2400/ 3009]\n",
            "loss: 0.010580  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.143626 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.011216  [    0/ 3009]\n",
            "loss: 0.054751  [  400/ 3009]\n",
            "loss: 0.028139  [  800/ 3009]\n",
            "loss: 0.131705  [ 1200/ 3009]\n",
            "loss: 0.005617  [ 1600/ 3009]\n",
            "loss: 0.018773  [ 2000/ 3009]\n",
            "loss: 0.010009  [ 2400/ 3009]\n",
            "loss: 0.091494  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.152579 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.066070  [    0/ 3009]\n",
            "loss: 0.219145  [  400/ 3009]\n",
            "loss: 0.091968  [  800/ 3009]\n",
            "loss: 0.006136  [ 1200/ 3009]\n",
            "loss: 0.001052  [ 1600/ 3009]\n",
            "loss: 0.000482  [ 2000/ 3009]\n",
            "loss: 0.028152  [ 2400/ 3009]\n",
            "loss: 0.002581  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.133998 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.165606  [    0/ 3009]\n",
            "loss: 0.210460  [  400/ 3009]\n",
            "loss: 0.032674  [  800/ 3009]\n",
            "loss: 0.037292  [ 1200/ 3009]\n",
            "loss: 0.188122  [ 1600/ 3009]\n",
            "loss: 0.099286  [ 2000/ 3009]\n",
            "loss: 0.019548  [ 2400/ 3009]\n",
            "loss: 0.029412  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.162997 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.002150  [    0/ 3009]\n",
            "loss: 0.136642  [  400/ 3009]\n",
            "loss: 0.000210  [  800/ 3009]\n",
            "loss: 0.000529  [ 1200/ 3009]\n",
            "loss: 0.381063  [ 1600/ 3009]\n",
            "loss: 0.038335  [ 2000/ 3009]\n",
            "loss: 0.084255  [ 2400/ 3009]\n",
            "loss: 0.057154  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.138039 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000615  [    0/ 3009]\n",
            "loss: 0.002280  [  400/ 3009]\n",
            "loss: 0.016025  [  800/ 3009]\n",
            "loss: 0.065343  [ 1200/ 3009]\n",
            "loss: 0.002293  [ 1600/ 3009]\n",
            "loss: 0.117130  [ 2000/ 3009]\n",
            "loss: 0.120037  [ 2400/ 3009]\n",
            "loss: 0.000372  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.156702 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.022609  [    0/ 3009]\n",
            "loss: 0.007668  [  400/ 3009]\n",
            "loss: 0.036419  [  800/ 3009]\n",
            "loss: 0.150392  [ 1200/ 3009]\n",
            "loss: 0.089437  [ 1600/ 3009]\n",
            "loss: 0.062241  [ 2000/ 3009]\n",
            "loss: 0.028511  [ 2400/ 3009]\n",
            "loss: 0.097432  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.150703 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.240325  [    0/ 3009]\n",
            "loss: 0.012184  [  400/ 3009]\n",
            "loss: 0.176684  [  800/ 3009]\n",
            "loss: 0.009827  [ 1200/ 3009]\n",
            "loss: 0.058193  [ 1600/ 3009]\n",
            "loss: 0.013621  [ 2000/ 3009]\n",
            "loss: 0.104801  [ 2400/ 3009]\n",
            "loss: 0.003556  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.134776 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.016578  [    0/ 3009]\n",
            "loss: 0.080263  [  400/ 3009]\n",
            "loss: 0.025703  [  800/ 3009]\n",
            "loss: 0.024730  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000709  [ 2000/ 3009]\n",
            "loss: 0.099430  [ 2400/ 3009]\n",
            "loss: 0.012153  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.153368 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.006334  [    0/ 3009]\n",
            "loss: 0.102640  [  400/ 3009]\n",
            "loss: 0.025072  [  800/ 3009]\n",
            "loss: 0.030225  [ 1200/ 3009]\n",
            "loss: 0.013594  [ 1600/ 3009]\n",
            "loss: 0.004346  [ 2000/ 3009]\n",
            "loss: 0.001230  [ 2400/ 3009]\n",
            "loss: 0.020000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.151494 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.023574  [    0/ 3009]\n",
            "loss: 0.003133  [  400/ 3009]\n",
            "loss: 0.000711  [  800/ 3009]\n",
            "loss: 0.436393  [ 1200/ 3009]\n",
            "loss: 0.003080  [ 1600/ 3009]\n",
            "loss: 0.001121  [ 2000/ 3009]\n",
            "loss: 0.003495  [ 2400/ 3009]\n",
            "loss: 0.001560  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.137547 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.107420  [    0/ 3009]\n",
            "loss: 0.001688  [  400/ 3009]\n",
            "loss: 0.168379  [  800/ 3009]\n",
            "loss: 0.000077  [ 1200/ 3009]\n",
            "loss: 0.003519  [ 1600/ 3009]\n",
            "loss: 0.016092  [ 2000/ 3009]\n",
            "loss: 0.214889  [ 2400/ 3009]\n",
            "loss: 0.004456  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.126074 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.005282  [    0/ 3009]\n",
            "loss: 0.006061  [  400/ 3009]\n",
            "loss: 0.025224  [  800/ 3009]\n",
            "loss: 0.018786  [ 1200/ 3009]\n",
            "loss: 0.000428  [ 1600/ 3009]\n",
            "loss: 0.001601  [ 2000/ 3009]\n",
            "loss: 0.001098  [ 2400/ 3009]\n",
            "loss: 0.102838  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.165393 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000444  [    0/ 3009]\n",
            "loss: 0.001978  [  400/ 3009]\n",
            "loss: 0.000249  [  800/ 3009]\n",
            "loss: 0.001738  [ 1200/ 3009]\n",
            "loss: 0.006249  [ 1600/ 3009]\n",
            "loss: 0.096075  [ 2000/ 3009]\n",
            "loss: 0.000363  [ 2400/ 3009]\n",
            "loss: 0.222524  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.144720 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.009217  [    0/ 3009]\n",
            "loss: 0.044082  [  400/ 3009]\n",
            "loss: 0.012161  [  800/ 3009]\n",
            "loss: 0.008317  [ 1200/ 3009]\n",
            "loss: 0.012204  [ 1600/ 3009]\n",
            "loss: 0.002339  [ 2000/ 3009]\n",
            "loss: 0.090060  [ 2400/ 3009]\n",
            "loss: 0.032806  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.152124 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.002308  [    0/ 3009]\n",
            "loss: 0.004596  [  400/ 3009]\n",
            "loss: 0.061646  [  800/ 3009]\n",
            "loss: 0.000382  [ 1200/ 3009]\n",
            "loss: 0.026786  [ 1600/ 3009]\n",
            "loss: 0.048584  [ 2000/ 3009]\n",
            "loss: 0.088708  [ 2400/ 3009]\n",
            "loss: 0.028331  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.145311 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.004897  [    0/ 3009]\n",
            "loss: 0.009799  [  400/ 3009]\n",
            "loss: 0.001345  [  800/ 3009]\n",
            "loss: 0.011646  [ 1200/ 3009]\n",
            "loss: 0.089074  [ 1600/ 3009]\n",
            "loss: 0.001898  [ 2000/ 3009]\n",
            "loss: 0.179835  [ 2400/ 3009]\n",
            "loss: 0.009365  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.121747 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.082532  [    0/ 3009]\n",
            "loss: 0.002329  [  400/ 3009]\n",
            "loss: 0.004243  [  800/ 3009]\n",
            "loss: 0.008818  [ 1200/ 3009]\n",
            "loss: 0.093305  [ 1600/ 3009]\n",
            "loss: 0.000223  [ 2000/ 3009]\n",
            "loss: 0.023876  [ 2400/ 3009]\n",
            "loss: 0.013310  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.132355 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.005474  [    0/ 3009]\n",
            "loss: 0.011453  [  400/ 3009]\n",
            "loss: 0.071224  [  800/ 3009]\n",
            "loss: 0.014114  [ 1200/ 3009]\n",
            "loss: 0.161992  [ 1600/ 3009]\n",
            "loss: 0.018816  [ 2000/ 3009]\n",
            "loss: 0.029412  [ 2400/ 3009]\n",
            "loss: 0.000866  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.136038 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model2, loss_fn, build_optimizer(model2 , learning_rate))\n",
        "\n",
        "    loss = test_loop(test_loader, model2, loss_fn)\n",
        "    losses.append(loss)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "pbePEJBw-5z1",
        "outputId": "d2ef3486-9454-44f5-e69c-50b414b3b1a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7bf123ccaad0>]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(0,100),losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "what is the diffrence ?\n",
        "we have less noise in second model and it has a little better performance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxkE7DRe-5z1",
        "outputId": "8f0dca5d-904e-469d-9c60-3acf4fd469b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9T1xOo--5z1"
      },
      "source": [
        "## WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3C7vaDM-5z1",
        "outputId": "1420d5a4-d886-4fe6-d937-be96c69422e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login cfa61dfee26b7bf9fbe8d11b14248ef541558"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy48IRVf-5z1"
      },
      "outputs": [],
      "source": [
        "# !wandb init(\n",
        "#     # set the wandb project where this run will be logged\n",
        "#     project = \"MRI_CI_LAB\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNuEEnSp-5z1"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method' : 'random'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3CAlYJJ-5z1"
      },
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'learning_rate' : {\n",
        "        'distribution' : 'uniform' ,\n",
        "        'min' : 0.00005,\n",
        "        'max' : 0.001\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEGi7g-e-5z2",
        "outputId": "cbcfda6c-c5f0-4ddd-f4ea-af3c2849065d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'parameters': {'learning_rate': {'distribution': 'uniform',\n",
            "                                  'max': 0.001,\n",
            "                                  'min': 5e-05}}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvfLh4fm-5z2"
      },
      "outputs": [],
      "source": [
        "def train(config=None , model = model2 , train_loader = train_loader , test_loader = test_loader , loss_fn = loss_fn):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "        losses=[]\n",
        "        for t in range(epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            train_loop(train_loader, model, loss_fn, build_optimizer(model , config.learning_rate))\n",
        "\n",
        "            loss = test_loop(test_loader, model, loss_fn)\n",
        "            wandb.log({\"loss\" : loss , \"epoch\" : i })\n",
        "            losses.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "72cba75755c84d24920d97457c3a9f63",
            "a6cbc5a098794a989fbc8dedceb1563d",
            "38ef2ae2958b4042ac656e15197eec53",
            "28a19fdcf2134566950a495b459752f5",
            "aea4074e042c490184fd9ffa2a7e8ff1",
            "9025c427e12a4bebad41cece589ab6a1",
            "5fba1836a8ad43d7bea59bda434cfede",
            "45a8dbe3ec8b4841bcfeab9603330ccb",
            "2a593f89cec844f9b4ecfccf36e920be",
            "babe5f7bfc4c43888654f09d5847b92a",
            "3e5918a624e64230bdc22eee01e0cdc0",
            "f3006247aef540bba09f0e84cb5b3955",
            "24565207eec34dbe805f599f0ec17dbd",
            "db9cd74e8e264ce5ab7d6792302b60bc",
            "4924d7f0a7ee4626b9573d9cd9068e5a",
            "ec10da7c20c948fca17ce6e266c4aafb",
            "4d23dbe3411641118384047e7220744c",
            "92000ef2a0a14956a86235e046d4abe9",
            "fe0b319970aa4ff185ed8ae8e684a87e",
            "656d6808fd9642edb4ae6535bb61fb10",
            "6bb5f118972d42e0baefdec59eb90294",
            "49d6581aaefb4bd78644d92475e006fc",
            "51840b8335374baf88c3f0944f75c37f",
            "4294b8e236324030900be16930f67d7a",
            "943e534152d0481daee56edfbaa9dcb4",
            "66b8c9d575bb432eaee598cc1b5d498f",
            "21ac1436b35e4e27a3bcec7282baf89b",
            "ae814cb8fc994179a6e0416c6c69a69f",
            "da060817afe14f58be229c01d2986fb1",
            "0c434af7e569476c9014fe209489724d",
            "185f0ff33ad94bac825fb76f1ebf5113",
            "0cbaa8c7588e4d8ea167682c0251bd1a",
            "ba82b7e9ecde498783cf4b2cc104867e"
          ]
        },
        "id": "2gT2fBNR-5z2",
        "outputId": "2d1fee5d-e7a4-4a70-9f4b-794a3f6da2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: i1a7tcfq\n",
            "Sweep URL: https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iwlbqpht with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00016311417094374702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamiraliarbab1831\u001b[0m (\u001b[33mamirali\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231221_113831-iwlbqpht</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/iwlbqpht' target=\"_blank\">fine-sweep-1</a></strong> to <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/iwlbqpht' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/iwlbqpht</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.008974  [    0/ 3009]\n",
            "loss: 0.000169  [  400/ 3009]\n",
            "loss: 0.001432  [  800/ 3009]\n",
            "loss: 0.017995  [ 1200/ 3009]\n",
            "loss: 0.170658  [ 1600/ 3009]\n",
            "loss: 0.042944  [ 2000/ 3009]\n",
            "loss: 0.022932  [ 2400/ 3009]\n",
            "loss: 0.004916  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.127158 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.051149  [    0/ 3009]\n",
            "loss: 0.002535  [  400/ 3009]\n",
            "loss: 0.000358  [  800/ 3009]\n",
            "loss: 0.067330  [ 1200/ 3009]\n",
            "loss: 0.009514  [ 1600/ 3009]\n",
            "loss: 0.021719  [ 2000/ 3009]\n",
            "loss: 0.004498  [ 2400/ 3009]\n",
            "loss: 0.000043  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.129671 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.061330  [    0/ 3009]\n",
            "loss: 0.044152  [  400/ 3009]\n",
            "loss: 0.001321  [  800/ 3009]\n",
            "loss: 0.019081  [ 1200/ 3009]\n",
            "loss: 0.000329  [ 1600/ 3009]\n",
            "loss: 0.319821  [ 2000/ 3009]\n",
            "loss: 0.016100  [ 2400/ 3009]\n",
            "loss: 0.036549  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.130629 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.033867  [    0/ 3009]\n",
            "loss: 0.063415  [  400/ 3009]\n",
            "loss: 0.007222  [  800/ 3009]\n",
            "loss: 0.059515  [ 1200/ 3009]\n",
            "loss: 0.000151  [ 1600/ 3009]\n",
            "loss: 0.002548  [ 2000/ 3009]\n",
            "loss: 0.016335  [ 2400/ 3009]\n",
            "loss: 0.053263  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.127104 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.073914  [    0/ 3009]\n",
            "loss: 0.065564  [  400/ 3009]\n",
            "loss: 0.000158  [  800/ 3009]\n",
            "loss: 0.010612  [ 1200/ 3009]\n",
            "loss: 0.402469  [ 1600/ 3009]\n",
            "loss: 0.003305  [ 2000/ 3009]\n",
            "loss: 0.041149  [ 2400/ 3009]\n",
            "loss: 0.000624  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.130563 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.028483  [    0/ 3009]\n",
            "loss: 0.002115  [  400/ 3009]\n",
            "loss: 0.451693  [  800/ 3009]\n",
            "loss: 0.000706  [ 1200/ 3009]\n",
            "loss: 0.001378  [ 1600/ 3009]\n",
            "loss: 0.020814  [ 2000/ 3009]\n",
            "loss: 0.006928  [ 2400/ 3009]\n",
            "loss: 0.431508  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.132815 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.006802  [    0/ 3009]\n",
            "loss: 0.006640  [  400/ 3009]\n",
            "loss: 0.007073  [  800/ 3009]\n",
            "loss: 0.005323  [ 1200/ 3009]\n",
            "loss: 0.002767  [ 1600/ 3009]\n",
            "loss: 0.003654  [ 2000/ 3009]\n",
            "loss: 0.006306  [ 2400/ 3009]\n",
            "loss: 0.007402  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.133435 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.001082  [    0/ 3009]\n",
            "loss: 0.002602  [  400/ 3009]\n",
            "loss: 0.009218  [  800/ 3009]\n",
            "loss: 0.027013  [ 1200/ 3009]\n",
            "loss: 0.002521  [ 1600/ 3009]\n",
            "loss: 0.021547  [ 2000/ 3009]\n",
            "loss: 0.001781  [ 2400/ 3009]\n",
            "loss: 0.001094  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.130909 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.061277  [    0/ 3009]\n",
            "loss: 0.000193  [  400/ 3009]\n",
            "loss: 0.004627  [  800/ 3009]\n",
            "loss: 0.001453  [ 1200/ 3009]\n",
            "loss: 0.000289  [ 1600/ 3009]\n",
            "loss: 0.003298  [ 2000/ 3009]\n",
            "loss: 0.012002  [ 2400/ 3009]\n",
            "loss: 0.000081  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.127303 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.001026  [    0/ 3009]\n",
            "loss: 0.046878  [  400/ 3009]\n",
            "loss: 0.002931  [  800/ 3009]\n",
            "loss: 0.002098  [ 1200/ 3009]\n",
            "loss: 0.001717  [ 1600/ 3009]\n",
            "loss: 0.000107  [ 2000/ 3009]\n",
            "loss: 0.053971  [ 2400/ 3009]\n",
            "loss: 0.193062  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.128394 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.003207  [    0/ 3009]\n",
            "loss: 0.105112  [  400/ 3009]\n",
            "loss: 0.001960  [  800/ 3009]\n",
            "loss: 0.009536  [ 1200/ 3009]\n",
            "loss: 0.003639  [ 1600/ 3009]\n",
            "loss: 0.000942  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.106584  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.136984 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.134406  [    0/ 3009]\n",
            "loss: 0.003609  [  400/ 3009]\n",
            "loss: 0.001794  [  800/ 3009]\n",
            "loss: 0.004412  [ 1200/ 3009]\n",
            "loss: 0.000200  [ 1600/ 3009]\n",
            "loss: 0.002711  [ 2000/ 3009]\n",
            "loss: 0.009970  [ 2400/ 3009]\n",
            "loss: 0.000079  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134313 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.003082  [    0/ 3009]\n",
            "loss: 0.002540  [  400/ 3009]\n",
            "loss: 0.043344  [  800/ 3009]\n",
            "loss: 0.067745  [ 1200/ 3009]\n",
            "loss: 0.015641  [ 1600/ 3009]\n",
            "loss: 0.154147  [ 2000/ 3009]\n",
            "loss: 0.029617  [ 2400/ 3009]\n",
            "loss: 0.001878  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.130830 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.001255  [    0/ 3009]\n",
            "loss: 0.000322  [  400/ 3009]\n",
            "loss: 0.000485  [  800/ 3009]\n",
            "loss: 0.003311  [ 1200/ 3009]\n",
            "loss: 0.000556  [ 1600/ 3009]\n",
            "loss: 0.022450  [ 2000/ 3009]\n",
            "loss: 0.000980  [ 2400/ 3009]\n",
            "loss: 0.005704  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.135211 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.012445  [    0/ 3009]\n",
            "loss: 0.000007  [  400/ 3009]\n",
            "loss: 0.000686  [  800/ 3009]\n",
            "loss: 0.049957  [ 1200/ 3009]\n",
            "loss: 0.008436  [ 1600/ 3009]\n",
            "loss: 0.062208  [ 2000/ 3009]\n",
            "loss: 0.001200  [ 2400/ 3009]\n",
            "loss: 0.001118  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.131297 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.002708  [    0/ 3009]\n",
            "loss: 0.010108  [  400/ 3009]\n",
            "loss: 0.184364  [  800/ 3009]\n",
            "loss: 0.006125  [ 1200/ 3009]\n",
            "loss: 0.005865  [ 1600/ 3009]\n",
            "loss: 0.085875  [ 2000/ 3009]\n",
            "loss: 0.005843  [ 2400/ 3009]\n",
            "loss: 0.064768  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.137290 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.004334  [    0/ 3009]\n",
            "loss: 0.002944  [  400/ 3009]\n",
            "loss: 0.009587  [  800/ 3009]\n",
            "loss: 0.000597  [ 1200/ 3009]\n",
            "loss: 0.013390  [ 1600/ 3009]\n",
            "loss: 0.070370  [ 2000/ 3009]\n",
            "loss: 0.000484  [ 2400/ 3009]\n",
            "loss: 0.007309  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.131030 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.000111  [    0/ 3009]\n",
            "loss: 0.001436  [  400/ 3009]\n",
            "loss: 0.000504  [  800/ 3009]\n",
            "loss: 0.005680  [ 1200/ 3009]\n",
            "loss: 0.004587  [ 1600/ 3009]\n",
            "loss: 0.015157  [ 2000/ 3009]\n",
            "loss: 0.000199  [ 2400/ 3009]\n",
            "loss: 0.003920  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.132655 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.000983  [    0/ 3009]\n",
            "loss: 0.000268  [  400/ 3009]\n",
            "loss: 0.046476  [  800/ 3009]\n",
            "loss: 0.003142  [ 1200/ 3009]\n",
            "loss: 0.086174  [ 1600/ 3009]\n",
            "loss: 0.000411  [ 2000/ 3009]\n",
            "loss: 0.001603  [ 2400/ 3009]\n",
            "loss: 0.002351  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.138367 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.000035  [    0/ 3009]\n",
            "loss: 0.104191  [  400/ 3009]\n",
            "loss: 0.003777  [  800/ 3009]\n",
            "loss: 0.000134  [ 1200/ 3009]\n",
            "loss: 0.020692  [ 1600/ 3009]\n",
            "loss: 0.003682  [ 2000/ 3009]\n",
            "loss: 0.010552  [ 2400/ 3009]\n",
            "loss: 0.049781  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.134296 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.000768  [    0/ 3009]\n",
            "loss: 0.016013  [  400/ 3009]\n",
            "loss: 0.000091  [  800/ 3009]\n",
            "loss: 0.013298  [ 1200/ 3009]\n",
            "loss: 0.001148  [ 1600/ 3009]\n",
            "loss: 0.000077  [ 2000/ 3009]\n",
            "loss: 0.023241  [ 2400/ 3009]\n",
            "loss: 0.001145  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.137674 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.021434  [    0/ 3009]\n",
            "loss: 0.009068  [  400/ 3009]\n",
            "loss: 0.001268  [  800/ 3009]\n",
            "loss: 0.018214  [ 1200/ 3009]\n",
            "loss: 0.003752  [ 1600/ 3009]\n",
            "loss: 0.075104  [ 2000/ 3009]\n",
            "loss: 0.002720  [ 2400/ 3009]\n",
            "loss: 0.000156  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.133432 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.000505  [    0/ 3009]\n",
            "loss: 0.000280  [  400/ 3009]\n",
            "loss: 0.000114  [  800/ 3009]\n",
            "loss: 0.027362  [ 1200/ 3009]\n",
            "loss: 0.028885  [ 1600/ 3009]\n",
            "loss: 0.015922  [ 2000/ 3009]\n",
            "loss: 0.006473  [ 2400/ 3009]\n",
            "loss: 0.000607  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.132889 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.097469  [    0/ 3009]\n",
            "loss: 0.000155  [  400/ 3009]\n",
            "loss: 0.000157  [  800/ 3009]\n",
            "loss: 0.125139  [ 1200/ 3009]\n",
            "loss: 0.003767  [ 1600/ 3009]\n",
            "loss: 0.228093  [ 2000/ 3009]\n",
            "loss: 0.005048  [ 2400/ 3009]\n",
            "loss: 0.006321  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.133137 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.001219  [    0/ 3009]\n",
            "loss: 0.028095  [  400/ 3009]\n",
            "loss: 0.005576  [  800/ 3009]\n",
            "loss: 0.000035  [ 1200/ 3009]\n",
            "loss: 0.002928  [ 1600/ 3009]\n",
            "loss: 0.000530  [ 2000/ 3009]\n",
            "loss: 0.000483  [ 2400/ 3009]\n",
            "loss: 0.000147  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.136327 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.015579  [    0/ 3009]\n",
            "loss: 0.006564  [  400/ 3009]\n",
            "loss: 0.000637  [  800/ 3009]\n",
            "loss: 0.013270  [ 1200/ 3009]\n",
            "loss: 0.047612  [ 1600/ 3009]\n",
            "loss: 0.011016  [ 2000/ 3009]\n",
            "loss: 0.007565  [ 2400/ 3009]\n",
            "loss: 0.200741  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.143832 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.005385  [    0/ 3009]\n",
            "loss: 0.028653  [  400/ 3009]\n",
            "loss: 0.000720  [  800/ 3009]\n",
            "loss: 0.065779  [ 1200/ 3009]\n",
            "loss: 0.011085  [ 1600/ 3009]\n",
            "loss: 0.276379  [ 2000/ 3009]\n",
            "loss: 0.008137  [ 2400/ 3009]\n",
            "loss: 0.000388  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.140231 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000853  [    0/ 3009]\n",
            "loss: 0.004396  [  400/ 3009]\n",
            "loss: 0.002428  [  800/ 3009]\n",
            "loss: 0.218719  [ 1200/ 3009]\n",
            "loss: 0.000063  [ 1600/ 3009]\n",
            "loss: 0.002361  [ 2000/ 3009]\n",
            "loss: 0.024268  [ 2400/ 3009]\n",
            "loss: 0.008041  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.133333 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.010171  [    0/ 3009]\n",
            "loss: 0.000098  [  400/ 3009]\n",
            "loss: 0.000953  [  800/ 3009]\n",
            "loss: 0.053727  [ 1200/ 3009]\n",
            "loss: 0.007748  [ 1600/ 3009]\n",
            "loss: 0.099037  [ 2000/ 3009]\n",
            "loss: 0.001139  [ 2400/ 3009]\n",
            "loss: 0.002706  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.139801 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000838  [    0/ 3009]\n",
            "loss: 0.004388  [  400/ 3009]\n",
            "loss: 0.001472  [  800/ 3009]\n",
            "loss: 0.009527  [ 1200/ 3009]\n",
            "loss: 0.000415  [ 1600/ 3009]\n",
            "loss: 0.001215  [ 2000/ 3009]\n",
            "loss: 0.003130  [ 2400/ 3009]\n",
            "loss: 0.014517  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.135982 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.013527  [    0/ 3009]\n",
            "loss: 0.002134  [  400/ 3009]\n",
            "loss: 0.000540  [  800/ 3009]\n",
            "loss: 0.000670  [ 1200/ 3009]\n",
            "loss: 0.003138  [ 1600/ 3009]\n",
            "loss: 0.032564  [ 2000/ 3009]\n",
            "loss: 0.000068  [ 2400/ 3009]\n",
            "loss: 0.015646  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.138812 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.001052  [    0/ 3009]\n",
            "loss: 0.000922  [  400/ 3009]\n",
            "loss: 0.076900  [  800/ 3009]\n",
            "loss: 0.064593  [ 1200/ 3009]\n",
            "loss: 0.017103  [ 1600/ 3009]\n",
            "loss: 0.003432  [ 2000/ 3009]\n",
            "loss: 0.000245  [ 2400/ 3009]\n",
            "loss: 0.229685  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.138088 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.014579  [    0/ 3009]\n",
            "loss: 0.000047  [  400/ 3009]\n",
            "loss: 0.008125  [  800/ 3009]\n",
            "loss: 0.004777  [ 1200/ 3009]\n",
            "loss: 0.006939  [ 1600/ 3009]\n",
            "loss: 0.007078  [ 2000/ 3009]\n",
            "loss: 0.004670  [ 2400/ 3009]\n",
            "loss: 0.000373  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.139364 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.004917  [    0/ 3009]\n",
            "loss: 0.002743  [  400/ 3009]\n",
            "loss: 0.009078  [  800/ 3009]\n",
            "loss: 0.008192  [ 1200/ 3009]\n",
            "loss: 0.004188  [ 1600/ 3009]\n",
            "loss: 0.004090  [ 2000/ 3009]\n",
            "loss: 0.000065  [ 2400/ 3009]\n",
            "loss: 0.003099  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.135346 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.007194  [    0/ 3009]\n",
            "loss: 0.001824  [  400/ 3009]\n",
            "loss: 0.051183  [  800/ 3009]\n",
            "loss: 0.023638  [ 1200/ 3009]\n",
            "loss: 0.007202  [ 1600/ 3009]\n",
            "loss: 0.038806  [ 2000/ 3009]\n",
            "loss: 0.038256  [ 2400/ 3009]\n",
            "loss: 0.002130  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.141590 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000031  [    0/ 3009]\n",
            "loss: 0.006421  [  400/ 3009]\n",
            "loss: 0.000005  [  800/ 3009]\n",
            "loss: 0.000096  [ 1200/ 3009]\n",
            "loss: 0.001104  [ 1600/ 3009]\n",
            "loss: 0.020510  [ 2000/ 3009]\n",
            "loss: 0.025112  [ 2400/ 3009]\n",
            "loss: 0.195136  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.137191 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.027821  [    0/ 3009]\n",
            "loss: 0.003810  [  400/ 3009]\n",
            "loss: 0.000190  [  800/ 3009]\n",
            "loss: 0.085511  [ 1200/ 3009]\n",
            "loss: 0.001517  [ 1600/ 3009]\n",
            "loss: 0.000060  [ 2000/ 3009]\n",
            "loss: 0.069433  [ 2400/ 3009]\n",
            "loss: 0.000162  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.140029 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.047988  [    0/ 3009]\n",
            "loss: 0.010314  [  400/ 3009]\n",
            "loss: 0.000276  [  800/ 3009]\n",
            "loss: 0.000063  [ 1200/ 3009]\n",
            "loss: 0.002271  [ 1600/ 3009]\n",
            "loss: 0.205880  [ 2000/ 3009]\n",
            "loss: 0.001354  [ 2400/ 3009]\n",
            "loss: 0.033488  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.140392 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.002886  [    0/ 3009]\n",
            "loss: 0.025735  [  400/ 3009]\n",
            "loss: 0.010826  [  800/ 3009]\n",
            "loss: 0.000159  [ 1200/ 3009]\n",
            "loss: 0.003557  [ 1600/ 3009]\n",
            "loss: 0.000685  [ 2000/ 3009]\n",
            "loss: 0.000033  [ 2400/ 3009]\n",
            "loss: 0.000344  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.136604 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000798  [    0/ 3009]\n",
            "loss: 0.028224  [  400/ 3009]\n",
            "loss: 0.000398  [  800/ 3009]\n",
            "loss: 0.002533  [ 1200/ 3009]\n",
            "loss: 0.001669  [ 1600/ 3009]\n",
            "loss: 0.153944  [ 2000/ 3009]\n",
            "loss: 0.040847  [ 2400/ 3009]\n",
            "loss: 0.050938  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.138703 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000471  [    0/ 3009]\n",
            "loss: 0.000733  [  400/ 3009]\n",
            "loss: 0.008641  [  800/ 3009]\n",
            "loss: 0.010681  [ 1200/ 3009]\n",
            "loss: 0.003341  [ 1600/ 3009]\n",
            "loss: 0.186862  [ 2000/ 3009]\n",
            "loss: 0.001292  [ 2400/ 3009]\n",
            "loss: 0.000548  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.142552 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.090696  [    0/ 3009]\n",
            "loss: 0.032100  [  400/ 3009]\n",
            "loss: 0.006204  [  800/ 3009]\n",
            "loss: 0.002007  [ 1200/ 3009]\n",
            "loss: 0.040217  [ 1600/ 3009]\n",
            "loss: 0.007507  [ 2000/ 3009]\n",
            "loss: 0.080176  [ 2400/ 3009]\n",
            "loss: 0.013453  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.136138 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.001035  [    0/ 3009]\n",
            "loss: 0.003716  [  400/ 3009]\n",
            "loss: 0.000302  [  800/ 3009]\n",
            "loss: 0.000576  [ 1200/ 3009]\n",
            "loss: 0.730660  [ 1600/ 3009]\n",
            "loss: 0.000035  [ 2000/ 3009]\n",
            "loss: 0.000505  [ 2400/ 3009]\n",
            "loss: 0.000827  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.141524 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.045523  [    0/ 3009]\n",
            "loss: 0.000401  [  400/ 3009]\n",
            "loss: 0.004103  [  800/ 3009]\n",
            "loss: 0.000127  [ 1200/ 3009]\n",
            "loss: 0.000693  [ 1600/ 3009]\n",
            "loss: 0.000487  [ 2000/ 3009]\n",
            "loss: 0.004488  [ 2400/ 3009]\n",
            "loss: 0.043022  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.141949 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000520  [    0/ 3009]\n",
            "loss: 0.001354  [  400/ 3009]\n",
            "loss: 0.000203  [  800/ 3009]\n",
            "loss: 0.033275  [ 1200/ 3009]\n",
            "loss: 0.001069  [ 1600/ 3009]\n",
            "loss: 0.000911  [ 2000/ 3009]\n",
            "loss: 0.000664  [ 2400/ 3009]\n",
            "loss: 0.003196  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.143288 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.001580  [    0/ 3009]\n",
            "loss: 0.000484  [  400/ 3009]\n",
            "loss: 0.001093  [  800/ 3009]\n",
            "loss: 0.000721  [ 1200/ 3009]\n",
            "loss: 0.003991  [ 1600/ 3009]\n",
            "loss: 0.000027  [ 2000/ 3009]\n",
            "loss: 0.003720  [ 2400/ 3009]\n",
            "loss: 0.025753  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.138156 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000819  [    0/ 3009]\n",
            "loss: 0.097823  [  400/ 3009]\n",
            "loss: 0.000008  [  800/ 3009]\n",
            "loss: 0.146037  [ 1200/ 3009]\n",
            "loss: 0.007171  [ 1600/ 3009]\n",
            "loss: 0.000269  [ 2000/ 3009]\n",
            "loss: 0.007680  [ 2400/ 3009]\n",
            "loss: 0.000133  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.141541 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.038496  [    0/ 3009]\n",
            "loss: 0.000074  [  400/ 3009]\n",
            "loss: 0.000020  [  800/ 3009]\n",
            "loss: 0.014158  [ 1200/ 3009]\n",
            "loss: 0.000765  [ 1600/ 3009]\n",
            "loss: 0.002858  [ 2000/ 3009]\n",
            "loss: 0.000073  [ 2400/ 3009]\n",
            "loss: 0.005152  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.142890 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.001659  [    0/ 3009]\n",
            "loss: 0.038945  [  400/ 3009]\n",
            "loss: 0.009401  [  800/ 3009]\n",
            "loss: 0.012485  [ 1200/ 3009]\n",
            "loss: 0.004419  [ 1600/ 3009]\n",
            "loss: 0.003818  [ 2000/ 3009]\n",
            "loss: 0.016272  [ 2400/ 3009]\n",
            "loss: 0.001306  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.144704 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000029  [    0/ 3009]\n",
            "loss: 0.000299  [  400/ 3009]\n",
            "loss: 0.127134  [  800/ 3009]\n",
            "loss: 0.003799  [ 1200/ 3009]\n",
            "loss: 0.009156  [ 1600/ 3009]\n",
            "loss: 0.008339  [ 2000/ 3009]\n",
            "loss: 0.000685  [ 2400/ 3009]\n",
            "loss: 0.004908  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.148151 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.000043  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.005167  [  800/ 3009]\n",
            "loss: 0.000240  [ 1200/ 3009]\n",
            "loss: 0.003343  [ 1600/ 3009]\n",
            "loss: 0.000022  [ 2000/ 3009]\n",
            "loss: 0.007899  [ 2400/ 3009]\n",
            "loss: 0.234477  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.139366 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.000451  [    0/ 3009]\n",
            "loss: 0.015733  [  400/ 3009]\n",
            "loss: 0.028757  [  800/ 3009]\n",
            "loss: 0.000154  [ 1200/ 3009]\n",
            "loss: 0.004133  [ 1600/ 3009]\n",
            "loss: 0.003259  [ 2000/ 3009]\n",
            "loss: 0.001079  [ 2400/ 3009]\n",
            "loss: 0.001704  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.143971 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.001757  [    0/ 3009]\n",
            "loss: 0.029815  [  400/ 3009]\n",
            "loss: 0.071865  [  800/ 3009]\n",
            "loss: 0.005341  [ 1200/ 3009]\n",
            "loss: 0.000287  [ 1600/ 3009]\n",
            "loss: 0.000190  [ 2000/ 3009]\n",
            "loss: 0.000008  [ 2400/ 3009]\n",
            "loss: 0.021350  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.151386 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.034837  [    0/ 3009]\n",
            "loss: 0.006730  [  400/ 3009]\n",
            "loss: 0.000325  [  800/ 3009]\n",
            "loss: 0.001893  [ 1200/ 3009]\n",
            "loss: 0.017068  [ 1600/ 3009]\n",
            "loss: 0.008691  [ 2000/ 3009]\n",
            "loss: 0.000114  [ 2400/ 3009]\n",
            "loss: 0.015904  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.141849 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.000078  [    0/ 3009]\n",
            "loss: 0.119762  [  400/ 3009]\n",
            "loss: 0.001998  [  800/ 3009]\n",
            "loss: 0.010706  [ 1200/ 3009]\n",
            "loss: 0.022502  [ 1600/ 3009]\n",
            "loss: 0.004186  [ 2000/ 3009]\n",
            "loss: 0.000995  [ 2400/ 3009]\n",
            "loss: 0.000036  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.146782 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.000164  [    0/ 3009]\n",
            "loss: 0.004090  [  400/ 3009]\n",
            "loss: 0.049809  [  800/ 3009]\n",
            "loss: 0.189154  [ 1200/ 3009]\n",
            "loss: 0.001184  [ 1600/ 3009]\n",
            "loss: 0.036786  [ 2000/ 3009]\n",
            "loss: 0.016071  [ 2400/ 3009]\n",
            "loss: 0.016504  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.142630 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.023061  [    0/ 3009]\n",
            "loss: 0.001246  [  400/ 3009]\n",
            "loss: 0.001038  [  800/ 3009]\n",
            "loss: 0.000008  [ 1200/ 3009]\n",
            "loss: 0.000820  [ 1600/ 3009]\n",
            "loss: 0.000032  [ 2000/ 3009]\n",
            "loss: 0.011884  [ 2400/ 3009]\n",
            "loss: 0.000907  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.141119 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.002260  [    0/ 3009]\n",
            "loss: 0.001869  [  400/ 3009]\n",
            "loss: 0.021124  [  800/ 3009]\n",
            "loss: 0.001568  [ 1200/ 3009]\n",
            "loss: 0.000587  [ 1600/ 3009]\n",
            "loss: 0.000570  [ 2000/ 3009]\n",
            "loss: 0.000006  [ 2400/ 3009]\n",
            "loss: 0.000053  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.144111 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.000073  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.022028  [  800/ 3009]\n",
            "loss: 0.001707  [ 1200/ 3009]\n",
            "loss: 0.000793  [ 1600/ 3009]\n",
            "loss: 0.000524  [ 2000/ 3009]\n",
            "loss: 0.010183  [ 2400/ 3009]\n",
            "loss: 0.000518  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.147668 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.000477  [    0/ 3009]\n",
            "loss: 0.011892  [  400/ 3009]\n",
            "loss: 0.002181  [  800/ 3009]\n",
            "loss: 0.000378  [ 1200/ 3009]\n",
            "loss: 0.000567  [ 1600/ 3009]\n",
            "loss: 0.007578  [ 2000/ 3009]\n",
            "loss: 0.000076  [ 2400/ 3009]\n",
            "loss: 0.157807  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.152459 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.003323  [    0/ 3009]\n",
            "loss: 0.010718  [  400/ 3009]\n",
            "loss: 0.001960  [  800/ 3009]\n",
            "loss: 0.016162  [ 1200/ 3009]\n",
            "loss: 0.011891  [ 1600/ 3009]\n",
            "loss: 0.003273  [ 2000/ 3009]\n",
            "loss: 0.022997  [ 2400/ 3009]\n",
            "loss: 0.001559  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.143100 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.008615  [    0/ 3009]\n",
            "loss: 0.007586  [  400/ 3009]\n",
            "loss: 0.232819  [  800/ 3009]\n",
            "loss: 0.007157  [ 1200/ 3009]\n",
            "loss: 0.023463  [ 1600/ 3009]\n",
            "loss: 0.000536  [ 2000/ 3009]\n",
            "loss: 0.075973  [ 2400/ 3009]\n",
            "loss: 0.028099  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.144430 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.008499  [    0/ 3009]\n",
            "loss: 0.000195  [  400/ 3009]\n",
            "loss: 0.005400  [  800/ 3009]\n",
            "loss: 0.000964  [ 1200/ 3009]\n",
            "loss: 0.000029  [ 1600/ 3009]\n",
            "loss: 0.001404  [ 2000/ 3009]\n",
            "loss: 0.004720  [ 2400/ 3009]\n",
            "loss: 0.008465  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.144982 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.001673  [    0/ 3009]\n",
            "loss: 0.000139  [  400/ 3009]\n",
            "loss: 0.019754  [  800/ 3009]\n",
            "loss: 0.000206  [ 1200/ 3009]\n",
            "loss: 0.000033  [ 1600/ 3009]\n",
            "loss: 0.000895  [ 2000/ 3009]\n",
            "loss: 0.000821  [ 2400/ 3009]\n",
            "loss: 0.001076  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.158308 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.000190  [    0/ 3009]\n",
            "loss: 0.066555  [  400/ 3009]\n",
            "loss: 0.000267  [  800/ 3009]\n",
            "loss: 0.000842  [ 1200/ 3009]\n",
            "loss: 0.000543  [ 1600/ 3009]\n",
            "loss: 0.034441  [ 2000/ 3009]\n",
            "loss: 0.000115  [ 2400/ 3009]\n",
            "loss: 0.000029  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.146380 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.221181  [    0/ 3009]\n",
            "loss: 0.000381  [  400/ 3009]\n",
            "loss: 0.012046  [  800/ 3009]\n",
            "loss: 0.000418  [ 1200/ 3009]\n",
            "loss: 0.015845  [ 1600/ 3009]\n",
            "loss: 0.004253  [ 2000/ 3009]\n",
            "loss: 0.000037  [ 2400/ 3009]\n",
            "loss: 0.001780  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.144015 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.004822  [    0/ 3009]\n",
            "loss: 0.000507  [  400/ 3009]\n",
            "loss: 0.006686  [  800/ 3009]\n",
            "loss: 0.000350  [ 1200/ 3009]\n",
            "loss: 0.000354  [ 1600/ 3009]\n",
            "loss: 0.005676  [ 2000/ 3009]\n",
            "loss: 0.000082  [ 2400/ 3009]\n",
            "loss: 0.084766  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.152246 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.001695  [    0/ 3009]\n",
            "loss: 0.004629  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.007943  [ 1200/ 3009]\n",
            "loss: 0.040685  [ 1600/ 3009]\n",
            "loss: 0.010269  [ 2000/ 3009]\n",
            "loss: 0.006367  [ 2400/ 3009]\n",
            "loss: 0.000271  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.142713 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.061071  [    0/ 3009]\n",
            "loss: 0.001334  [  400/ 3009]\n",
            "loss: 0.000044  [  800/ 3009]\n",
            "loss: 0.032407  [ 1200/ 3009]\n",
            "loss: 0.002944  [ 1600/ 3009]\n",
            "loss: 0.000282  [ 2000/ 3009]\n",
            "loss: 0.009821  [ 2400/ 3009]\n",
            "loss: 0.010714  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.145253 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.003326  [    0/ 3009]\n",
            "loss: 0.006567  [  400/ 3009]\n",
            "loss: 0.029679  [  800/ 3009]\n",
            "loss: 0.003576  [ 1200/ 3009]\n",
            "loss: 0.000178  [ 1600/ 3009]\n",
            "loss: 0.000193  [ 2000/ 3009]\n",
            "loss: 0.020682  [ 2400/ 3009]\n",
            "loss: 0.000179  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.141438 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.003084  [    0/ 3009]\n",
            "loss: 0.018125  [  400/ 3009]\n",
            "loss: 0.001286  [  800/ 3009]\n",
            "loss: 0.007093  [ 1200/ 3009]\n",
            "loss: 0.000016  [ 1600/ 3009]\n",
            "loss: 0.000561  [ 2000/ 3009]\n",
            "loss: 0.032884  [ 2400/ 3009]\n",
            "loss: 0.034976  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.146221 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.012258  [    0/ 3009]\n",
            "loss: 0.000132  [  400/ 3009]\n",
            "loss: 0.002803  [  800/ 3009]\n",
            "loss: 0.002767  [ 1200/ 3009]\n",
            "loss: 0.005175  [ 1600/ 3009]\n",
            "loss: 0.000066  [ 2000/ 3009]\n",
            "loss: 0.004605  [ 2400/ 3009]\n",
            "loss: 0.011438  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.143245 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.000642  [    0/ 3009]\n",
            "loss: 0.001105  [  400/ 3009]\n",
            "loss: 0.000058  [  800/ 3009]\n",
            "loss: 0.015807  [ 1200/ 3009]\n",
            "loss: 0.000868  [ 1600/ 3009]\n",
            "loss: 0.001190  [ 2000/ 3009]\n",
            "loss: 0.003611  [ 2400/ 3009]\n",
            "loss: 0.001353  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.146239 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.000027  [    0/ 3009]\n",
            "loss: 0.008198  [  400/ 3009]\n",
            "loss: 0.001562  [  800/ 3009]\n",
            "loss: 0.023707  [ 1200/ 3009]\n",
            "loss: 0.004561  [ 1600/ 3009]\n",
            "loss: 0.069323  [ 2000/ 3009]\n",
            "loss: 0.017240  [ 2400/ 3009]\n",
            "loss: 0.000037  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.151656 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.010561  [    0/ 3009]\n",
            "loss: 0.001056  [  400/ 3009]\n",
            "loss: 0.000552  [  800/ 3009]\n",
            "loss: 0.004104  [ 1200/ 3009]\n",
            "loss: 0.000020  [ 1600/ 3009]\n",
            "loss: 0.003761  [ 2000/ 3009]\n",
            "loss: 0.003953  [ 2400/ 3009]\n",
            "loss: 0.001310  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.151105 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.012431  [    0/ 3009]\n",
            "loss: 0.004285  [  400/ 3009]\n",
            "loss: 0.001635  [  800/ 3009]\n",
            "loss: 0.022582  [ 1200/ 3009]\n",
            "loss: 0.000329  [ 1600/ 3009]\n",
            "loss: 0.001008  [ 2000/ 3009]\n",
            "loss: 0.016176  [ 2400/ 3009]\n",
            "loss: 0.000660  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.142848 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.141543  [    0/ 3009]\n",
            "loss: 0.004280  [  400/ 3009]\n",
            "loss: 0.005733  [  800/ 3009]\n",
            "loss: 0.000412  [ 1200/ 3009]\n",
            "loss: 0.000198  [ 1600/ 3009]\n",
            "loss: 0.006874  [ 2000/ 3009]\n",
            "loss: 0.000270  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.146112 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.009844  [  400/ 3009]\n",
            "loss: 0.000218  [  800/ 3009]\n",
            "loss: 0.002622  [ 1200/ 3009]\n",
            "loss: 0.000702  [ 1600/ 3009]\n",
            "loss: 0.000749  [ 2000/ 3009]\n",
            "loss: 0.000194  [ 2400/ 3009]\n",
            "loss: 0.022110  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.148748 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.001062  [    0/ 3009]\n",
            "loss: 0.000035  [  400/ 3009]\n",
            "loss: 0.005036  [  800/ 3009]\n",
            "loss: 0.000072  [ 1200/ 3009]\n",
            "loss: 0.006077  [ 1600/ 3009]\n",
            "loss: 0.015511  [ 2000/ 3009]\n",
            "loss: 0.000934  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.150864 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.003517  [    0/ 3009]\n",
            "loss: 0.000095  [  400/ 3009]\n",
            "loss: 0.003608  [  800/ 3009]\n",
            "loss: 0.001192  [ 1200/ 3009]\n",
            "loss: 0.001338  [ 1600/ 3009]\n",
            "loss: 0.010773  [ 2000/ 3009]\n",
            "loss: 0.000072  [ 2400/ 3009]\n",
            "loss: 0.000619  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.147482 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.003369  [    0/ 3009]\n",
            "loss: 0.000726  [  400/ 3009]\n",
            "loss: 0.010313  [  800/ 3009]\n",
            "loss: 0.001543  [ 1200/ 3009]\n",
            "loss: 0.021535  [ 1600/ 3009]\n",
            "loss: 0.000188  [ 2000/ 3009]\n",
            "loss: 0.042388  [ 2400/ 3009]\n",
            "loss: 0.000489  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.145211 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.003451  [    0/ 3009]\n",
            "loss: 0.000090  [  400/ 3009]\n",
            "loss: 0.005406  [  800/ 3009]\n",
            "loss: 0.008733  [ 1200/ 3009]\n",
            "loss: 0.000586  [ 1600/ 3009]\n",
            "loss: 0.010628  [ 2000/ 3009]\n",
            "loss: 0.002188  [ 2400/ 3009]\n",
            "loss: 0.081509  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.144371 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.020816  [    0/ 3009]\n",
            "loss: 0.008537  [  400/ 3009]\n",
            "loss: 0.000575  [  800/ 3009]\n",
            "loss: 0.001704  [ 1200/ 3009]\n",
            "loss: 0.002552  [ 1600/ 3009]\n",
            "loss: 0.005663  [ 2000/ 3009]\n",
            "loss: 0.019252  [ 2400/ 3009]\n",
            "loss: 0.006627  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.144477 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.001658  [    0/ 3009]\n",
            "loss: 0.118008  [  400/ 3009]\n",
            "loss: 0.001174  [  800/ 3009]\n",
            "loss: 0.000340  [ 1200/ 3009]\n",
            "loss: 0.000259  [ 1600/ 3009]\n",
            "loss: 0.021043  [ 2000/ 3009]\n",
            "loss: 0.000964  [ 2400/ 3009]\n",
            "loss: 0.002552  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.149940 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.000118  [    0/ 3009]\n",
            "loss: 0.016660  [  400/ 3009]\n",
            "loss: 0.004560  [  800/ 3009]\n",
            "loss: 0.000617  [ 1200/ 3009]\n",
            "loss: 0.001342  [ 1600/ 3009]\n",
            "loss: 0.005282  [ 2000/ 3009]\n",
            "loss: 0.008174  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.154357 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.118944  [    0/ 3009]\n",
            "loss: 0.004380  [  400/ 3009]\n",
            "loss: 0.000379  [  800/ 3009]\n",
            "loss: 0.000756  [ 1200/ 3009]\n",
            "loss: 0.005298  [ 1600/ 3009]\n",
            "loss: 0.000015  [ 2000/ 3009]\n",
            "loss: 0.001611  [ 2400/ 3009]\n",
            "loss: 0.002168  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.153311 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000229  [    0/ 3009]\n",
            "loss: 0.073518  [  400/ 3009]\n",
            "loss: 0.009301  [  800/ 3009]\n",
            "loss: 0.000135  [ 1200/ 3009]\n",
            "loss: 0.004816  [ 1600/ 3009]\n",
            "loss: 0.003550  [ 2000/ 3009]\n",
            "loss: 0.005299  [ 2400/ 3009]\n",
            "loss: 0.002040  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.154421 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.000070  [    0/ 3009]\n",
            "loss: 0.011592  [  400/ 3009]\n",
            "loss: 0.000625  [  800/ 3009]\n",
            "loss: 0.006147  [ 1200/ 3009]\n",
            "loss: 0.000875  [ 1600/ 3009]\n",
            "loss: 0.001579  [ 2000/ 3009]\n",
            "loss: 0.065446  [ 2400/ 3009]\n",
            "loss: 0.092396  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.148336 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.000046  [    0/ 3009]\n",
            "loss: 0.000083  [  400/ 3009]\n",
            "loss: 0.011707  [  800/ 3009]\n",
            "loss: 0.012363  [ 1200/ 3009]\n",
            "loss: 0.012308  [ 1600/ 3009]\n",
            "loss: 0.023221  [ 2000/ 3009]\n",
            "loss: 0.000006  [ 2400/ 3009]\n",
            "loss: 0.000990  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.146029 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.000136  [    0/ 3009]\n",
            "loss: 0.005863  [  400/ 3009]\n",
            "loss: 0.018893  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.017412  [ 1600/ 3009]\n",
            "loss: 0.001433  [ 2000/ 3009]\n",
            "loss: 0.000091  [ 2400/ 3009]\n",
            "loss: 0.015854  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.155578 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.001515  [    0/ 3009]\n",
            "loss: 0.000917  [  400/ 3009]\n",
            "loss: 0.046075  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000217  [ 1600/ 3009]\n",
            "loss: 0.000503  [ 2000/ 3009]\n",
            "loss: 0.000182  [ 2400/ 3009]\n",
            "loss: 0.000838  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.149539 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.000317  [    0/ 3009]\n",
            "loss: 0.039185  [  400/ 3009]\n",
            "loss: 0.077926  [  800/ 3009]\n",
            "loss: 0.000137  [ 1200/ 3009]\n",
            "loss: 0.019073  [ 1600/ 3009]\n",
            "loss: 0.004307  [ 2000/ 3009]\n",
            "loss: 0.021293  [ 2400/ 3009]\n",
            "loss: 0.000197  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.155470 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.000028  [    0/ 3009]\n",
            "loss: 0.026505  [  400/ 3009]\n",
            "loss: 0.000958  [  800/ 3009]\n",
            "loss: 0.004389  [ 1200/ 3009]\n",
            "loss: 0.000019  [ 1600/ 3009]\n",
            "loss: 0.000027  [ 2000/ 3009]\n",
            "loss: 0.307265  [ 2400/ 3009]\n",
            "loss: 0.030555  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.147622 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.079701  [    0/ 3009]\n",
            "loss: 0.019599  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000371  [ 1200/ 3009]\n",
            "loss: 0.001024  [ 1600/ 3009]\n",
            "loss: 0.007606  [ 2000/ 3009]\n",
            "loss: 0.062795  [ 2400/ 3009]\n",
            "loss: 0.000029  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.153358 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.004550  [    0/ 3009]\n",
            "loss: 0.000346  [  400/ 3009]\n",
            "loss: 0.019807  [  800/ 3009]\n",
            "loss: 0.000342  [ 1200/ 3009]\n",
            "loss: 0.001693  [ 1600/ 3009]\n",
            "loss: 0.000028  [ 2000/ 3009]\n",
            "loss: 0.016786  [ 2400/ 3009]\n",
            "loss: 0.012989  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.147451 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000932  [    0/ 3009]\n",
            "loss: 0.000006  [  400/ 3009]\n",
            "loss: 0.000432  [  800/ 3009]\n",
            "loss: 0.000180  [ 1200/ 3009]\n",
            "loss: 0.000015  [ 1600/ 3009]\n",
            "loss: 0.018108  [ 2000/ 3009]\n",
            "loss: 0.000251  [ 2400/ 3009]\n",
            "loss: 0.008667  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.147196 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.001643  [    0/ 3009]\n",
            "loss: 0.032625  [  400/ 3009]\n",
            "loss: 0.000694  [  800/ 3009]\n",
            "loss: 0.000099  [ 1200/ 3009]\n",
            "loss: 0.000583  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000025  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.151162 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.032569  [    0/ 3009]\n",
            "loss: 0.007288  [  400/ 3009]\n",
            "loss: 0.000793  [  800/ 3009]\n",
            "loss: 0.000859  [ 1200/ 3009]\n",
            "loss: 0.015810  [ 1600/ 3009]\n",
            "loss: 0.000011  [ 2000/ 3009]\n",
            "loss: 0.000287  [ 2400/ 3009]\n",
            "loss: 0.029911  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.152463 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000539  [    0/ 3009]\n",
            "loss: 0.000053  [  400/ 3009]\n",
            "loss: 0.001723  [  800/ 3009]\n",
            "loss: 0.000361  [ 1200/ 3009]\n",
            "loss: 0.000045  [ 1600/ 3009]\n",
            "loss: 0.025139  [ 2000/ 3009]\n",
            "loss: 0.001848  [ 2400/ 3009]\n",
            "loss: 0.000281  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.150955 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.005597  [    0/ 3009]\n",
            "loss: 0.000625  [  400/ 3009]\n",
            "loss: 0.004153  [  800/ 3009]\n",
            "loss: 0.000442  [ 1200/ 3009]\n",
            "loss: 0.001024  [ 1600/ 3009]\n",
            "loss: 0.007256  [ 2000/ 3009]\n",
            "loss: 0.000029  [ 2400/ 3009]\n",
            "loss: 0.002289  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.152533 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72cba75755c84d24920d97457c3a9f63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded\\r'), FloatProgress(value=0.11185723484500046, max=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▂▂▂▃▂▃▂▃▂▅▂▄▃▃▃▄▄▃▅▄▄▄▆▅█▇▅▅▇▅▆▅▆▇▅▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.15253</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine-sweep-1</strong> at: <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/iwlbqpht' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/iwlbqpht</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231221_113831-iwlbqpht/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c21zf6bf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004489817168100679\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231221_114231-c21zf6bf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/c21zf6bf' target=\"_blank\">silver-sweep-2</a></strong> to <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/c21zf6bf' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/c21zf6bf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.000249  [    0/ 3009]\n",
            "loss: 0.022886  [  400/ 3009]\n",
            "loss: 0.002741  [  800/ 3009]\n",
            "loss: 0.001893  [ 1200/ 3009]\n",
            "loss: 0.022942  [ 1600/ 3009]\n",
            "loss: 0.000827  [ 2000/ 3009]\n",
            "loss: 0.002227  [ 2400/ 3009]\n",
            "loss: 0.007952  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.154826 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.000363  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000255  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.001470  [ 2000/ 3009]\n",
            "loss: 0.000079  [ 2400/ 3009]\n",
            "loss: 0.005452  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.155193 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.009638  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.000079  [  800/ 3009]\n",
            "loss: 0.005423  [ 1200/ 3009]\n",
            "loss: 0.000928  [ 1600/ 3009]\n",
            "loss: 0.040054  [ 2000/ 3009]\n",
            "loss: 0.001920  [ 2400/ 3009]\n",
            "loss: 0.240928  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.148526 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.019043  [    0/ 3009]\n",
            "loss: 0.003669  [  400/ 3009]\n",
            "loss: 0.000292  [  800/ 3009]\n",
            "loss: 0.000355  [ 1200/ 3009]\n",
            "loss: 0.000487  [ 1600/ 3009]\n",
            "loss: 0.045538  [ 2000/ 3009]\n",
            "loss: 0.004362  [ 2400/ 3009]\n",
            "loss: 0.008664  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159388 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.010114  [    0/ 3009]\n",
            "loss: 0.013006  [  400/ 3009]\n",
            "loss: 0.014011  [  800/ 3009]\n",
            "loss: 0.003297  [ 1200/ 3009]\n",
            "loss: 0.000074  [ 1600/ 3009]\n",
            "loss: 0.000813  [ 2000/ 3009]\n",
            "loss: 0.000388  [ 2400/ 3009]\n",
            "loss: 0.000936  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.165658 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.013080  [    0/ 3009]\n",
            "loss: 0.002701  [  400/ 3009]\n",
            "loss: 0.025132  [  800/ 3009]\n",
            "loss: 0.000476  [ 1200/ 3009]\n",
            "loss: 0.000395  [ 1600/ 3009]\n",
            "loss: 0.000091  [ 2000/ 3009]\n",
            "loss: 0.001015  [ 2400/ 3009]\n",
            "loss: 0.000572  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.162324 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.000192  [    0/ 3009]\n",
            "loss: 0.000010  [  400/ 3009]\n",
            "loss: 0.002443  [  800/ 3009]\n",
            "loss: 0.144688  [ 1200/ 3009]\n",
            "loss: 0.000173  [ 1600/ 3009]\n",
            "loss: 0.005457  [ 2000/ 3009]\n",
            "loss: 0.000136  [ 2400/ 3009]\n",
            "loss: 0.000680  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.155388 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.000723  [    0/ 3009]\n",
            "loss: 0.028747  [  400/ 3009]\n",
            "loss: 0.019587  [  800/ 3009]\n",
            "loss: 0.001089  [ 1200/ 3009]\n",
            "loss: 0.000025  [ 1600/ 3009]\n",
            "loss: 0.000738  [ 2000/ 3009]\n",
            "loss: 0.007711  [ 2400/ 3009]\n",
            "loss: 0.091014  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.153292 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.000158  [    0/ 3009]\n",
            "loss: 0.000174  [  400/ 3009]\n",
            "loss: 0.000585  [  800/ 3009]\n",
            "loss: 0.000457  [ 1200/ 3009]\n",
            "loss: 0.000066  [ 1600/ 3009]\n",
            "loss: 0.002560  [ 2000/ 3009]\n",
            "loss: 0.001570  [ 2400/ 3009]\n",
            "loss: 0.000984  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.161175 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.005821  [    0/ 3009]\n",
            "loss: 0.014166  [  400/ 3009]\n",
            "loss: 0.000003  [  800/ 3009]\n",
            "loss: 0.000321  [ 1200/ 3009]\n",
            "loss: 0.005295  [ 1600/ 3009]\n",
            "loss: 0.068933  [ 2000/ 3009]\n",
            "loss: 0.000074  [ 2400/ 3009]\n",
            "loss: 0.003451  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.156807 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.000034  [    0/ 3009]\n",
            "loss: 0.036399  [  400/ 3009]\n",
            "loss: 0.003562  [  800/ 3009]\n",
            "loss: 0.000047  [ 1200/ 3009]\n",
            "loss: 0.000153  [ 1600/ 3009]\n",
            "loss: 0.000155  [ 2000/ 3009]\n",
            "loss: 0.000973  [ 2400/ 3009]\n",
            "loss: 0.002771  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.189930 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.179736  [    0/ 3009]\n",
            "loss: 0.000655  [  400/ 3009]\n",
            "loss: 0.006874  [  800/ 3009]\n",
            "loss: 0.001168  [ 1200/ 3009]\n",
            "loss: 0.018324  [ 1600/ 3009]\n",
            "loss: 0.000075  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.002677  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.174553 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.020397  [    0/ 3009]\n",
            "loss: 0.000515  [  400/ 3009]\n",
            "loss: 0.000220  [  800/ 3009]\n",
            "loss: 0.011220  [ 1200/ 3009]\n",
            "loss: 0.003390  [ 1600/ 3009]\n",
            "loss: 0.120285  [ 2000/ 3009]\n",
            "loss: 0.004203  [ 2400/ 3009]\n",
            "loss: 0.017295  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.184991 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000628  [  400/ 3009]\n",
            "loss: 0.001499  [  800/ 3009]\n",
            "loss: 0.000103  [ 1200/ 3009]\n",
            "loss: 0.000019  [ 1600/ 3009]\n",
            "loss: 0.014963  [ 2000/ 3009]\n",
            "loss: 0.035485  [ 2400/ 3009]\n",
            "loss: 0.000241  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.151752 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.039780  [    0/ 3009]\n",
            "loss: 0.002332  [  400/ 3009]\n",
            "loss: 0.000594  [  800/ 3009]\n",
            "loss: 0.016903  [ 1200/ 3009]\n",
            "loss: 0.001731  [ 1600/ 3009]\n",
            "loss: 0.005640  [ 2000/ 3009]\n",
            "loss: 0.005771  [ 2400/ 3009]\n",
            "loss: 0.000018  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.155647 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.000030  [    0/ 3009]\n",
            "loss: 0.009010  [  400/ 3009]\n",
            "loss: 0.000058  [  800/ 3009]\n",
            "loss: 0.000679  [ 1200/ 3009]\n",
            "loss: 0.000353  [ 1600/ 3009]\n",
            "loss: 0.006854  [ 2000/ 3009]\n",
            "loss: 0.104316  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.167022 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.005097  [    0/ 3009]\n",
            "loss: 0.000129  [  400/ 3009]\n",
            "loss: 0.024974  [  800/ 3009]\n",
            "loss: 0.000253  [ 1200/ 3009]\n",
            "loss: 0.011901  [ 1600/ 3009]\n",
            "loss: 0.007029  [ 2000/ 3009]\n",
            "loss: 0.000967  [ 2400/ 3009]\n",
            "loss: 0.011044  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.154647 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.004180  [    0/ 3009]\n",
            "loss: 0.003140  [  400/ 3009]\n",
            "loss: 0.000090  [  800/ 3009]\n",
            "loss: 0.005774  [ 1200/ 3009]\n",
            "loss: 0.002312  [ 1600/ 3009]\n",
            "loss: 0.013339  [ 2000/ 3009]\n",
            "loss: 0.000207  [ 2400/ 3009]\n",
            "loss: 0.002211  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.175322 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.000423  [    0/ 3009]\n",
            "loss: 0.000147  [  400/ 3009]\n",
            "loss: 0.000055  [  800/ 3009]\n",
            "loss: 0.015543  [ 1200/ 3009]\n",
            "loss: 0.028913  [ 1600/ 3009]\n",
            "loss: 0.005430  [ 2000/ 3009]\n",
            "loss: 0.000028  [ 2400/ 3009]\n",
            "loss: 0.000597  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.166417 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.000061  [    0/ 3009]\n",
            "loss: 0.001633  [  400/ 3009]\n",
            "loss: 0.000291  [  800/ 3009]\n",
            "loss: 0.000089  [ 1200/ 3009]\n",
            "loss: 0.020925  [ 1600/ 3009]\n",
            "loss: 0.000028  [ 2000/ 3009]\n",
            "loss: 0.003696  [ 2400/ 3009]\n",
            "loss: 0.000060  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.155416 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.010139  [    0/ 3009]\n",
            "loss: 0.066698  [  400/ 3009]\n",
            "loss: 0.000671  [  800/ 3009]\n",
            "loss: 0.000085  [ 1200/ 3009]\n",
            "loss: 0.000276  [ 1600/ 3009]\n",
            "loss: 0.002605  [ 2000/ 3009]\n",
            "loss: 0.000165  [ 2400/ 3009]\n",
            "loss: 0.000027  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.162361 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000006  [  400/ 3009]\n",
            "loss: 0.041081  [  800/ 3009]\n",
            "loss: 0.003264  [ 1200/ 3009]\n",
            "loss: 0.000467  [ 1600/ 3009]\n",
            "loss: 0.048200  [ 2000/ 3009]\n",
            "loss: 0.039574  [ 2400/ 3009]\n",
            "loss: 0.000425  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.151416 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.021040  [    0/ 3009]\n",
            "loss: 0.000160  [  400/ 3009]\n",
            "loss: 0.000219  [  800/ 3009]\n",
            "loss: 0.005459  [ 1200/ 3009]\n",
            "loss: 0.013106  [ 1600/ 3009]\n",
            "loss: 0.000053  [ 2000/ 3009]\n",
            "loss: 0.002090  [ 2400/ 3009]\n",
            "loss: 0.001894  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.168968 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000050  [    0/ 3009]\n",
            "loss: 0.017052  [  400/ 3009]\n",
            "loss: 0.000363  [  800/ 3009]\n",
            "loss: 0.002498  [ 1200/ 3009]\n",
            "loss: 0.000268  [ 1600/ 3009]\n",
            "loss: 0.006991  [ 2000/ 3009]\n",
            "loss: 0.045249  [ 2400/ 3009]\n",
            "loss: 0.011658  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.173392 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000062  [    0/ 3009]\n",
            "loss: 0.000031  [  400/ 3009]\n",
            "loss: 0.014742  [  800/ 3009]\n",
            "loss: 0.000024  [ 1200/ 3009]\n",
            "loss: 0.000007  [ 1600/ 3009]\n",
            "loss: 0.000023  [ 2000/ 3009]\n",
            "loss: 0.001202  [ 2400/ 3009]\n",
            "loss: 0.004634  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.160119 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000379  [    0/ 3009]\n",
            "loss: 0.000300  [  400/ 3009]\n",
            "loss: 0.009631  [  800/ 3009]\n",
            "loss: 0.000399  [ 1200/ 3009]\n",
            "loss: 0.000598  [ 1600/ 3009]\n",
            "loss: 0.000103  [ 2000/ 3009]\n",
            "loss: 0.000167  [ 2400/ 3009]\n",
            "loss: 0.000682  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.160553 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000996  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.020776  [  800/ 3009]\n",
            "loss: 0.024245  [ 1200/ 3009]\n",
            "loss: 0.000132  [ 1600/ 3009]\n",
            "loss: 0.000155  [ 2000/ 3009]\n",
            "loss: 0.000192  [ 2400/ 3009]\n",
            "loss: 0.001072  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.161217 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000144  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.002135  [ 1200/ 3009]\n",
            "loss: 0.000090  [ 1600/ 3009]\n",
            "loss: 0.002394  [ 2000/ 3009]\n",
            "loss: 0.000123  [ 2400/ 3009]\n",
            "loss: 0.001189  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.156678 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000041  [    0/ 3009]\n",
            "loss: 0.000616  [  400/ 3009]\n",
            "loss: 0.002966  [  800/ 3009]\n",
            "loss: 0.001999  [ 1200/ 3009]\n",
            "loss: 0.001361  [ 1600/ 3009]\n",
            "loss: 0.000239  [ 2000/ 3009]\n",
            "loss: 0.000717  [ 2400/ 3009]\n",
            "loss: 0.000512  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.164649 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000226  [    0/ 3009]\n",
            "loss: 0.026766  [  400/ 3009]\n",
            "loss: 0.005026  [  800/ 3009]\n",
            "loss: 0.000029  [ 1200/ 3009]\n",
            "loss: 0.001079  [ 1600/ 3009]\n",
            "loss: 0.018110  [ 2000/ 3009]\n",
            "loss: 0.000784  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.166159 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.002705  [    0/ 3009]\n",
            "loss: 0.004014  [  400/ 3009]\n",
            "loss: 0.035212  [  800/ 3009]\n",
            "loss: 0.000318  [ 1200/ 3009]\n",
            "loss: 0.000929  [ 1600/ 3009]\n",
            "loss: 0.002178  [ 2000/ 3009]\n",
            "loss: 0.000181  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.171491 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.016129  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000102  [  800/ 3009]\n",
            "loss: 0.003779  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000040  [ 2000/ 3009]\n",
            "loss: 0.000066  [ 2400/ 3009]\n",
            "loss: 0.000277  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.172783 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000428  [    0/ 3009]\n",
            "loss: 0.001039  [  400/ 3009]\n",
            "loss: 0.001337  [  800/ 3009]\n",
            "loss: 0.000274  [ 1200/ 3009]\n",
            "loss: 0.001302  [ 1600/ 3009]\n",
            "loss: 0.033152  [ 2000/ 3009]\n",
            "loss: 0.003783  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.181253 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.000005  [    0/ 3009]\n",
            "loss: 0.002499  [  400/ 3009]\n",
            "loss: 0.000008  [  800/ 3009]\n",
            "loss: 0.004401  [ 1200/ 3009]\n",
            "loss: 0.068300  [ 1600/ 3009]\n",
            "loss: 0.008697  [ 2000/ 3009]\n",
            "loss: 0.002127  [ 2400/ 3009]\n",
            "loss: 0.000010  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.171006 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.000529  [    0/ 3009]\n",
            "loss: 0.000326  [  400/ 3009]\n",
            "loss: 0.000373  [  800/ 3009]\n",
            "loss: 0.272356  [ 1200/ 3009]\n",
            "loss: 0.000018  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.006784  [ 2400/ 3009]\n",
            "loss: 0.000649  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.174016 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.084376  [    0/ 3009]\n",
            "loss: 0.000207  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.009462  [ 1200/ 3009]\n",
            "loss: 0.085622  [ 1600/ 3009]\n",
            "loss: 0.000011  [ 2000/ 3009]\n",
            "loss: 0.007533  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.171022 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.022494  [    0/ 3009]\n",
            "loss: 0.007423  [  400/ 3009]\n",
            "loss: 0.000033  [  800/ 3009]\n",
            "loss: 0.000482  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000100  [ 2000/ 3009]\n",
            "loss: 0.010109  [ 2400/ 3009]\n",
            "loss: 0.000028  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.175932 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.002752  [  400/ 3009]\n",
            "loss: 0.009352  [  800/ 3009]\n",
            "loss: 0.001733  [ 1200/ 3009]\n",
            "loss: 0.000699  [ 1600/ 3009]\n",
            "loss: 0.006911  [ 2000/ 3009]\n",
            "loss: 0.000460  [ 2400/ 3009]\n",
            "loss: 0.000007  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.171899 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.001191  [    0/ 3009]\n",
            "loss: 0.000155  [  400/ 3009]\n",
            "loss: 0.009148  [  800/ 3009]\n",
            "loss: 0.002606  [ 1200/ 3009]\n",
            "loss: 0.018559  [ 1600/ 3009]\n",
            "loss: 0.000797  [ 2000/ 3009]\n",
            "loss: 0.010289  [ 2400/ 3009]\n",
            "loss: 0.000774  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.166531 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000014  [    0/ 3009]\n",
            "loss: 0.004530  [  400/ 3009]\n",
            "loss: 0.000020  [  800/ 3009]\n",
            "loss: 0.001943  [ 1200/ 3009]\n",
            "loss: 0.000921  [ 1600/ 3009]\n",
            "loss: 0.000007  [ 2000/ 3009]\n",
            "loss: 0.007820  [ 2400/ 3009]\n",
            "loss: 0.000613  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.170632 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000084  [    0/ 3009]\n",
            "loss: 0.003558  [  400/ 3009]\n",
            "loss: 0.000743  [  800/ 3009]\n",
            "loss: 0.000058  [ 1200/ 3009]\n",
            "loss: 0.002681  [ 1600/ 3009]\n",
            "loss: 0.001313  [ 2000/ 3009]\n",
            "loss: 0.000540  [ 2400/ 3009]\n",
            "loss: 0.013770  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.167617 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000047  [    0/ 3009]\n",
            "loss: 0.004950  [  400/ 3009]\n",
            "loss: 0.002423  [  800/ 3009]\n",
            "loss: 0.002402  [ 1200/ 3009]\n",
            "loss: 0.000010  [ 1600/ 3009]\n",
            "loss: 0.005202  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.003336  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.173678 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000100  [    0/ 3009]\n",
            "loss: 0.000065  [  400/ 3009]\n",
            "loss: 0.000377  [  800/ 3009]\n",
            "loss: 0.000187  [ 1200/ 3009]\n",
            "loss: 0.000186  [ 1600/ 3009]\n",
            "loss: 0.001160  [ 2000/ 3009]\n",
            "loss: 0.001577  [ 2400/ 3009]\n",
            "loss: 0.014334  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.168203 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000195  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000069  [  800/ 3009]\n",
            "loss: 0.010472  [ 1200/ 3009]\n",
            "loss: 0.000912  [ 1600/ 3009]\n",
            "loss: 0.000260  [ 2000/ 3009]\n",
            "loss: 0.000116  [ 2400/ 3009]\n",
            "loss: 0.007766  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.172698 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.001013  [    0/ 3009]\n",
            "loss: 0.004374  [  400/ 3009]\n",
            "loss: 0.000117  [  800/ 3009]\n",
            "loss: 0.000053  [ 1200/ 3009]\n",
            "loss: 0.000187  [ 1600/ 3009]\n",
            "loss: 0.000931  [ 2000/ 3009]\n",
            "loss: 0.000276  [ 2400/ 3009]\n",
            "loss: 0.002475  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.178936 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.006434  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.001006  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.041918  [ 1600/ 3009]\n",
            "loss: 0.000899  [ 2000/ 3009]\n",
            "loss: 0.047346  [ 2400/ 3009]\n",
            "loss: 0.000049  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.178048 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000330  [    0/ 3009]\n",
            "loss: 0.000025  [  400/ 3009]\n",
            "loss: 0.001714  [  800/ 3009]\n",
            "loss: 0.001769  [ 1200/ 3009]\n",
            "loss: 0.062269  [ 1600/ 3009]\n",
            "loss: 0.007906  [ 2000/ 3009]\n",
            "loss: 0.017975  [ 2400/ 3009]\n",
            "loss: 0.000489  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.174374 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000098  [    0/ 3009]\n",
            "loss: 0.000513  [  400/ 3009]\n",
            "loss: 0.000110  [  800/ 3009]\n",
            "loss: 0.014240  [ 1200/ 3009]\n",
            "loss: 0.007216  [ 1600/ 3009]\n",
            "loss: 0.001682  [ 2000/ 3009]\n",
            "loss: 0.002542  [ 2400/ 3009]\n",
            "loss: 0.000270  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.185322 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000552  [    0/ 3009]\n",
            "loss: 0.000899  [  400/ 3009]\n",
            "loss: 0.010013  [  800/ 3009]\n",
            "loss: 0.000058  [ 1200/ 3009]\n",
            "loss: 0.002197  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.008665  [ 2400/ 3009]\n",
            "loss: 0.000068  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.177548 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.022259  [    0/ 3009]\n",
            "loss: 0.000831  [  400/ 3009]\n",
            "loss: 0.000145  [  800/ 3009]\n",
            "loss: 0.001739  [ 1200/ 3009]\n",
            "loss: 0.000138  [ 1600/ 3009]\n",
            "loss: 0.000278  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000339  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.181386 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.000014  [    0/ 3009]\n",
            "loss: 0.003632  [  400/ 3009]\n",
            "loss: 0.039184  [  800/ 3009]\n",
            "loss: 0.001804  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000015  [ 2000/ 3009]\n",
            "loss: 0.017208  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.190106 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.001398  [    0/ 3009]\n",
            "loss: 0.000835  [  400/ 3009]\n",
            "loss: 0.071883  [  800/ 3009]\n",
            "loss: 0.000051  [ 1200/ 3009]\n",
            "loss: 0.001842  [ 1600/ 3009]\n",
            "loss: 0.002584  [ 2000/ 3009]\n",
            "loss: 0.000326  [ 2400/ 3009]\n",
            "loss: 0.000019  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.179998 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.000026  [    0/ 3009]\n",
            "loss: 0.009698  [  400/ 3009]\n",
            "loss: 0.000411  [  800/ 3009]\n",
            "loss: 0.000332  [ 1200/ 3009]\n",
            "loss: 0.000423  [ 1600/ 3009]\n",
            "loss: 0.001852  [ 2000/ 3009]\n",
            "loss: 0.000628  [ 2400/ 3009]\n",
            "loss: 0.039570  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.176248 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.000838  [    0/ 3009]\n",
            "loss: 0.000704  [  400/ 3009]\n",
            "loss: 0.000526  [  800/ 3009]\n",
            "loss: 0.006417  [ 1200/ 3009]\n",
            "loss: 0.000023  [ 1600/ 3009]\n",
            "loss: 0.000965  [ 2000/ 3009]\n",
            "loss: 0.001280  [ 2400/ 3009]\n",
            "loss: 0.089113  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.180414 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.000441  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000012  [  800/ 3009]\n",
            "loss: 0.000951  [ 1200/ 3009]\n",
            "loss: 0.000008  [ 1600/ 3009]\n",
            "loss: 0.001949  [ 2000/ 3009]\n",
            "loss: 0.000964  [ 2400/ 3009]\n",
            "loss: 0.000109  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.184505 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.000062  [    0/ 3009]\n",
            "loss: 0.000596  [  400/ 3009]\n",
            "loss: 0.001509  [  800/ 3009]\n",
            "loss: 0.001355  [ 1200/ 3009]\n",
            "loss: 0.000167  [ 1600/ 3009]\n",
            "loss: 0.046991  [ 2000/ 3009]\n",
            "loss: 0.000014  [ 2400/ 3009]\n",
            "loss: 0.000006  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.175559 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.008125  [    0/ 3009]\n",
            "loss: 0.000584  [  400/ 3009]\n",
            "loss: 0.004498  [  800/ 3009]\n",
            "loss: 0.000014  [ 1200/ 3009]\n",
            "loss: 0.000072  [ 1600/ 3009]\n",
            "loss: 0.000010  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000020  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.182965 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000773  [  400/ 3009]\n",
            "loss: 0.000207  [  800/ 3009]\n",
            "loss: 0.009494  [ 1200/ 3009]\n",
            "loss: 0.000198  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.006318  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.182681 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.015801  [    0/ 3009]\n",
            "loss: 0.011589  [  400/ 3009]\n",
            "loss: 0.003853  [  800/ 3009]\n",
            "loss: 0.000153  [ 1200/ 3009]\n",
            "loss: 0.028640  [ 1600/ 3009]\n",
            "loss: 0.000042  [ 2000/ 3009]\n",
            "loss: 0.000146  [ 2400/ 3009]\n",
            "loss: 0.016767  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.183080 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000080  [  400/ 3009]\n",
            "loss: 0.000037  [  800/ 3009]\n",
            "loss: 0.019310  [ 1200/ 3009]\n",
            "loss: 0.000023  [ 1600/ 3009]\n",
            "loss: 0.000051  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.004242  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.181161 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.000118  [    0/ 3009]\n",
            "loss: 0.000287  [  400/ 3009]\n",
            "loss: 0.000578  [  800/ 3009]\n",
            "loss: 0.000024  [ 1200/ 3009]\n",
            "loss: 0.000582  [ 1600/ 3009]\n",
            "loss: 0.000052  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000152  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.180041 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.003040  [    0/ 3009]\n",
            "loss: 0.000279  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002556  [ 1600/ 3009]\n",
            "loss: 0.004111  [ 2000/ 3009]\n",
            "loss: 0.000004  [ 2400/ 3009]\n",
            "loss: 0.000386  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.193817 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.000007  [    0/ 3009]\n",
            "loss: 0.000083  [  400/ 3009]\n",
            "loss: 0.000182  [  800/ 3009]\n",
            "loss: 0.000049  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.028798  [ 2000/ 3009]\n",
            "loss: 0.000371  [ 2400/ 3009]\n",
            "loss: 0.000053  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.192072 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.029330  [    0/ 3009]\n",
            "loss: 0.000006  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000022  [ 1200/ 3009]\n",
            "loss: 0.002281  [ 1600/ 3009]\n",
            "loss: 0.000351  [ 2000/ 3009]\n",
            "loss: 0.000399  [ 2400/ 3009]\n",
            "loss: 0.000575  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.190382 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.000280  [    0/ 3009]\n",
            "loss: 0.002467  [  400/ 3009]\n",
            "loss: 0.002057  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000302  [ 1600/ 3009]\n",
            "loss: 0.000122  [ 2000/ 3009]\n",
            "loss: 0.000478  [ 2400/ 3009]\n",
            "loss: 0.002763  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.180828 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.010005  [    0/ 3009]\n",
            "loss: 0.000035  [  400/ 3009]\n",
            "loss: 0.000064  [  800/ 3009]\n",
            "loss: 0.000065  [ 1200/ 3009]\n",
            "loss: 0.000032  [ 1600/ 3009]\n",
            "loss: 0.030729  [ 2000/ 3009]\n",
            "loss: 0.004339  [ 2400/ 3009]\n",
            "loss: 0.000017  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.182850 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.005037  [    0/ 3009]\n",
            "loss: 0.000013  [  400/ 3009]\n",
            "loss: 0.001335  [  800/ 3009]\n",
            "loss: 0.000468  [ 1200/ 3009]\n",
            "loss: 0.000144  [ 1600/ 3009]\n",
            "loss: 0.000325  [ 2000/ 3009]\n",
            "loss: 0.002180  [ 2400/ 3009]\n",
            "loss: 0.000021  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.194414 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.000055  [    0/ 3009]\n",
            "loss: 0.012986  [  400/ 3009]\n",
            "loss: 0.001566  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000375  [ 1600/ 3009]\n",
            "loss: 0.000040  [ 2000/ 3009]\n",
            "loss: 0.000029  [ 2400/ 3009]\n",
            "loss: 0.001549  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.191401 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.000112  [    0/ 3009]\n",
            "loss: 0.001673  [  400/ 3009]\n",
            "loss: 0.005386  [  800/ 3009]\n",
            "loss: 0.000118  [ 1200/ 3009]\n",
            "loss: 0.000030  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000013  [ 2400/ 3009]\n",
            "loss: 0.010198  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.181927 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.000139  [    0/ 3009]\n",
            "loss: 0.004732  [  400/ 3009]\n",
            "loss: 0.002502  [  800/ 3009]\n",
            "loss: 0.000029  [ 1200/ 3009]\n",
            "loss: 0.004040  [ 1600/ 3009]\n",
            "loss: 0.019283  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.000228  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.199074 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.001521  [    0/ 3009]\n",
            "loss: 0.000174  [  400/ 3009]\n",
            "loss: 0.000011  [  800/ 3009]\n",
            "loss: 0.004734  [ 1200/ 3009]\n",
            "loss: 0.005026  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.002352  [ 2400/ 3009]\n",
            "loss: 0.002656  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.189146 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.003036  [    0/ 3009]\n",
            "loss: 0.000951  [  400/ 3009]\n",
            "loss: 0.000587  [  800/ 3009]\n",
            "loss: 0.000277  [ 1200/ 3009]\n",
            "loss: 0.003496  [ 1600/ 3009]\n",
            "loss: 0.000217  [ 2000/ 3009]\n",
            "loss: 0.000041  [ 2400/ 3009]\n",
            "loss: 0.004245  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.199368 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.006537  [    0/ 3009]\n",
            "loss: 0.001820  [  400/ 3009]\n",
            "loss: 0.000878  [  800/ 3009]\n",
            "loss: 0.000925  [ 1200/ 3009]\n",
            "loss: 0.002507  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.188495 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.004333  [    0/ 3009]\n",
            "loss: 0.004924  [  400/ 3009]\n",
            "loss: 0.000249  [  800/ 3009]\n",
            "loss: 0.000008  [ 1200/ 3009]\n",
            "loss: 0.002344  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.004054  [ 2400/ 3009]\n",
            "loss: 0.002004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.182629 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.001620  [    0/ 3009]\n",
            "loss: 0.002723  [  400/ 3009]\n",
            "loss: 0.004480  [  800/ 3009]\n",
            "loss: 0.000042  [ 1200/ 3009]\n",
            "loss: 0.000359  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.002723  [ 2400/ 3009]\n",
            "loss: 0.015624  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.182656 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.000090  [    0/ 3009]\n",
            "loss: 0.000005  [  400/ 3009]\n",
            "loss: 0.000096  [  800/ 3009]\n",
            "loss: 0.000930  [ 1200/ 3009]\n",
            "loss: 0.000056  [ 1600/ 3009]\n",
            "loss: 0.006329  [ 2000/ 3009]\n",
            "loss: 0.007300  [ 2400/ 3009]\n",
            "loss: 0.000210  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.186846 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.031989  [    0/ 3009]\n",
            "loss: 0.000079  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000273  [ 1200/ 3009]\n",
            "loss: 0.001357  [ 1600/ 3009]\n",
            "loss: 0.000087  [ 2000/ 3009]\n",
            "loss: 0.000088  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.194060 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.000463  [    0/ 3009]\n",
            "loss: 0.000040  [  400/ 3009]\n",
            "loss: 0.008026  [  800/ 3009]\n",
            "loss: 0.004091  [ 1200/ 3009]\n",
            "loss: 0.000044  [ 1600/ 3009]\n",
            "loss: 0.000073  [ 2000/ 3009]\n",
            "loss: 0.005822  [ 2400/ 3009]\n",
            "loss: 0.000089  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.194372 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.001221  [    0/ 3009]\n",
            "loss: 0.000020  [  400/ 3009]\n",
            "loss: 0.000029  [  800/ 3009]\n",
            "loss: 0.000187  [ 1200/ 3009]\n",
            "loss: 0.001483  [ 1600/ 3009]\n",
            "loss: 0.000589  [ 2000/ 3009]\n",
            "loss: 0.000032  [ 2400/ 3009]\n",
            "loss: 0.000073  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.184117 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.017045  [  400/ 3009]\n",
            "loss: 0.000894  [  800/ 3009]\n",
            "loss: 0.001865  [ 1200/ 3009]\n",
            "loss: 0.000275  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000092  [ 2400/ 3009]\n",
            "loss: 0.002860  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.184226 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.000435  [    0/ 3009]\n",
            "loss: 0.000224  [  400/ 3009]\n",
            "loss: 0.006836  [  800/ 3009]\n",
            "loss: 0.000021  [ 1200/ 3009]\n",
            "loss: 0.000027  [ 1600/ 3009]\n",
            "loss: 0.001039  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.204398 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.000093  [    0/ 3009]\n",
            "loss: 0.000080  [  400/ 3009]\n",
            "loss: 0.000078  [  800/ 3009]\n",
            "loss: 0.000014  [ 1200/ 3009]\n",
            "loss: 0.005667  [ 1600/ 3009]\n",
            "loss: 0.000029  [ 2000/ 3009]\n",
            "loss: 0.000842  [ 2400/ 3009]\n",
            "loss: 0.002301  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.196674 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.000166  [    0/ 3009]\n",
            "loss: 0.000016  [  400/ 3009]\n",
            "loss: 0.000427  [  800/ 3009]\n",
            "loss: 0.000176  [ 1200/ 3009]\n",
            "loss: 0.000019  [ 1600/ 3009]\n",
            "loss: 0.006808  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000271  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.199094 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.000635  [    0/ 3009]\n",
            "loss: 0.000015  [  400/ 3009]\n",
            "loss: 0.000265  [  800/ 3009]\n",
            "loss: 0.000313  [ 1200/ 3009]\n",
            "loss: 0.013998  [ 1600/ 3009]\n",
            "loss: 0.004569  [ 2000/ 3009]\n",
            "loss: 0.000554  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.212477 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.000074  [    0/ 3009]\n",
            "loss: 0.005650  [  400/ 3009]\n",
            "loss: 0.002027  [  800/ 3009]\n",
            "loss: 0.000005  [ 1200/ 3009]\n",
            "loss: 0.002782  [ 1600/ 3009]\n",
            "loss: 0.000216  [ 2000/ 3009]\n",
            "loss: 0.000314  [ 2400/ 3009]\n",
            "loss: 0.000121  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.187684 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.000209  [    0/ 3009]\n",
            "loss: 0.000091  [  400/ 3009]\n",
            "loss: 0.000234  [  800/ 3009]\n",
            "loss: 0.003489  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.001247  [ 2000/ 3009]\n",
            "loss: 0.026096  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.195748 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000044  [    0/ 3009]\n",
            "loss: 0.000151  [  400/ 3009]\n",
            "loss: 0.000005  [  800/ 3009]\n",
            "loss: 0.000036  [ 1200/ 3009]\n",
            "loss: 0.000090  [ 1600/ 3009]\n",
            "loss: 0.000406  [ 2000/ 3009]\n",
            "loss: 0.000020  [ 2400/ 3009]\n",
            "loss: 0.000760  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.200154 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.000714  [    0/ 3009]\n",
            "loss: 0.002359  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000739  [ 1200/ 3009]\n",
            "loss: 0.000026  [ 1600/ 3009]\n",
            "loss: 0.047850  [ 2000/ 3009]\n",
            "loss: 0.001598  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.199719 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.000427  [    0/ 3009]\n",
            "loss: 0.000104  [  400/ 3009]\n",
            "loss: 0.000542  [  800/ 3009]\n",
            "loss: 0.000011  [ 1200/ 3009]\n",
            "loss: 0.000183  [ 1600/ 3009]\n",
            "loss: 0.000119  [ 2000/ 3009]\n",
            "loss: 0.000004  [ 2400/ 3009]\n",
            "loss: 0.000006  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.198117 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.002844  [    0/ 3009]\n",
            "loss: 0.004624  [  400/ 3009]\n",
            "loss: 0.011500  [  800/ 3009]\n",
            "loss: 0.000044  [ 1200/ 3009]\n",
            "loss: 0.000909  [ 1600/ 3009]\n",
            "loss: 0.000497  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000348  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.204331 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.000231  [    0/ 3009]\n",
            "loss: 0.007369  [  400/ 3009]\n",
            "loss: 0.000190  [  800/ 3009]\n",
            "loss: 0.002083  [ 1200/ 3009]\n",
            "loss: 0.009576  [ 1600/ 3009]\n",
            "loss: 0.003081  [ 2000/ 3009]\n",
            "loss: 0.014041  [ 2400/ 3009]\n",
            "loss: 0.000690  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.196110 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.000436  [    0/ 3009]\n",
            "loss: 0.000056  [  400/ 3009]\n",
            "loss: 0.000007  [  800/ 3009]\n",
            "loss: 0.000037  [ 1200/ 3009]\n",
            "loss: 0.000520  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000049  [ 2400/ 3009]\n",
            "loss: 0.000022  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.191896 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.007094  [    0/ 3009]\n",
            "loss: 0.001470  [  400/ 3009]\n",
            "loss: 0.001537  [  800/ 3009]\n",
            "loss: 0.000025  [ 1200/ 3009]\n",
            "loss: 0.000033  [ 1600/ 3009]\n",
            "loss: 0.001926  [ 2000/ 3009]\n",
            "loss: 0.017191  [ 2400/ 3009]\n",
            "loss: 0.000031  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.198474 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.003047  [    0/ 3009]\n",
            "loss: 0.001037  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.022646  [ 1200/ 3009]\n",
            "loss: 0.003403  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000078  [ 2400/ 3009]\n",
            "loss: 0.000022  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.203600 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000031  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000049  [ 1200/ 3009]\n",
            "loss: 0.000050  [ 1600/ 3009]\n",
            "loss: 0.000029  [ 2000/ 3009]\n",
            "loss: 0.001634  [ 2400/ 3009]\n",
            "loss: 0.006021  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.199981 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.002150  [  400/ 3009]\n",
            "loss: 0.000198  [  800/ 3009]\n",
            "loss: 0.000823  [ 1200/ 3009]\n",
            "loss: 0.000156  [ 1600/ 3009]\n",
            "loss: 0.008946  [ 2000/ 3009]\n",
            "loss: 0.000016  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.200215 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.004661  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.001372  [ 1200/ 3009]\n",
            "loss: 0.006018  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000489  [ 2400/ 3009]\n",
            "loss: 0.000020  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.192408 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000050  [  400/ 3009]\n",
            "loss: 0.008503  [  800/ 3009]\n",
            "loss: 0.007920  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000121  [ 2000/ 3009]\n",
            "loss: 0.000005  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.206082 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000253  [    0/ 3009]\n",
            "loss: 0.000016  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000499  [ 1200/ 3009]\n",
            "loss: 0.001994  [ 1600/ 3009]\n",
            "loss: 0.013600  [ 2000/ 3009]\n",
            "loss: 0.001060  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.206786 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.000041  [    0/ 3009]\n",
            "loss: 0.000053  [  400/ 3009]\n",
            "loss: 0.000040  [  800/ 3009]\n",
            "loss: 0.000100  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000158  [ 2000/ 3009]\n",
            "loss: 0.000263  [ 2400/ 3009]\n",
            "loss: 0.009368  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.204226 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a593f89cec844f9b4ecfccf36e920be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▂▁▃▂▆▅▃▄▃▃▂▂▄▃▃▃▃▄▄▄▆▄▄▅▄▆▆▅▇▅▆▅▆█▇▆▆▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.20423</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silver-sweep-2</strong> at: <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/c21zf6bf' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/c21zf6bf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231221_114231-c21zf6bf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9joggbr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00035098726310255453\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231221_114635-n9joggbr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/n9joggbr' target=\"_blank\">fiery-sweep-3</a></strong> to <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/n9joggbr' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/n9joggbr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.001349  [    0/ 3009]\n",
            "loss: 0.000771  [  400/ 3009]\n",
            "loss: 0.000463  [  800/ 3009]\n",
            "loss: 0.000178  [ 1200/ 3009]\n",
            "loss: 0.002940  [ 1600/ 3009]\n",
            "loss: 0.000066  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.002808  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.195717 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.001022  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.012457  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000127  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.197098 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.000048  [    0/ 3009]\n",
            "loss: 0.000055  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000010  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.024498  [ 2000/ 3009]\n",
            "loss: 0.002747  [ 2400/ 3009]\n",
            "loss: 0.001161  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.205585 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.000080  [    0/ 3009]\n",
            "loss: 0.000010  [  400/ 3009]\n",
            "loss: 0.000241  [  800/ 3009]\n",
            "loss: 0.000569  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.001295  [ 2000/ 3009]\n",
            "loss: 0.007251  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.198267 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.000062  [    0/ 3009]\n",
            "loss: 0.000071  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000030  [ 2000/ 3009]\n",
            "loss: 0.001992  [ 2400/ 3009]\n",
            "loss: 0.000006  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.204229 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000133  [  400/ 3009]\n",
            "loss: 0.000225  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.003700  [ 1600/ 3009]\n",
            "loss: 0.000366  [ 2000/ 3009]\n",
            "loss: 0.006232  [ 2400/ 3009]\n",
            "loss: 0.000027  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.195503 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.004379  [  400/ 3009]\n",
            "loss: 0.000091  [  800/ 3009]\n",
            "loss: 0.003287  [ 1200/ 3009]\n",
            "loss: 0.000012  [ 1600/ 3009]\n",
            "loss: 0.007318  [ 2000/ 3009]\n",
            "loss: 0.000072  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.212547 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.000153  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000371  [  800/ 3009]\n",
            "loss: 0.000070  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000034  [ 2000/ 3009]\n",
            "loss: 0.000024  [ 2400/ 3009]\n",
            "loss: 0.000602  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.201549 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.002219  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000008  [  800/ 3009]\n",
            "loss: 0.000278  [ 1200/ 3009]\n",
            "loss: 0.000021  [ 1600/ 3009]\n",
            "loss: 0.000677  [ 2000/ 3009]\n",
            "loss: 0.000921  [ 2400/ 3009]\n",
            "loss: 0.003578  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.205782 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.001973  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.001558  [ 1200/ 3009]\n",
            "loss: 0.000311  [ 1600/ 3009]\n",
            "loss: 0.003927  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000208  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.201085 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000371  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000013  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.002725  [ 2400/ 3009]\n",
            "loss: 0.002678  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.201706 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.003184  [  400/ 3009]\n",
            "loss: 0.014542  [  800/ 3009]\n",
            "loss: 0.003098  [ 1200/ 3009]\n",
            "loss: 0.000070  [ 1600/ 3009]\n",
            "loss: 0.000005  [ 2000/ 3009]\n",
            "loss: 0.000101  [ 2400/ 3009]\n",
            "loss: 0.000268  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.203072 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.003661  [    0/ 3009]\n",
            "loss: 0.000044  [  400/ 3009]\n",
            "loss: 0.000273  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000113  [ 1600/ 3009]\n",
            "loss: 0.000532  [ 2000/ 3009]\n",
            "loss: 0.000895  [ 2400/ 3009]\n",
            "loss: 0.000498  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.202495 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.000942  [    0/ 3009]\n",
            "loss: 0.000696  [  400/ 3009]\n",
            "loss: 0.000311  [  800/ 3009]\n",
            "loss: 0.000137  [ 1200/ 3009]\n",
            "loss: 0.006735  [ 1600/ 3009]\n",
            "loss: 0.000057  [ 2000/ 3009]\n",
            "loss: 0.000251  [ 2400/ 3009]\n",
            "loss: 0.000009  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.200391 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.000046  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.001051  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000810  [ 1600/ 3009]\n",
            "loss: 0.000110  [ 2000/ 3009]\n",
            "loss: 0.000005  [ 2400/ 3009]\n",
            "loss: 0.000242  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.207332 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000026  [  400/ 3009]\n",
            "loss: 0.001230  [  800/ 3009]\n",
            "loss: 0.003160  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.001635  [ 2000/ 3009]\n",
            "loss: 0.000637  [ 2400/ 3009]\n",
            "loss: 0.000370  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.205670 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.004172  [  400/ 3009]\n",
            "loss: 0.000030  [  800/ 3009]\n",
            "loss: 0.000240  [ 1200/ 3009]\n",
            "loss: 0.000213  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000020  [ 2400/ 3009]\n",
            "loss: 0.033839  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.208792 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.001339  [    0/ 3009]\n",
            "loss: 0.000018  [  400/ 3009]\n",
            "loss: 0.001581  [  800/ 3009]\n",
            "loss: 0.000185  [ 1200/ 3009]\n",
            "loss: 0.000028  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.001728  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.209573 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.000035  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000357  [  800/ 3009]\n",
            "loss: 0.000131  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000042  [ 2000/ 3009]\n",
            "loss: 0.000225  [ 2400/ 3009]\n",
            "loss: 0.004811  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.208289 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.001749  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000012  [  800/ 3009]\n",
            "loss: 0.000029  [ 1200/ 3009]\n",
            "loss: 0.000508  [ 1600/ 3009]\n",
            "loss: 0.004821  [ 2000/ 3009]\n",
            "loss: 0.000196  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.206559 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.000174  [    0/ 3009]\n",
            "loss: 0.000028  [  400/ 3009]\n",
            "loss: 0.000022  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000016  [ 2000/ 3009]\n",
            "loss: 0.001082  [ 2400/ 3009]\n",
            "loss: 0.003279  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.216965 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000012  [    0/ 3009]\n",
            "loss: 0.000334  [  400/ 3009]\n",
            "loss: 0.000014  [  800/ 3009]\n",
            "loss: 0.000282  [ 1200/ 3009]\n",
            "loss: 0.000007  [ 1600/ 3009]\n",
            "loss: 0.000645  [ 2000/ 3009]\n",
            "loss: 0.000012  [ 2400/ 3009]\n",
            "loss: 0.006661  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.209294 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.002613  [    0/ 3009]\n",
            "loss: 0.000188  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000027  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.006027  [ 2000/ 3009]\n",
            "loss: 0.005528  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.201298 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000410  [    0/ 3009]\n",
            "loss: 0.000011  [  400/ 3009]\n",
            "loss: 0.000330  [  800/ 3009]\n",
            "loss: 0.001062  [ 1200/ 3009]\n",
            "loss: 0.000012  [ 1600/ 3009]\n",
            "loss: 0.000057  [ 2000/ 3009]\n",
            "loss: 0.000224  [ 2400/ 3009]\n",
            "loss: 0.001715  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.203162 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.004664  [  400/ 3009]\n",
            "loss: 0.000016  [  800/ 3009]\n",
            "loss: 0.000011  [ 1200/ 3009]\n",
            "loss: 0.003329  [ 1600/ 3009]\n",
            "loss: 0.001184  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.206817 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.001259  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000184  [  800/ 3009]\n",
            "loss: 0.001363  [ 1200/ 3009]\n",
            "loss: 0.001705  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.010924  [ 2400/ 3009]\n",
            "loss: 0.002533  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.211529 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.001020  [    0/ 3009]\n",
            "loss: 0.010195  [  400/ 3009]\n",
            "loss: 0.004342  [  800/ 3009]\n",
            "loss: 0.000152  [ 1200/ 3009]\n",
            "loss: 0.000038  [ 1600/ 3009]\n",
            "loss: 0.001212  [ 2000/ 3009]\n",
            "loss: 0.000584  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.211958 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000428  [  400/ 3009]\n",
            "loss: 0.000555  [  800/ 3009]\n",
            "loss: 0.002921  [ 1200/ 3009]\n",
            "loss: 0.000096  [ 1600/ 3009]\n",
            "loss: 0.000038  [ 2000/ 3009]\n",
            "loss: 0.000113  [ 2400/ 3009]\n",
            "loss: 0.005033  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.204414 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000016  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000492  [  800/ 3009]\n",
            "loss: 0.000035  [ 1200/ 3009]\n",
            "loss: 0.001625  [ 1600/ 3009]\n",
            "loss: 0.000345  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.003168  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.210112 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000301  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.001900  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000609  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.204219 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.000052  [    0/ 3009]\n",
            "loss: 0.002394  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000275  [ 1200/ 3009]\n",
            "loss: 0.000031  [ 1600/ 3009]\n",
            "loss: 0.003046  [ 2000/ 3009]\n",
            "loss: 0.004525  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.210237 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.000193  [  400/ 3009]\n",
            "loss: 0.000050  [  800/ 3009]\n",
            "loss: 0.004643  [ 1200/ 3009]\n",
            "loss: 0.001341  [ 1600/ 3009]\n",
            "loss: 0.000226  [ 2000/ 3009]\n",
            "loss: 0.000440  [ 2400/ 3009]\n",
            "loss: 0.000028  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.206447 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000173  [  400/ 3009]\n",
            "loss: 0.000867  [  800/ 3009]\n",
            "loss: 0.000200  [ 1200/ 3009]\n",
            "loss: 0.000055  [ 1600/ 3009]\n",
            "loss: 0.000058  [ 2000/ 3009]\n",
            "loss: 0.000015  [ 2400/ 3009]\n",
            "loss: 0.001409  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.206272 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.002483  [    0/ 3009]\n",
            "loss: 0.004095  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000038  [ 1200/ 3009]\n",
            "loss: 0.000007  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.005985  [ 2400/ 3009]\n",
            "loss: 0.000044  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.210448 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.004837  [    0/ 3009]\n",
            "loss: 0.000054  [  400/ 3009]\n",
            "loss: 0.005408  [  800/ 3009]\n",
            "loss: 0.000142  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000074  [ 2400/ 3009]\n",
            "loss: 0.000115  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.208785 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000036  [    0/ 3009]\n",
            "loss: 0.015259  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.010913  [ 1200/ 3009]\n",
            "loss: 0.000392  [ 1600/ 3009]\n",
            "loss: 0.000373  [ 2000/ 3009]\n",
            "loss: 0.004987  [ 2400/ 3009]\n",
            "loss: 0.000007  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.206541 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.004661  [    0/ 3009]\n",
            "loss: 0.001019  [  400/ 3009]\n",
            "loss: 0.002449  [  800/ 3009]\n",
            "loss: 0.000140  [ 1200/ 3009]\n",
            "loss: 0.001006  [ 1600/ 3009]\n",
            "loss: 0.000016  [ 2000/ 3009]\n",
            "loss: 0.003641  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.212564 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.001457  [    0/ 3009]\n",
            "loss: 0.001205  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.003443  [ 1200/ 3009]\n",
            "loss: 0.006778  [ 1600/ 3009]\n",
            "loss: 0.000452  [ 2000/ 3009]\n",
            "loss: 0.000005  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.203457 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.001217  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.003668  [  800/ 3009]\n",
            "loss: 0.000068  [ 1200/ 3009]\n",
            "loss: 0.000453  [ 1600/ 3009]\n",
            "loss: 0.000037  [ 2000/ 3009]\n",
            "loss: 0.000007  [ 2400/ 3009]\n",
            "loss: 0.000484  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.213069 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.003864  [  400/ 3009]\n",
            "loss: 0.000031  [  800/ 3009]\n",
            "loss: 0.000014  [ 1200/ 3009]\n",
            "loss: 0.000025  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000276  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.208857 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000050  [    0/ 3009]\n",
            "loss: 0.000240  [  400/ 3009]\n",
            "loss: 0.000424  [  800/ 3009]\n",
            "loss: 0.000126  [ 1200/ 3009]\n",
            "loss: 0.000089  [ 1600/ 3009]\n",
            "loss: 0.000010  [ 2000/ 3009]\n",
            "loss: 0.000979  [ 2400/ 3009]\n",
            "loss: 0.000148  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.215938 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000047  [    0/ 3009]\n",
            "loss: 0.009952  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.004925  [ 1600/ 3009]\n",
            "loss: 0.000641  [ 2000/ 3009]\n",
            "loss: 0.003345  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.210099 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000041  [    0/ 3009]\n",
            "loss: 0.000349  [  400/ 3009]\n",
            "loss: 0.000485  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000355  [ 1600/ 3009]\n",
            "loss: 0.000202  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000020  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.216849 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.001126  [    0/ 3009]\n",
            "loss: 0.000863  [  400/ 3009]\n",
            "loss: 0.000504  [  800/ 3009]\n",
            "loss: 0.010170  [ 1200/ 3009]\n",
            "loss: 0.000017  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000006  [ 2400/ 3009]\n",
            "loss: 0.002570  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.211504 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.018326  [ 1600/ 3009]\n",
            "loss: 0.000008  [ 2000/ 3009]\n",
            "loss: 0.000012  [ 2400/ 3009]\n",
            "loss: 0.000281  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.211537 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000357  [    0/ 3009]\n",
            "loss: 0.000005  [  400/ 3009]\n",
            "loss: 0.000376  [  800/ 3009]\n",
            "loss: 0.006498  [ 1200/ 3009]\n",
            "loss: 0.001148  [ 1600/ 3009]\n",
            "loss: 0.000008  [ 2000/ 3009]\n",
            "loss: 0.000010  [ 2400/ 3009]\n",
            "loss: 0.004152  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.215467 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.005911  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000999  [ 1600/ 3009]\n",
            "loss: 0.000150  [ 2000/ 3009]\n",
            "loss: 0.000115  [ 2400/ 3009]\n",
            "loss: 0.004367  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.214159 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.001509  [  400/ 3009]\n",
            "loss: 0.000416  [  800/ 3009]\n",
            "loss: 0.000391  [ 1200/ 3009]\n",
            "loss: 0.000480  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.001182  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.215979 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000724  [  400/ 3009]\n",
            "loss: 0.000028  [  800/ 3009]\n",
            "loss: 0.004423  [ 1200/ 3009]\n",
            "loss: 0.000186  [ 1600/ 3009]\n",
            "loss: 0.000056  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.217676 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000005  [    0/ 3009]\n",
            "loss: 0.000705  [  400/ 3009]\n",
            "loss: 0.000017  [  800/ 3009]\n",
            "loss: 0.000013  [ 1200/ 3009]\n",
            "loss: 0.000041  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000175  [ 2400/ 3009]\n",
            "loss: 0.000009  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.209648 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.000070  [    0/ 3009]\n",
            "loss: 0.000034  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000526  [ 1200/ 3009]\n",
            "loss: 0.000019  [ 1600/ 3009]\n",
            "loss: 0.000323  [ 2000/ 3009]\n",
            "loss: 0.000103  [ 2400/ 3009]\n",
            "loss: 0.001208  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.215310 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.000664  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.001593  [  800/ 3009]\n",
            "loss: 0.000013  [ 1200/ 3009]\n",
            "loss: 0.000155  [ 1600/ 3009]\n",
            "loss: 0.001766  [ 2000/ 3009]\n",
            "loss: 0.000677  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.213024 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.000152  [    0/ 3009]\n",
            "loss: 0.000030  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000159  [ 1200/ 3009]\n",
            "loss: 0.000010  [ 1600/ 3009]\n",
            "loss: 0.000338  [ 2000/ 3009]\n",
            "loss: 0.001081  [ 2400/ 3009]\n",
            "loss: 0.000299  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.212077 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.001176  [    0/ 3009]\n",
            "loss: 0.000017  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000168  [ 1200/ 3009]\n",
            "loss: 0.000910  [ 1600/ 3009]\n",
            "loss: 0.000060  [ 2000/ 3009]\n",
            "loss: 0.000017  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.220603 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.001367  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.000091  [  800/ 3009]\n",
            "loss: 0.004290  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000024  [ 2000/ 3009]\n",
            "loss: 0.000040  [ 2400/ 3009]\n",
            "loss: 0.000007  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.222329 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000437  [  400/ 3009]\n",
            "loss: 0.000021  [  800/ 3009]\n",
            "loss: 0.001918  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000580  [ 2000/ 3009]\n",
            "loss: 0.000128  [ 2400/ 3009]\n",
            "loss: 0.002453  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.215443 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000062  [  400/ 3009]\n",
            "loss: 0.000059  [  800/ 3009]\n",
            "loss: 0.000031  [ 1200/ 3009]\n",
            "loss: 0.002238  [ 1600/ 3009]\n",
            "loss: 0.001122  [ 2000/ 3009]\n",
            "loss: 0.000468  [ 2400/ 3009]\n",
            "loss: 0.001001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.217629 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.000068  [    0/ 3009]\n",
            "loss: 0.000011  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.000051  [ 1200/ 3009]\n",
            "loss: 0.000288  [ 1600/ 3009]\n",
            "loss: 0.002230  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.003984  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.217462 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.000049  [    0/ 3009]\n",
            "loss: 0.000082  [  400/ 3009]\n",
            "loss: 0.000452  [  800/ 3009]\n",
            "loss: 0.000242  [ 1200/ 3009]\n",
            "loss: 0.002859  [ 1600/ 3009]\n",
            "loss: 0.000025  [ 2000/ 3009]\n",
            "loss: 0.001397  [ 2400/ 3009]\n",
            "loss: 0.002545  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.214733 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.000620  [    0/ 3009]\n",
            "loss: 0.003422  [  400/ 3009]\n",
            "loss: 0.000047  [  800/ 3009]\n",
            "loss: 0.000427  [ 1200/ 3009]\n",
            "loss: 0.000025  [ 1600/ 3009]\n",
            "loss: 0.000042  [ 2000/ 3009]\n",
            "loss: 0.000011  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.225883 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.017738  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.001081  [  800/ 3009]\n",
            "loss: 0.000427  [ 1200/ 3009]\n",
            "loss: 0.000124  [ 1600/ 3009]\n",
            "loss: 0.000050  [ 2000/ 3009]\n",
            "loss: 0.000005  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.215562 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000032  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000088  [ 2400/ 3009]\n",
            "loss: 0.000546  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.211633 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.000262  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000612  [  800/ 3009]\n",
            "loss: 0.000029  [ 1200/ 3009]\n",
            "loss: 0.000328  [ 1600/ 3009]\n",
            "loss: 0.000009  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000471  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.218440 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.000402  [    0/ 3009]\n",
            "loss: 0.001954  [  400/ 3009]\n",
            "loss: 0.000913  [  800/ 3009]\n",
            "loss: 0.006650  [ 1200/ 3009]\n",
            "loss: 0.000066  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.011363  [ 2400/ 3009]\n",
            "loss: 0.000010  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.211432 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.000007  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.000139  [  800/ 3009]\n",
            "loss: 0.007601  [ 1200/ 3009]\n",
            "loss: 0.000618  [ 1600/ 3009]\n",
            "loss: 0.001100  [ 2000/ 3009]\n",
            "loss: 0.001006  [ 2400/ 3009]\n",
            "loss: 0.001676  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.235735 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.002212  [    0/ 3009]\n",
            "loss: 0.005710  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000009  [ 1200/ 3009]\n",
            "loss: 0.004695  [ 1600/ 3009]\n",
            "loss: 0.019216  [ 2000/ 3009]\n",
            "loss: 0.000024  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.211945 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.000037  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000009  [ 1200/ 3009]\n",
            "loss: 0.000161  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000953  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.223421 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.002662  [    0/ 3009]\n",
            "loss: 0.000028  [  400/ 3009]\n",
            "loss: 0.002132  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000013  [ 1600/ 3009]\n",
            "loss: 0.000024  [ 2000/ 3009]\n",
            "loss: 0.000301  [ 2400/ 3009]\n",
            "loss: 0.002732  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.216098 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.001035  [  800/ 3009]\n",
            "loss: 0.000957  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000406  [ 2000/ 3009]\n",
            "loss: 0.001297  [ 2400/ 3009]\n",
            "loss: 0.000116  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.211922 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000092  [  400/ 3009]\n",
            "loss: 0.000003  [  800/ 3009]\n",
            "loss: 0.001430  [ 1200/ 3009]\n",
            "loss: 0.002555  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000030  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.213112 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.003617  [    0/ 3009]\n",
            "loss: 0.000039  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000021  [ 1200/ 3009]\n",
            "loss: 0.000532  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.217216 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.000008  [    0/ 3009]\n",
            "loss: 0.001483  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000045  [ 1600/ 3009]\n",
            "loss: 0.000348  [ 2000/ 3009]\n",
            "loss: 0.000092  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.210973 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.000232  [    0/ 3009]\n",
            "loss: 0.001343  [  400/ 3009]\n",
            "loss: 0.002340  [  800/ 3009]\n",
            "loss: 0.000011  [ 1200/ 3009]\n",
            "loss: 0.001026  [ 1600/ 3009]\n",
            "loss: 0.003023  [ 2000/ 3009]\n",
            "loss: 0.000368  [ 2400/ 3009]\n",
            "loss: 0.001588  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.215887 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.004058  [    0/ 3009]\n",
            "loss: 0.004518  [  400/ 3009]\n",
            "loss: 0.000041  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.002614  [ 2000/ 3009]\n",
            "loss: 0.001144  [ 2400/ 3009]\n",
            "loss: 0.000019  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.218993 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.000025  [    0/ 3009]\n",
            "loss: 0.000055  [  400/ 3009]\n",
            "loss: 0.000739  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.006923  [ 2000/ 3009]\n",
            "loss: 0.002303  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.217242 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000141  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000034  [ 1200/ 3009]\n",
            "loss: 0.000038  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.003025  [ 2400/ 3009]\n",
            "loss: 0.000170  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.222084 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.000018  [    0/ 3009]\n",
            "loss: 0.004588  [  400/ 3009]\n",
            "loss: 0.000428  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000077  [ 1600/ 3009]\n",
            "loss: 0.000502  [ 2000/ 3009]\n",
            "loss: 0.000005  [ 2400/ 3009]\n",
            "loss: 0.000033  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.219769 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.000173  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.005184  [  800/ 3009]\n",
            "loss: 0.000052  [ 1200/ 3009]\n",
            "loss: 0.000005  [ 1600/ 3009]\n",
            "loss: 0.000215  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000350  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.217394 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.000958  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.000049  [  800/ 3009]\n",
            "loss: 0.002831  [ 1200/ 3009]\n",
            "loss: 0.000062  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000620  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.221009 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.000235  [    0/ 3009]\n",
            "loss: 0.000615  [  400/ 3009]\n",
            "loss: 0.000397  [  800/ 3009]\n",
            "loss: 0.001310  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.216985 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.000119  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000279  [  800/ 3009]\n",
            "loss: 0.000197  [ 1200/ 3009]\n",
            "loss: 0.000657  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.222379 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.001753  [  800/ 3009]\n",
            "loss: 0.000017  [ 1200/ 3009]\n",
            "loss: 0.003433  [ 1600/ 3009]\n",
            "loss: 0.000279  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000083  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.216098 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000039  [  800/ 3009]\n",
            "loss: 0.000474  [ 1200/ 3009]\n",
            "loss: 0.000012  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.001356  [ 2400/ 3009]\n",
            "loss: 0.005837  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.226851 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000248  [  400/ 3009]\n",
            "loss: 0.000650  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002134  [ 1600/ 3009]\n",
            "loss: 0.000200  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000178  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.219389 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.016608  [ 1600/ 3009]\n",
            "loss: 0.000104  [ 2000/ 3009]\n",
            "loss: 0.000010  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.223033 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.000010  [    0/ 3009]\n",
            "loss: 0.001151  [  400/ 3009]\n",
            "loss: 0.013456  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.001357  [ 1600/ 3009]\n",
            "loss: 0.000068  [ 2000/ 3009]\n",
            "loss: 0.007536  [ 2400/ 3009]\n",
            "loss: 0.000545  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.228573 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000670  [  400/ 3009]\n",
            "loss: 0.000772  [  800/ 3009]\n",
            "loss: 0.000045  [ 1200/ 3009]\n",
            "loss: 0.027676  [ 1600/ 3009]\n",
            "loss: 0.000013  [ 2000/ 3009]\n",
            "loss: 0.000037  [ 2400/ 3009]\n",
            "loss: 0.000200  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.221244 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000296  [  400/ 3009]\n",
            "loss: 0.000886  [  800/ 3009]\n",
            "loss: 0.000942  [ 1200/ 3009]\n",
            "loss: 0.000005  [ 1600/ 3009]\n",
            "loss: 0.000136  [ 2000/ 3009]\n",
            "loss: 0.001461  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.215067 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.002732  [    0/ 3009]\n",
            "loss: 0.000403  [  400/ 3009]\n",
            "loss: 0.000009  [  800/ 3009]\n",
            "loss: 0.002808  [ 1200/ 3009]\n",
            "loss: 0.000108  [ 1600/ 3009]\n",
            "loss: 0.003917  [ 2000/ 3009]\n",
            "loss: 0.000075  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.243054 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.000659  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.003134  [ 1200/ 3009]\n",
            "loss: 0.000336  [ 1600/ 3009]\n",
            "loss: 0.001604  [ 2000/ 3009]\n",
            "loss: 0.000234  [ 2400/ 3009]\n",
            "loss: 0.002015  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.219574 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.001520  [    0/ 3009]\n",
            "loss: 0.000104  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000243  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000020  [ 2400/ 3009]\n",
            "loss: 0.000229  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.234122 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.000553  [    0/ 3009]\n",
            "loss: 0.000306  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000923  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000877  [ 2400/ 3009]\n",
            "loss: 0.000133  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.216648 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000034  [  400/ 3009]\n",
            "loss: 0.001098  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.000188  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.220565 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.000274  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.004681  [  800/ 3009]\n",
            "loss: 0.000161  [ 1200/ 3009]\n",
            "loss: 0.000020  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.004873  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.223620 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000007  [    0/ 3009]\n",
            "loss: 0.001563  [  400/ 3009]\n",
            "loss: 0.001194  [  800/ 3009]\n",
            "loss: 0.002994  [ 1200/ 3009]\n",
            "loss: 0.000058  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000018  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.217462 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000021  [    0/ 3009]\n",
            "loss: 0.000987  [  400/ 3009]\n",
            "loss: 0.000162  [  800/ 3009]\n",
            "loss: 0.002187  [ 1200/ 3009]\n",
            "loss: 0.002059  [ 1600/ 3009]\n",
            "loss: 0.000005  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000079  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.223826 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.001328  [    0/ 3009]\n",
            "loss: 0.000024  [  400/ 3009]\n",
            "loss: 0.000021  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000141  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.227688 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.000279  [    0/ 3009]\n",
            "loss: 0.000068  [  400/ 3009]\n",
            "loss: 0.000049  [  800/ 3009]\n",
            "loss: 0.000768  [ 1200/ 3009]\n",
            "loss: 0.001406  [ 1600/ 3009]\n",
            "loss: 0.002912  [ 2000/ 3009]\n",
            "loss: 0.000151  [ 2400/ 3009]\n",
            "loss: 0.000942  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.223243 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000107  [    0/ 3009]\n",
            "loss: 0.000301  [  400/ 3009]\n",
            "loss: 0.000336  [  800/ 3009]\n",
            "loss: 0.000045  [ 1200/ 3009]\n",
            "loss: 0.000122  [ 1600/ 3009]\n",
            "loss: 0.006063  [ 2000/ 3009]\n",
            "loss: 0.000368  [ 2400/ 3009]\n",
            "loss: 0.001612  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.224943 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.000011  [    0/ 3009]\n",
            "loss: 0.000031  [  400/ 3009]\n",
            "loss: 0.000029  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000007  [ 1600/ 3009]\n",
            "loss: 0.000240  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000057  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.223277 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d23dbe3411641118384047e7220744c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▂▁▂▂▂▂▃▄▂▃▂▃▃▃▄▄▃▄▄▄▅▄▄▄▃▅▃▃▄▅▅▄▅▅█▄▅▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.22328</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fiery-sweep-3</strong> at: <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/n9joggbr' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/n9joggbr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231221_114635-n9joggbr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6srai5wy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004648150808940979\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231221_115044-6srai5wy</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/6srai5wy' target=\"_blank\">fancy-sweep-4</a></strong> to <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/6srai5wy' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/6srai5wy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.002636  [    0/ 3009]\n",
            "loss: 0.002276  [  400/ 3009]\n",
            "loss: 0.000326  [  800/ 3009]\n",
            "loss: 0.000156  [ 1200/ 3009]\n",
            "loss: 0.000039  [ 1600/ 3009]\n",
            "loss: 0.000035  [ 2000/ 3009]\n",
            "loss: 0.000589  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.235111 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.000560  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000003  [  800/ 3009]\n",
            "loss: 0.000032  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000284  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.228522 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000012  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002845  [ 1600/ 3009]\n",
            "loss: 0.001182  [ 2000/ 3009]\n",
            "loss: 0.000050  [ 2400/ 3009]\n",
            "loss: 0.000309  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.226749 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.000010  [    0/ 3009]\n",
            "loss: 0.002499  [  400/ 3009]\n",
            "loss: 0.001490  [  800/ 3009]\n",
            "loss: 0.000013  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.001649  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000077  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.224945 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.009629  [    0/ 3009]\n",
            "loss: 0.009727  [  400/ 3009]\n",
            "loss: 0.000030  [  800/ 3009]\n",
            "loss: 0.000193  [ 1200/ 3009]\n",
            "loss: 0.001786  [ 1600/ 3009]\n",
            "loss: 0.001362  [ 2000/ 3009]\n",
            "loss: 0.000009  [ 2400/ 3009]\n",
            "loss: 0.000132  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.230239 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.000031  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000064  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.226447 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.000042  [    0/ 3009]\n",
            "loss: 0.000038  [  400/ 3009]\n",
            "loss: 0.000017  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000029  [ 1600/ 3009]\n",
            "loss: 0.000092  [ 2000/ 3009]\n",
            "loss: 0.000055  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.225808 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.000102  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000049  [  800/ 3009]\n",
            "loss: 0.001142  [ 1200/ 3009]\n",
            "loss: 0.000102  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000032  [ 2400/ 3009]\n",
            "loss: 0.000198  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.225184 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000005  [  400/ 3009]\n",
            "loss: 0.000014  [  800/ 3009]\n",
            "loss: 0.000127  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000057  [ 2000/ 3009]\n",
            "loss: 0.000215  [ 2400/ 3009]\n",
            "loss: 0.000126  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.228842 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.000376  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000121  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000886  [ 2000/ 3009]\n",
            "loss: 0.000265  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.221213 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000020  [ 1600/ 3009]\n",
            "loss: 0.000323  [ 2000/ 3009]\n",
            "loss: 0.000048  [ 2400/ 3009]\n",
            "loss: 0.000343  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.224968 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.000508  [    0/ 3009]\n",
            "loss: 0.000421  [  400/ 3009]\n",
            "loss: 0.000060  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000112  [ 1600/ 3009]\n",
            "loss: 0.000885  [ 2000/ 3009]\n",
            "loss: 0.004014  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.234587 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.001330  [ 1200/ 3009]\n",
            "loss: 0.000070  [ 1600/ 3009]\n",
            "loss: 0.004883  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.018200  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.224703 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.000075  [    0/ 3009]\n",
            "loss: 0.000077  [  400/ 3009]\n",
            "loss: 0.000039  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000223  [ 1600/ 3009]\n",
            "loss: 0.000937  [ 2000/ 3009]\n",
            "loss: 0.002170  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.226043 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.001551  [  800/ 3009]\n",
            "loss: 0.000740  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000017  [ 2000/ 3009]\n",
            "loss: 0.000117  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.221225 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.000197  [    0/ 3009]\n",
            "loss: 0.000007  [  400/ 3009]\n",
            "loss: 0.001940  [  800/ 3009]\n",
            "loss: 0.000102  [ 1200/ 3009]\n",
            "loss: 0.000051  [ 1600/ 3009]\n",
            "loss: 0.000003  [ 2000/ 3009]\n",
            "loss: 0.000055  [ 2400/ 3009]\n",
            "loss: 0.001111  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.228807 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000046  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000035  [ 1200/ 3009]\n",
            "loss: 0.000620  [ 1600/ 3009]\n",
            "loss: 0.003644  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.220236 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.001651  [    0/ 3009]\n",
            "loss: 0.000252  [  400/ 3009]\n",
            "loss: 0.000051  [  800/ 3009]\n",
            "loss: 0.000014  [ 1200/ 3009]\n",
            "loss: 0.000011  [ 1600/ 3009]\n",
            "loss: 0.000125  [ 2000/ 3009]\n",
            "loss: 0.000893  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.222703 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.000283  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000914  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.001824  [ 1600/ 3009]\n",
            "loss: 0.000173  [ 2000/ 3009]\n",
            "loss: 0.000166  [ 2400/ 3009]\n",
            "loss: 0.000016  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.225181 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.000523  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.001208  [  800/ 3009]\n",
            "loss: 0.000620  [ 1200/ 3009]\n",
            "loss: 0.011573  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000543  [ 2400/ 3009]\n",
            "loss: 0.000126  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.222366 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.006226  [    0/ 3009]\n",
            "loss: 0.000346  [  400/ 3009]\n",
            "loss: 0.002202  [  800/ 3009]\n",
            "loss: 0.000057  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.000003  [ 2000/ 3009]\n",
            "loss: 0.003083  [ 2400/ 3009]\n",
            "loss: 0.002897  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.232884 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000225  [    0/ 3009]\n",
            "loss: 0.000076  [  400/ 3009]\n",
            "loss: 0.000107  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000085  [ 2000/ 3009]\n",
            "loss: 0.000359  [ 2400/ 3009]\n",
            "loss: 0.001137  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.229332 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.002991  [    0/ 3009]\n",
            "loss: 0.000193  [  400/ 3009]\n",
            "loss: 0.000046  [  800/ 3009]\n",
            "loss: 0.000109  [ 1200/ 3009]\n",
            "loss: 0.002689  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000113  [ 2400/ 3009]\n",
            "loss: 0.000195  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.227961 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000042  [    0/ 3009]\n",
            "loss: 0.000027  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000443  [ 1200/ 3009]\n",
            "loss: 0.000776  [ 1600/ 3009]\n",
            "loss: 0.000007  [ 2000/ 3009]\n",
            "loss: 0.000053  [ 2400/ 3009]\n",
            "loss: 0.000497  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.223100 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000009  [  400/ 3009]\n",
            "loss: 0.000053  [  800/ 3009]\n",
            "loss: 0.000013  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000102  [ 2000/ 3009]\n",
            "loss: 0.000044  [ 2400/ 3009]\n",
            "loss: 0.000134  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.224967 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.017900  [  400/ 3009]\n",
            "loss: 0.000016  [  800/ 3009]\n",
            "loss: 0.000026  [ 1200/ 3009]\n",
            "loss: 0.000035  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000016  [ 2400/ 3009]\n",
            "loss: 0.000159  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.223800 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000921  [    0/ 3009]\n",
            "loss: 0.000013  [  400/ 3009]\n",
            "loss: 0.000029  [  800/ 3009]\n",
            "loss: 0.001222  [ 1200/ 3009]\n",
            "loss: 0.000207  [ 1600/ 3009]\n",
            "loss: 0.000118  [ 2000/ 3009]\n",
            "loss: 0.000012  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.228081 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000014  [    0/ 3009]\n",
            "loss: 0.001702  [  400/ 3009]\n",
            "loss: 0.000386  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000141  [ 1600/ 3009]\n",
            "loss: 0.000563  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000250  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.228280 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000063  [    0/ 3009]\n",
            "loss: 0.001108  [  400/ 3009]\n",
            "loss: 0.000148  [  800/ 3009]\n",
            "loss: 0.001774  [ 1200/ 3009]\n",
            "loss: 0.000048  [ 1600/ 3009]\n",
            "loss: 0.000442  [ 2000/ 3009]\n",
            "loss: 0.000769  [ 2400/ 3009]\n",
            "loss: 0.010521  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.230403 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000165  [  800/ 3009]\n",
            "loss: 0.000098  [ 1200/ 3009]\n",
            "loss: 0.000010  [ 1600/ 3009]\n",
            "loss: 0.000069  [ 2000/ 3009]\n",
            "loss: 0.000048  [ 2400/ 3009]\n",
            "loss: 0.001505  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.230867 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.000603  [    0/ 3009]\n",
            "loss: 0.000439  [  400/ 3009]\n",
            "loss: 0.000187  [  800/ 3009]\n",
            "loss: 0.002679  [ 1200/ 3009]\n",
            "loss: 0.003183  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.002199  [ 2400/ 3009]\n",
            "loss: 0.000146  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.226360 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000123  [  400/ 3009]\n",
            "loss: 0.009723  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.001550  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000007  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.236296 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000009  [    0/ 3009]\n",
            "loss: 0.002885  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000018  [ 1600/ 3009]\n",
            "loss: 0.000051  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.228203 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.000235  [    0/ 3009]\n",
            "loss: 0.000084  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.001223  [ 1600/ 3009]\n",
            "loss: 0.006411  [ 2000/ 3009]\n",
            "loss: 0.000870  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.229269 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000015  [  800/ 3009]\n",
            "loss: 0.001862  [ 1200/ 3009]\n",
            "loss: 0.005944  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000097  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.228653 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.001910  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.007203  [ 1600/ 3009]\n",
            "loss: 0.000012  [ 2000/ 3009]\n",
            "loss: 0.000530  [ 2400/ 3009]\n",
            "loss: 0.001076  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.230439 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.000011  [    0/ 3009]\n",
            "loss: 0.000006  [  400/ 3009]\n",
            "loss: 0.001996  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000736  [ 1600/ 3009]\n",
            "loss: 0.000084  [ 2000/ 3009]\n",
            "loss: 0.000470  [ 2400/ 3009]\n",
            "loss: 0.000897  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.240720 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000632  [    0/ 3009]\n",
            "loss: 0.000045  [  400/ 3009]\n",
            "loss: 0.001549  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002016  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000182  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.229128 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000150  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000089  [  800/ 3009]\n",
            "loss: 0.000005  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000137  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000112  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.232248 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000133  [    0/ 3009]\n",
            "loss: 0.000026  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000074  [ 2400/ 3009]\n",
            "loss: 0.000487  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.224118 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.001539  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000147  [ 1200/ 3009]\n",
            "loss: 0.000051  [ 1600/ 3009]\n",
            "loss: 0.002216  [ 2000/ 3009]\n",
            "loss: 0.000018  [ 2400/ 3009]\n",
            "loss: 0.000190  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.234952 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000016  [    0/ 3009]\n",
            "loss: 0.000026  [  400/ 3009]\n",
            "loss: 0.000411  [  800/ 3009]\n",
            "loss: 0.004903  [ 1200/ 3009]\n",
            "loss: 0.001820  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000050  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.232257 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000109  [  400/ 3009]\n",
            "loss: 0.000592  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000077  [ 2400/ 3009]\n",
            "loss: 0.000703  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.231566 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000016  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000215  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000195  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.231493 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.003801  [    0/ 3009]\n",
            "loss: 0.000299  [  400/ 3009]\n",
            "loss: 0.000080  [  800/ 3009]\n",
            "loss: 0.000025  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000060  [ 2000/ 3009]\n",
            "loss: 0.000390  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.230119 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000009  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000075  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000319  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000037  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.226440 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000202  [  800/ 3009]\n",
            "loss: 0.000200  [ 1200/ 3009]\n",
            "loss: 0.000541  [ 1600/ 3009]\n",
            "loss: 0.000003  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000018  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236333 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000019  [    0/ 3009]\n",
            "loss: 0.002248  [  400/ 3009]\n",
            "loss: 0.000003  [  800/ 3009]\n",
            "loss: 0.000224  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000054  [ 2400/ 3009]\n",
            "loss: 0.000376  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.231660 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000153  [    0/ 3009]\n",
            "loss: 0.000329  [  400/ 3009]\n",
            "loss: 0.015604  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000008  [ 1600/ 3009]\n",
            "loss: 0.000085  [ 2000/ 3009]\n",
            "loss: 0.002437  [ 2400/ 3009]\n",
            "loss: 0.000094  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.240081 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000018  [  400/ 3009]\n",
            "loss: 0.000062  [  800/ 3009]\n",
            "loss: 0.002258  [ 1200/ 3009]\n",
            "loss: 0.001103  [ 1600/ 3009]\n",
            "loss: 0.000836  [ 2000/ 3009]\n",
            "loss: 0.000010  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.234058 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.000877  [    0/ 3009]\n",
            "loss: 0.000227  [  400/ 3009]\n",
            "loss: 0.006478  [  800/ 3009]\n",
            "loss: 0.000784  [ 1200/ 3009]\n",
            "loss: 0.000131  [ 1600/ 3009]\n",
            "loss: 0.000356  [ 2000/ 3009]\n",
            "loss: 0.001037  [ 2400/ 3009]\n",
            "loss: 0.000992  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.235550 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.000108  [    0/ 3009]\n",
            "loss: 0.001555  [  400/ 3009]\n",
            "loss: 0.000054  [  800/ 3009]\n",
            "loss: 0.002256  [ 1200/ 3009]\n",
            "loss: 0.001255  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.232799 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.000174  [    0/ 3009]\n",
            "loss: 0.000153  [  400/ 3009]\n",
            "loss: 0.000309  [  800/ 3009]\n",
            "loss: 0.000057  [ 1200/ 3009]\n",
            "loss: 0.000691  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.253599 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.001206  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000027  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000014  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.232703 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000005  [  800/ 3009]\n",
            "loss: 0.000012  [ 1200/ 3009]\n",
            "loss: 0.000160  [ 1600/ 3009]\n",
            "loss: 0.000083  [ 2000/ 3009]\n",
            "loss: 0.010495  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236669 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.000531  [    0/ 3009]\n",
            "loss: 0.001081  [  400/ 3009]\n",
            "loss: 0.000122  [  800/ 3009]\n",
            "loss: 0.002102  [ 1200/ 3009]\n",
            "loss: 0.000811  [ 1600/ 3009]\n",
            "loss: 0.000250  [ 2000/ 3009]\n",
            "loss: 0.002256  [ 2400/ 3009]\n",
            "loss: 0.000186  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236105 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.000675  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000302  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000082  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.235953 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.000028  [    0/ 3009]\n",
            "loss: 0.001291  [  400/ 3009]\n",
            "loss: 0.001313  [  800/ 3009]\n",
            "loss: 0.001666  [ 1200/ 3009]\n",
            "loss: 0.000069  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000025  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236357 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.000171  [    0/ 3009]\n",
            "loss: 0.000325  [  400/ 3009]\n",
            "loss: 0.000775  [  800/ 3009]\n",
            "loss: 0.000441  [ 1200/ 3009]\n",
            "loss: 0.000031  [ 1600/ 3009]\n",
            "loss: 0.000132  [ 2000/ 3009]\n",
            "loss: 0.000120  [ 2400/ 3009]\n",
            "loss: 0.000033  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.228009 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.000642  [    0/ 3009]\n",
            "loss: 0.000123  [  400/ 3009]\n",
            "loss: 0.000156  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.002764  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.239312 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.000116  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000234  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000007  [ 2400/ 3009]\n",
            "loss: 0.001379  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.236976 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000315  [  400/ 3009]\n",
            "loss: 0.000066  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000947  [ 1600/ 3009]\n",
            "loss: 0.000043  [ 2000/ 3009]\n",
            "loss: 0.000053  [ 2400/ 3009]\n",
            "loss: 0.000104  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.233436 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.000739  [    0/ 3009]\n",
            "loss: 0.000465  [  400/ 3009]\n",
            "loss: 0.001779  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000120  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.237184 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.000068  [    0/ 3009]\n",
            "loss: 0.000825  [  400/ 3009]\n",
            "loss: 0.000521  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000016  [ 1600/ 3009]\n",
            "loss: 0.000037  [ 2000/ 3009]\n",
            "loss: 0.000075  [ 2400/ 3009]\n",
            "loss: 0.000186  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.234011 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000968  [  400/ 3009]\n",
            "loss: 0.004851  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000005  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.237248 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.000126  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000971  [  800/ 3009]\n",
            "loss: 0.001717  [ 1200/ 3009]\n",
            "loss: 0.000020  [ 1600/ 3009]\n",
            "loss: 0.000284  [ 2000/ 3009]\n",
            "loss: 0.000121  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.243867 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.000377  [    0/ 3009]\n",
            "loss: 0.000413  [  400/ 3009]\n",
            "loss: 0.000083  [  800/ 3009]\n",
            "loss: 0.000195  [ 1200/ 3009]\n",
            "loss: 0.001326  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000302  [ 2400/ 3009]\n",
            "loss: 0.001554  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.237687 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.000199  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.004988  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.000099  [ 2000/ 3009]\n",
            "loss: 0.000026  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.237368 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.002481  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000033  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000014  [ 2000/ 3009]\n",
            "loss: 0.002346  [ 2400/ 3009]\n",
            "loss: 0.000007  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.236785 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.003012  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000072  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.226622 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.001005  [    0/ 3009]\n",
            "loss: 0.000462  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000476  [ 1200/ 3009]\n",
            "loss: 0.000288  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000031  [ 2400/ 3009]\n",
            "loss: 0.001815  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.233134 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.000007  [    0/ 3009]\n",
            "loss: 0.000056  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000123  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000024  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.233408 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.002430  [    0/ 3009]\n",
            "loss: 0.000518  [  400/ 3009]\n",
            "loss: 0.000137  [  800/ 3009]\n",
            "loss: 0.000552  [ 1200/ 3009]\n",
            "loss: 0.000052  [ 1600/ 3009]\n",
            "loss: 0.000109  [ 2000/ 3009]\n",
            "loss: 0.000032  [ 2400/ 3009]\n",
            "loss: 0.001348  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.240237 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.000940  [    0/ 3009]\n",
            "loss: 0.000086  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000031  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000145  [ 2400/ 3009]\n",
            "loss: 0.000061  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.248375 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.000283  [    0/ 3009]\n",
            "loss: 0.000421  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000040  [ 1200/ 3009]\n",
            "loss: 0.000169  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000022  [ 2400/ 3009]\n",
            "loss: 0.005781  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.241113 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.005378  [    0/ 3009]\n",
            "loss: 0.000576  [  400/ 3009]\n",
            "loss: 0.008177  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002281  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.003249  [ 2400/ 3009]\n",
            "loss: 0.000705  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.236852 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000451  [ 1200/ 3009]\n",
            "loss: 0.001186  [ 1600/ 3009]\n",
            "loss: 0.001197  [ 2000/ 3009]\n",
            "loss: 0.000047  [ 2400/ 3009]\n",
            "loss: 0.000092  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.235386 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.000163  [    0/ 3009]\n",
            "loss: 0.000072  [  400/ 3009]\n",
            "loss: 0.000012  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000163  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000465  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.238060 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.000795  [    0/ 3009]\n",
            "loss: 0.000018  [  400/ 3009]\n",
            "loss: 0.001927  [  800/ 3009]\n",
            "loss: 0.000137  [ 1200/ 3009]\n",
            "loss: 0.000089  [ 1600/ 3009]\n",
            "loss: 0.001746  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000006  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.236987 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.005491  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000022  [ 1600/ 3009]\n",
            "loss: 0.000007  [ 2000/ 3009]\n",
            "loss: 0.000017  [ 2400/ 3009]\n",
            "loss: 0.002394  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.234213 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.000213  [    0/ 3009]\n",
            "loss: 0.000031  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000061  [ 1200/ 3009]\n",
            "loss: 0.000167  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000010  [ 2400/ 3009]\n",
            "loss: 0.000531  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.246913 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000099  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.237907 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.000046  [    0/ 3009]\n",
            "loss: 0.001651  [  400/ 3009]\n",
            "loss: 0.000088  [  800/ 3009]\n",
            "loss: 0.000012  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000019  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.238269 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.000050  [    0/ 3009]\n",
            "loss: 0.000010  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000158  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000510  [ 2000/ 3009]\n",
            "loss: 0.001220  [ 2400/ 3009]\n",
            "loss: 0.004101  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.252395 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.002613  [  400/ 3009]\n",
            "loss: 0.000021  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000416  [ 1600/ 3009]\n",
            "loss: 0.000070  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000034  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.247768 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.000058  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000007  [ 1600/ 3009]\n",
            "loss: 0.000245  [ 2000/ 3009]\n",
            "loss: 0.000148  [ 2400/ 3009]\n",
            "loss: 0.000584  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.233464 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000141  [    0/ 3009]\n",
            "loss: 0.000059  [  400/ 3009]\n",
            "loss: 0.000175  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.001000  [ 2000/ 3009]\n",
            "loss: 0.000681  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.237565 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.000009  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000118  [ 1200/ 3009]\n",
            "loss: 0.000032  [ 1600/ 3009]\n",
            "loss: 0.001583  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000024  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.237486 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.000036  [    0/ 3009]\n",
            "loss: 0.000633  [  400/ 3009]\n",
            "loss: 0.000053  [  800/ 3009]\n",
            "loss: 0.001519  [ 1200/ 3009]\n",
            "loss: 0.000095  [ 1600/ 3009]\n",
            "loss: 0.000033  [ 2000/ 3009]\n",
            "loss: 0.000253  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.231942 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000717  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.006938  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.235016 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.000033  [    0/ 3009]\n",
            "loss: 0.000620  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.005753  [ 1200/ 3009]\n",
            "loss: 0.005089  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.277136 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.000024  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000182  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000085  [ 2000/ 3009]\n",
            "loss: 0.000057  [ 2400/ 3009]\n",
            "loss: 0.000520  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.238976 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000007  [  400/ 3009]\n",
            "loss: 0.000010  [  800/ 3009]\n",
            "loss: 0.000979  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.000101  [ 2000/ 3009]\n",
            "loss: 0.000798  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.240664 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000694  [  400/ 3009]\n",
            "loss: 0.000496  [  800/ 3009]\n",
            "loss: 0.000017  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000332  [ 2000/ 3009]\n",
            "loss: 0.000156  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.238457 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000021  [  400/ 3009]\n",
            "loss: 0.000040  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000018  [ 1600/ 3009]\n",
            "loss: 0.000080  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.244032 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000356  [    0/ 3009]\n",
            "loss: 0.001002  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000127  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.235974 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.000002  [    0/ 3009]\n",
            "loss: 0.000369  [  400/ 3009]\n",
            "loss: 0.000010  [  800/ 3009]\n",
            "loss: 0.000726  [ 1200/ 3009]\n",
            "loss: 0.001906  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000008  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.242143 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.001428  [    0/ 3009]\n",
            "loss: 0.000375  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000027  [ 1200/ 3009]\n",
            "loss: 0.000096  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.242752 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.003730  [  400/ 3009]\n",
            "loss: 0.001247  [  800/ 3009]\n",
            "loss: 0.000006  [ 1200/ 3009]\n",
            "loss: 0.000079  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000120  [ 2400/ 3009]\n",
            "loss: 0.000067  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.245832 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.000126  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000028  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000017  [ 2000/ 3009]\n",
            "loss: 0.000224  [ 2400/ 3009]\n",
            "loss: 0.000418  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.242436 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92000ef2a0a14956a86235e046d4abe9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▄▂▂▂▂▁▂▁▃▂▁▂▂▃▃▃▄▃▂▅▄▃▄▂▄▄▅▄▄▇▄▄▅█▅▃▅▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.24244</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fancy-sweep-4</strong> at: <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/6srai5wy' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/6srai5wy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231221_115044-6srai5wy/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2z8nn46t with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005900669269670262\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231221_115443-2z8nn46t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/2z8nn46t' target=\"_blank\">sparkling-sweep-5</a></strong> to <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amirali/MRI_CI_LAB' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/sweeps/i1a7tcfq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/2z8nn46t' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/2z8nn46t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.005284  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000028  [  800/ 3009]\n",
            "loss: 0.000025  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000205  [ 2000/ 3009]\n",
            "loss: 0.000060  [ 2400/ 3009]\n",
            "loss: 0.000650  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.238935 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000362  [  800/ 3009]\n",
            "loss: 0.000064  [ 1200/ 3009]\n",
            "loss: 0.000105  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.001001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.252647 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.000073  [    0/ 3009]\n",
            "loss: 0.000018  [  400/ 3009]\n",
            "loss: 0.000020  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000169  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.237680 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.001952  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000041  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000147  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.249906 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000144  [  800/ 3009]\n",
            "loss: 0.000093  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000078  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000207  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.248437 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.002318  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000546  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.246192 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.001431  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000026  [ 1600/ 3009]\n",
            "loss: 0.004114  [ 2000/ 3009]\n",
            "loss: 0.000003  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.243763 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.000148  [    0/ 3009]\n",
            "loss: 0.000165  [  400/ 3009]\n",
            "loss: 0.000028  [  800/ 3009]\n",
            "loss: 0.000170  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000019  [ 2000/ 3009]\n",
            "loss: 0.000034  [ 2400/ 3009]\n",
            "loss: 0.000569  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.248316 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000012  [  400/ 3009]\n",
            "loss: 0.000173  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000016  [ 2000/ 3009]\n",
            "loss: 0.000073  [ 2400/ 3009]\n",
            "loss: 0.000699  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.245175 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.000070  [    0/ 3009]\n",
            "loss: 0.000373  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000848  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000293  [ 2000/ 3009]\n",
            "loss: 0.000488  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.242087 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.000226  [    0/ 3009]\n",
            "loss: 0.000092  [  400/ 3009]\n",
            "loss: 0.000009  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000014  [ 1600/ 3009]\n",
            "loss: 0.000065  [ 2000/ 3009]\n",
            "loss: 0.000122  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.244032 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.000005  [    0/ 3009]\n",
            "loss: 0.000131  [  400/ 3009]\n",
            "loss: 0.000009  [  800/ 3009]\n",
            "loss: 0.000034  [ 1200/ 3009]\n",
            "loss: 0.000009  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.243569 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.000970  [    0/ 3009]\n",
            "loss: 0.000059  [  400/ 3009]\n",
            "loss: 0.000021  [  800/ 3009]\n",
            "loss: 0.000125  [ 1200/ 3009]\n",
            "loss: 0.000256  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000715  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.242331 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.000014  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000360  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000057  [ 1600/ 3009]\n",
            "loss: 0.000096  [ 2000/ 3009]\n",
            "loss: 0.000114  [ 2400/ 3009]\n",
            "loss: 0.000642  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.244240 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.001476  [  400/ 3009]\n",
            "loss: 0.000008  [  800/ 3009]\n",
            "loss: 0.000115  [ 1200/ 3009]\n",
            "loss: 0.000849  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000872  [ 2400/ 3009]\n",
            "loss: 0.000627  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.246873 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.000190  [    0/ 3009]\n",
            "loss: 0.000009  [  400/ 3009]\n",
            "loss: 0.000975  [  800/ 3009]\n",
            "loss: 0.000070  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000022  [ 2400/ 3009]\n",
            "loss: 0.001879  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.245179 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000032  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000055  [ 1200/ 3009]\n",
            "loss: 0.000046  [ 1600/ 3009]\n",
            "loss: 0.000223  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.250585 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000072  [  400/ 3009]\n",
            "loss: 0.000008  [  800/ 3009]\n",
            "loss: 0.000367  [ 1200/ 3009]\n",
            "loss: 0.000954  [ 1600/ 3009]\n",
            "loss: 0.000009  [ 2000/ 3009]\n",
            "loss: 0.000016  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.238162 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.000803  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000062  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000090  [ 2000/ 3009]\n",
            "loss: 0.000129  [ 2400/ 3009]\n",
            "loss: 0.000012  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236609 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.000743  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000064  [  800/ 3009]\n",
            "loss: 0.000007  [ 1200/ 3009]\n",
            "loss: 0.000545  [ 1600/ 3009]\n",
            "loss: 0.000056  [ 2000/ 3009]\n",
            "loss: 0.000066  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.236865 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.000020  [    0/ 3009]\n",
            "loss: 0.000463  [  400/ 3009]\n",
            "loss: 0.000321  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000038  [ 2000/ 3009]\n",
            "loss: 0.001483  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.248287 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000373  [    0/ 3009]\n",
            "loss: 0.000961  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000245  [ 1600/ 3009]\n",
            "loss: 0.000299  [ 2000/ 3009]\n",
            "loss: 0.000486  [ 2400/ 3009]\n",
            "loss: 0.000471  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.254859 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.000128  [    0/ 3009]\n",
            "loss: 0.001655  [  400/ 3009]\n",
            "loss: 0.000013  [  800/ 3009]\n",
            "loss: 0.000932  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000857  [ 2000/ 3009]\n",
            "loss: 0.000399  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.251147 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.001661  [    0/ 3009]\n",
            "loss: 0.000840  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000104  [ 1200/ 3009]\n",
            "loss: 0.002007  [ 1600/ 3009]\n",
            "loss: 0.000199  [ 2000/ 3009]\n",
            "loss: 0.000028  [ 2400/ 3009]\n",
            "loss: 0.000230  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.251326 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000034  [    0/ 3009]\n",
            "loss: 0.000600  [  400/ 3009]\n",
            "loss: 0.000085  [  800/ 3009]\n",
            "loss: 0.000024  [ 1200/ 3009]\n",
            "loss: 0.001074  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000108  [ 2400/ 3009]\n",
            "loss: 0.000131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.242982 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000066  [  400/ 3009]\n",
            "loss: 0.000021  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000015  [ 2400/ 3009]\n",
            "loss: 0.001273  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.250905 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000206  [    0/ 3009]\n",
            "loss: 0.000347  [  400/ 3009]\n",
            "loss: 0.000070  [  800/ 3009]\n",
            "loss: 0.000983  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000074  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.247066 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.001210  [    0/ 3009]\n",
            "loss: 0.000410  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000819  [ 1600/ 3009]\n",
            "loss: 0.000158  [ 2000/ 3009]\n",
            "loss: 0.002163  [ 2400/ 3009]\n",
            "loss: 0.000034  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.248122 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.001621  [    0/ 3009]\n",
            "loss: 0.000035  [  400/ 3009]\n",
            "loss: 0.000095  [  800/ 3009]\n",
            "loss: 0.000028  [ 1200/ 3009]\n",
            "loss: 0.000235  [ 1600/ 3009]\n",
            "loss: 0.000017  [ 2000/ 3009]\n",
            "loss: 0.000829  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.248911 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000092  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000247  [  800/ 3009]\n",
            "loss: 0.000277  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000021  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.247007 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000083  [  400/ 3009]\n",
            "loss: 0.000064  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000013  [ 1600/ 3009]\n",
            "loss: 0.001417  [ 2000/ 3009]\n",
            "loss: 0.000629  [ 2400/ 3009]\n",
            "loss: 0.000031  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.246967 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.000283  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000022  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000011  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.252024 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000085  [    0/ 3009]\n",
            "loss: 0.000250  [  400/ 3009]\n",
            "loss: 0.000087  [  800/ 3009]\n",
            "loss: 0.001048  [ 1200/ 3009]\n",
            "loss: 0.001442  [ 1600/ 3009]\n",
            "loss: 0.000106  [ 2000/ 3009]\n",
            "loss: 0.000445  [ 2400/ 3009]\n",
            "loss: 0.000021  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.245216 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.001732  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000063  [  800/ 3009]\n",
            "loss: 0.000114  [ 1200/ 3009]\n",
            "loss: 0.000380  [ 1600/ 3009]\n",
            "loss: 0.000100  [ 2000/ 3009]\n",
            "loss: 0.000074  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.251913 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.000262  [    0/ 3009]\n",
            "loss: 0.000704  [  400/ 3009]\n",
            "loss: 0.001587  [  800/ 3009]\n",
            "loss: 0.000425  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.001100  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.244870 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000512  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.241850 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000098  [  400/ 3009]\n",
            "loss: 0.000042  [  800/ 3009]\n",
            "loss: 0.000128  [ 1200/ 3009]\n",
            "loss: 0.000018  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000025  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.246579 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000009  [    0/ 3009]\n",
            "loss: 0.001292  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000005  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.247539 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000059  [    0/ 3009]\n",
            "loss: 0.000045  [  400/ 3009]\n",
            "loss: 0.000237  [  800/ 3009]\n",
            "loss: 0.000110  [ 1200/ 3009]\n",
            "loss: 0.000784  [ 1600/ 3009]\n",
            "loss: 0.000770  [ 2000/ 3009]\n",
            "loss: 0.000215  [ 2400/ 3009]\n",
            "loss: 0.000003  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.272257 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000112  [    0/ 3009]\n",
            "loss: 0.000279  [  400/ 3009]\n",
            "loss: 0.000011  [  800/ 3009]\n",
            "loss: 0.001388  [ 1200/ 3009]\n",
            "loss: 0.000062  [ 1600/ 3009]\n",
            "loss: 0.002896  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000156  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.249953 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.001170  [  400/ 3009]\n",
            "loss: 0.001096  [  800/ 3009]\n",
            "loss: 0.000501  [ 1200/ 3009]\n",
            "loss: 0.000058  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.248893 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000040  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.001295  [ 2400/ 3009]\n",
            "loss: 0.006433  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.248674 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000018  [    0/ 3009]\n",
            "loss: 0.000002  [  400/ 3009]\n",
            "loss: 0.001062  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000548  [ 1600/ 3009]\n",
            "loss: 0.000023  [ 2000/ 3009]\n",
            "loss: 0.001421  [ 2400/ 3009]\n",
            "loss: 0.000288  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.250237 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000005  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000013  [ 2000/ 3009]\n",
            "loss: 0.005501  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.245720 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000054  [  800/ 3009]\n",
            "loss: 0.000097  [ 1200/ 3009]\n",
            "loss: 0.000540  [ 1600/ 3009]\n",
            "loss: 0.002671  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000009  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.249694 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000004  [    0/ 3009]\n",
            "loss: 0.000182  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.001343  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000021  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.244457 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000118  [    0/ 3009]\n",
            "loss: 0.000344  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000064  [ 1200/ 3009]\n",
            "loss: 0.000087  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000313  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.251056 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.003283  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000020  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000308  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000610  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.254501 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000252  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000042  [ 2000/ 3009]\n",
            "loss: 0.001432  [ 2400/ 3009]\n",
            "loss: 0.000060  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.254264 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000305  [    0/ 3009]\n",
            "loss: 0.000583  [  400/ 3009]\n",
            "loss: 0.000023  [  800/ 3009]\n",
            "loss: 0.000169  [ 1200/ 3009]\n",
            "loss: 0.004073  [ 1600/ 3009]\n",
            "loss: 0.000098  [ 2000/ 3009]\n",
            "loss: 0.002062  [ 2400/ 3009]\n",
            "loss: 0.000847  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.251023 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.000461  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.003007  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.246430 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.000015  [    0/ 3009]\n",
            "loss: 0.000116  [  400/ 3009]\n",
            "loss: 0.000148  [  800/ 3009]\n",
            "loss: 0.000289  [ 1200/ 3009]\n",
            "loss: 0.000078  [ 1600/ 3009]\n",
            "loss: 0.000009  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000049  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.252276 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000134  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.001117  [ 2400/ 3009]\n",
            "loss: 0.000055  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.244707 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.000245  [    0/ 3009]\n",
            "loss: 0.000088  [  400/ 3009]\n",
            "loss: 0.000425  [  800/ 3009]\n",
            "loss: 0.000385  [ 1200/ 3009]\n",
            "loss: 0.000133  [ 1600/ 3009]\n",
            "loss: 0.000003  [ 2000/ 3009]\n",
            "loss: 0.000089  [ 2400/ 3009]\n",
            "loss: 0.000246  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.251636 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000665  [ 1600/ 3009]\n",
            "loss: 0.000079  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.251849 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000019  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.001023  [ 1600/ 3009]\n",
            "loss: 0.000047  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000260  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.250775 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.000012  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.001811  [  800/ 3009]\n",
            "loss: 0.001681  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000017  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.252482 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.002575  [    0/ 3009]\n",
            "loss: 0.000844  [  400/ 3009]\n",
            "loss: 0.002204  [  800/ 3009]\n",
            "loss: 0.000497  [ 1200/ 3009]\n",
            "loss: 0.000124  [ 1600/ 3009]\n",
            "loss: 0.000076  [ 2000/ 3009]\n",
            "loss: 0.000013  [ 2400/ 3009]\n",
            "loss: 0.000004  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.255231 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.001662  [    0/ 3009]\n",
            "loss: 0.000040  [  400/ 3009]\n",
            "loss: 0.000022  [  800/ 3009]\n",
            "loss: 0.000037  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000011  [ 2000/ 3009]\n",
            "loss: 0.000066  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.246846 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.000005  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.001289  [  800/ 3009]\n",
            "loss: 0.001744  [ 1200/ 3009]\n",
            "loss: 0.000174  [ 1600/ 3009]\n",
            "loss: 0.000105  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000548  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.261515 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.000003  [    0/ 3009]\n",
            "loss: 0.000005  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000014  [ 2400/ 3009]\n",
            "loss: 0.001566  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.253415 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.000154  [    0/ 3009]\n",
            "loss: 0.000070  [  400/ 3009]\n",
            "loss: 0.001186  [  800/ 3009]\n",
            "loss: 0.000620  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000183  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.255882 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000014  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.003186  [ 2400/ 3009]\n",
            "loss: 0.000034  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.247852 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.000119  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.002516  [  800/ 3009]\n",
            "loss: 0.000633  [ 1200/ 3009]\n",
            "loss: 0.000015  [ 1600/ 3009]\n",
            "loss: 0.000307  [ 2000/ 3009]\n",
            "loss: 0.005945  [ 2400/ 3009]\n",
            "loss: 0.000228  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.247920 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000441  [  400/ 3009]\n",
            "loss: 0.000700  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000004  [ 1600/ 3009]\n",
            "loss: 0.000010  [ 2000/ 3009]\n",
            "loss: 0.000321  [ 2400/ 3009]\n",
            "loss: 0.001721  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.252036 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000336  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000208  [ 1200/ 3009]\n",
            "loss: 0.000141  [ 1600/ 3009]\n",
            "loss: 0.000001  [ 2000/ 3009]\n",
            "loss: 0.000046  [ 2400/ 3009]\n",
            "loss: 0.001125  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.253559 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000044  [  400/ 3009]\n",
            "loss: 0.000248  [  800/ 3009]\n",
            "loss: 0.000009  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000526  [ 2000/ 3009]\n",
            "loss: 0.000578  [ 2400/ 3009]\n",
            "loss: 0.000014  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.256525 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000322  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000136  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000325  [ 2400/ 3009]\n",
            "loss: 0.001040  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.254143 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.000010  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000029  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000640  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.253846 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000009  [  400/ 3009]\n",
            "loss: 0.000211  [  800/ 3009]\n",
            "loss: 0.000438  [ 1200/ 3009]\n",
            "loss: 0.000005  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000001  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.254650 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.000107  [    0/ 3009]\n",
            "loss: 0.000294  [  400/ 3009]\n",
            "loss: 0.000004  [  800/ 3009]\n",
            "loss: 0.000038  [ 1200/ 3009]\n",
            "loss: 0.000833  [ 1600/ 3009]\n",
            "loss: 0.000078  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000016  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.255556 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000114  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000476  [ 1600/ 3009]\n",
            "loss: 0.002444  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000638  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.252699 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.000010  [    0/ 3009]\n",
            "loss: 0.000098  [  400/ 3009]\n",
            "loss: 0.000367  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000006  [ 1600/ 3009]\n",
            "loss: 0.000066  [ 2000/ 3009]\n",
            "loss: 0.004631  [ 2400/ 3009]\n",
            "loss: 0.002567  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.252034 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000282  [  800/ 3009]\n",
            "loss: 0.001486  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000016  [ 2000/ 3009]\n",
            "loss: 0.000017  [ 2400/ 3009]\n",
            "loss: 0.000161  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.257233 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000387  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000084  [ 2000/ 3009]\n",
            "loss: 0.000120  [ 2400/ 3009]\n",
            "loss: 0.000426  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.255393 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000023  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000008  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000085  [ 2000/ 3009]\n",
            "loss: 0.000113  [ 2400/ 3009]\n",
            "loss: 0.000764  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.257837 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000006  [  400/ 3009]\n",
            "loss: 0.000446  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.000219  [ 2000/ 3009]\n",
            "loss: 0.000309  [ 2400/ 3009]\n",
            "loss: 0.000010  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.252020 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.000033  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000596  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.002083  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000448  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.250176 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000805  [  400/ 3009]\n",
            "loss: 0.001918  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000006  [ 2000/ 3009]\n",
            "loss: 0.000051  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.256346 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.000212  [    0/ 3009]\n",
            "loss: 0.000167  [  400/ 3009]\n",
            "loss: 0.000001  [  800/ 3009]\n",
            "loss: 0.000012  [ 1200/ 3009]\n",
            "loss: 0.000003  [ 1600/ 3009]\n",
            "loss: 0.001073  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.252050 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.000100  [    0/ 3009]\n",
            "loss: 0.002427  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000465  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000303  [ 2000/ 3009]\n",
            "loss: 0.003145  [ 2400/ 3009]\n",
            "loss: 0.000279  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.249683 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.000531  [    0/ 3009]\n",
            "loss: 0.000312  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.001673  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000048  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.254700 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.000582  [    0/ 3009]\n",
            "loss: 0.000004  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000000  [ 1200/ 3009]\n",
            "loss: 0.000266  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000002  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.265287 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.000407  [    0/ 3009]\n",
            "loss: 0.000325  [  400/ 3009]\n",
            "loss: 0.000005  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000291  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000780  [ 2400/ 3009]\n",
            "loss: 0.000013  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.257512 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.000129  [    0/ 3009]\n",
            "loss: 0.000532  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000002  [ 1600/ 3009]\n",
            "loss: 0.000077  [ 2000/ 3009]\n",
            "loss: 0.000043  [ 2400/ 3009]\n",
            "loss: 0.000483  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.258437 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.000494  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000293  [  800/ 3009]\n",
            "loss: 0.000004  [ 1200/ 3009]\n",
            "loss: 0.000023  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000007  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.252407 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.000006  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000002  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000402  [ 2000/ 3009]\n",
            "loss: 0.000014  [ 2400/ 3009]\n",
            "loss: 0.000005  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.255060 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.002983  [    0/ 3009]\n",
            "loss: 0.000000  [  400/ 3009]\n",
            "loss: 0.000081  [  800/ 3009]\n",
            "loss: 0.000026  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000037  [ 2400/ 3009]\n",
            "loss: 0.000131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.259385 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.000160  [    0/ 3009]\n",
            "loss: 0.000025  [  400/ 3009]\n",
            "loss: 0.000000  [  800/ 3009]\n",
            "loss: 0.000003  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.004262  [ 2000/ 3009]\n",
            "loss: 0.000006  [ 2400/ 3009]\n",
            "loss: 0.000088  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.259509 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.000500  [    0/ 3009]\n",
            "loss: 0.000003  [  400/ 3009]\n",
            "loss: 0.000039  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000065  [ 1600/ 3009]\n",
            "loss: 0.000022  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000012  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.254777 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.000007  [    0/ 3009]\n",
            "loss: 0.001135  [  400/ 3009]\n",
            "loss: 0.000028  [  800/ 3009]\n",
            "loss: 0.000106  [ 1200/ 3009]\n",
            "loss: 0.003820  [ 1600/ 3009]\n",
            "loss: 0.000043  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.255977 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.000376  [    0/ 3009]\n",
            "loss: 0.000001  [  400/ 3009]\n",
            "loss: 0.000380  [  800/ 3009]\n",
            "loss: 0.000064  [ 1200/ 3009]\n",
            "loss: 0.000726  [ 1600/ 3009]\n",
            "loss: 0.000840  [ 2000/ 3009]\n",
            "loss: 0.000030  [ 2400/ 3009]\n",
            "loss: 0.000002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.264491 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/ 3009]\n",
            "loss: 0.000011  [  400/ 3009]\n",
            "loss: 0.000011  [  800/ 3009]\n",
            "loss: 0.001098  [ 1200/ 3009]\n",
            "loss: 0.000016  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000451  [ 2400/ 3009]\n",
            "loss: 0.000019  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.261278 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.000496  [    0/ 3009]\n",
            "loss: 0.000061  [  400/ 3009]\n",
            "loss: 0.000113  [  800/ 3009]\n",
            "loss: 0.000032  [ 1200/ 3009]\n",
            "loss: 0.000262  [ 1600/ 3009]\n",
            "loss: 0.000004  [ 2000/ 3009]\n",
            "loss: 0.000258  [ 2400/ 3009]\n",
            "loss: 0.001506  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.253067 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000684  [  400/ 3009]\n",
            "loss: 0.000005  [  800/ 3009]\n",
            "loss: 0.001807  [ 1200/ 3009]\n",
            "loss: 0.000043  [ 1600/ 3009]\n",
            "loss: 0.000023  [ 2000/ 3009]\n",
            "loss: 0.000004  [ 2400/ 3009]\n",
            "loss: 0.000017  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.3%, Avg loss: 0.259303 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000053  [  400/ 3009]\n",
            "loss: 0.000294  [  800/ 3009]\n",
            "loss: 0.000018  [ 1200/ 3009]\n",
            "loss: 0.000000  [ 1600/ 3009]\n",
            "loss: 0.000281  [ 2000/ 3009]\n",
            "loss: 0.003182  [ 2400/ 3009]\n",
            "loss: 0.000045  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.254661 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000725  [  400/ 3009]\n",
            "loss: 0.000006  [  800/ 3009]\n",
            "loss: 0.000027  [ 1200/ 3009]\n",
            "loss: 0.000015  [ 1600/ 3009]\n",
            "loss: 0.000002  [ 2000/ 3009]\n",
            "loss: 0.000000  [ 2400/ 3009]\n",
            "loss: 0.000000  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.253034 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000009  [  400/ 3009]\n",
            "loss: 0.000427  [  800/ 3009]\n",
            "loss: 0.000188  [ 1200/ 3009]\n",
            "loss: 0.000074  [ 1600/ 3009]\n",
            "loss: 0.000000  [ 2000/ 3009]\n",
            "loss: 0.000293  [ 2400/ 3009]\n",
            "loss: 0.000279  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.255296 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.000733  [    0/ 3009]\n",
            "loss: 0.000215  [  400/ 3009]\n",
            "loss: 0.000055  [  800/ 3009]\n",
            "loss: 0.000548  [ 1200/ 3009]\n",
            "loss: 0.000001  [ 1600/ 3009]\n",
            "loss: 0.000012  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000430  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.258226 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.000000  [    0/ 3009]\n",
            "loss: 0.000012  [  400/ 3009]\n",
            "loss: 0.000002  [  800/ 3009]\n",
            "loss: 0.000001  [ 1200/ 3009]\n",
            "loss: 0.000028  [ 1600/ 3009]\n",
            "loss: 0.000829  [ 2000/ 3009]\n",
            "loss: 0.000001  [ 2400/ 3009]\n",
            "loss: 0.000130  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.257961 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66b8c9d575bb432eaee598cc1b5d498f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁▃▃▂▂▃▁▃▄▄▃▃▄▂█▃▃▂▄▃▄▄▃▄▃▅▄▄▅▄▅▄▅▅▅▆▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.25796</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sparkling-sweep-5</strong> at: <a href='https://wandb.ai/amirali/MRI_CI_LAB/runs/2z8nn46t' target=\"_blank\">https://wandb.ai/amirali/MRI_CI_LAB/runs/2z8nn46t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231221_115443-2z8nn46t/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"MRI_CI_LAB\")\n",
        "try :\n",
        "  wandb.agent(sweep_id , train , count=5)\n",
        "except Exception as e :\n",
        "  wandb.socket.close()\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyjLOC2n-5z2"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS8h-OH-E4Ca"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c434af7e569476c9014fe209489724d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbaa8c7588e4d8ea167682c0251bd1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185f0ff33ad94bac825fb76f1ebf5113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ac1436b35e4e27a3bcec7282baf89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c434af7e569476c9014fe209489724d",
            "placeholder": "​",
            "style": "IPY_MODEL_185f0ff33ad94bac825fb76f1ebf5113",
            "value": "0.042 MB of 0.042 MB uploaded\r"
          }
        },
        "24565207eec34dbe805f599f0ec17dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a19fdcf2134566950a495b459752f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a593f89cec844f9b4ecfccf36e920be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_babe5f7bfc4c43888654f09d5847b92a",
              "IPY_MODEL_3e5918a624e64230bdc22eee01e0cdc0"
            ],
            "layout": "IPY_MODEL_f3006247aef540bba09f0e84cb5b3955"
          }
        },
        "38ef2ae2958b4042ac656e15197eec53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fba1836a8ad43d7bea59bda434cfede",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45a8dbe3ec8b4841bcfeab9603330ccb",
            "value": 1
          }
        },
        "3e5918a624e64230bdc22eee01e0cdc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4924d7f0a7ee4626b9573d9cd9068e5a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec10da7c20c948fca17ce6e266c4aafb",
            "value": 0
          }
        },
        "4294b8e236324030900be16930f67d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a8dbe3ec8b4841bcfeab9603330ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4924d7f0a7ee4626b9573d9cd9068e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d6581aaefb4bd78644d92475e006fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51840b8335374baf88c3f0944f75c37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fba1836a8ad43d7bea59bda434cfede": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656d6808fd9642edb4ae6535bb61fb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4294b8e236324030900be16930f67d7a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_943e534152d0481daee56edfbaa9dcb4",
            "value": 1
          }
        },
        "66b8c9d575bb432eaee598cc1b5d498f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ac1436b35e4e27a3bcec7282baf89b",
              "IPY_MODEL_ae814cb8fc994179a6e0416c6c69a69f"
            ],
            "layout": "IPY_MODEL_da060817afe14f58be229c01d2986fb1"
          }
        },
        "6bb5f118972d42e0baefdec59eb90294": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cba75755c84d24920d97457c3a9f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6cbc5a098794a989fbc8dedceb1563d",
              "IPY_MODEL_38ef2ae2958b4042ac656e15197eec53"
            ],
            "layout": "IPY_MODEL_28a19fdcf2134566950a495b459752f5"
          }
        },
        "9025c427e12a4bebad41cece589ab6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92000ef2a0a14956a86235e046d4abe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0b319970aa4ff185ed8ae8e684a87e",
              "IPY_MODEL_656d6808fd9642edb4ae6535bb61fb10"
            ],
            "layout": "IPY_MODEL_6bb5f118972d42e0baefdec59eb90294"
          }
        },
        "943e534152d0481daee56edfbaa9dcb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6cbc5a098794a989fbc8dedceb1563d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea4074e042c490184fd9ffa2a7e8ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_9025c427e12a4bebad41cece589ab6a1",
            "value": "0.042 MB of 0.042 MB uploaded\r"
          }
        },
        "ae814cb8fc994179a6e0416c6c69a69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cbaa8c7588e4d8ea167682c0251bd1a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba82b7e9ecde498783cf4b2cc104867e",
            "value": 1
          }
        },
        "aea4074e042c490184fd9ffa2a7e8ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba82b7e9ecde498783cf4b2cc104867e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "babe5f7bfc4c43888654f09d5847b92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24565207eec34dbe805f599f0ec17dbd",
            "placeholder": "​",
            "style": "IPY_MODEL_db9cd74e8e264ce5ab7d6792302b60bc",
            "value": ""
          }
        },
        "da060817afe14f58be229c01d2986fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9cd74e8e264ce5ab7d6792302b60bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec10da7c20c948fca17ce6e266c4aafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3006247aef540bba09f0e84cb5b3955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0b319970aa4ff185ed8ae8e684a87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d6581aaefb4bd78644d92475e006fc",
            "placeholder": "​",
            "style": "IPY_MODEL_51840b8335374baf88c3f0944f75c37f",
            "value": "0.042 MB of 0.042 MB uploaded\r"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
